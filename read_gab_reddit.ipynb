{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import ast\n",
    "import time\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "# import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import re\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', 10)  # Limit number of rows displayed\n",
    "pd.set_option('display.width', 1000)  # Set max width for table\n",
    "pd.set_option('display.colheader_justify', 'center')  # Center-align column headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_special_chars(value):\n",
    "    if isinstance(value, str):  \n",
    "        return value.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ').replace('  ', ' ').strip()\n",
    "    return value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading gab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          id                                                text                        hate_speech_idx                      response                     \n",
      "0                                    1. 39869714\\r\\n  1. i joined gab to remind myself how retarded ...         [1]      [\"Using words that insult one group while defe...\n",
      "1  1. 39845588\\r\\n2. \\t39848775\\r\\n3. \\t\\t3991101...  1. This is what the left is really scared of. ...         [3]      ['You can disagree with someones opinion witho...\n",
      "2                   1. 37485560\\r\\n2. \\t37528625\\r\\n  1. It makes you an asshole.\\r\\n2. \\tGive it to...         [2]      ['Your argument is more rational if you leave ...\n",
      "3                   1. 39787626\\r\\n2. \\t39794481\\r\\n  1. So they manage to provide a whole lot of da...         [2]      [\"You shouldn't generalize a specific group or...\n",
      "4  1. 37957930\\r\\n2. \\t39953348\\r\\n3. \\t\\t3996521...  1. Hi there, i,m Keith, i hope you are doing w...         [3]      ['If someone is rude it is better to ignore th...\n",
      "5                                    1. 38462712\\r\\n                    1. you sound like a faggot \\r\\n         [1]      [\"Please be careful with the words you choose ...\n",
      "6  1. 38052531\\r\\n2. \\t38103723\\r\\n3. \\t\\t3851658...  1. Hi developers, give us a follow for updates...         [3]      [\"The words you've chosen are hateful and dero...\n",
      "7                   1. 38352488\\r\\n2. \\t38373190\\r\\n  1. Well, you are the fuckers that lit the matc...         [2]      ['Please refrain from using such horrible bigo...\n",
      "8  1. 37238116\\r\\n2. \\t38348543\\r\\n3. \\t\\t3837623...  1. SELF-HATING WHITE CUCKS ON PARADE\\r\\n2. \\tD...      [1, 3]      ['Your words are derogatory and offensive, and...\n",
      "9  1. 37358018\\r\\n2. \\t37359176\\r\\n3. \\t\\t3738104...  1. So after 6 years and nearly 11K followers, ...         [3]      [\"Woah! Please don't use such strong and offen...\n",
      "\n",
      "- - - - - -\n",
      "\n",
      "Index(['id', 'text', 'hate_speech_idx', 'response'], dtype='object')\n",
      "\n",
      "- - - - - -\n",
      "\n",
      "1. 39845588\n",
      "2. \t39848775\n",
      "3. \t\t39911017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content_gab = pd.read_csv('gab_reddit_benchmark/gab.csv')\n",
    "\n",
    "content_gab[\"text\"] = content_gab[\"text\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\") \n",
    "content_gab[\"response\"] = content_gab[\"response\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\")\n",
    "content_gab[\"hate_speech_idx\"] = content_gab[\"hate_speech_idx\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\") \n",
    "\n",
    "# content_gab[\"text\"] = content_gab[\"text\"].apply(clean_special_chars)\n",
    "# content_gab[\"response\"] = content_gab[\"response\"].apply(clean_special_chars)\n",
    "\n",
    "for index, row in content_gab.iterrows():\n",
    "    row['text'] = row['text'].replace(\"'\", '\"')\n",
    "    row['response'] = row['response'].replace(\"'\", '\"')\n",
    "\n",
    "# content_gab = content_gab.applymap(clean_special_chars)\n",
    "print(content_gab.head(n=10))\n",
    "print('\\n- - - - - -\\n')\n",
    "print(content_gab.columns)\n",
    "print('\\n- - - - - -\\n')\n",
    "print(content_gab.iloc[1]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_first_number(input_string):\n",
    "    match = re.search(r'\\d{2,}', input_string)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None\n",
    "\n",
    "content_gab['extracted_id'] = content_gab['id'].apply(get_first_number)\n",
    "\n",
    "# Find duplicate rows based on 'extracted_id'\n",
    "duplicates = content_gab[content_gab.duplicated(subset=['extracted_id'], keep=False)]\n",
    "filtered_groups = []\n",
    "grouped = content_gab.groupby('extracted_id')\n",
    "for key, group in grouped:\n",
    "    if len(group) > 1:\n",
    "        filtered_groups.append(group)\n",
    "\n",
    "merged_df = pd.concat(filtered_groups, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv('gab_reddit_benchmark/gab_groups.csv', index=False)\n",
    "\n",
    "merged_df = grouped.agg({\n",
    "    'id': ' '.join,\n",
    "    'text': ' '.join,\n",
    "    'hate_speech_idx': ' '.join,\n",
    "    'response': ' '.join\n",
    "}).reset_index()\n",
    "merged_df.to_csv('gab_reddit_benchmark/gab_merged.csv')\n",
    "\n",
    "df = pd.read_csv('gab_reddit_benchmark/gab_merged.csv')\n",
    "df = df.applymap(lambda x: x.replace('] [', ', ') if isinstance(x, str) else x)\n",
    "df = df.applymap(lambda x: x.replace(']  [', ', ') if isinstance(x, str) else x)\n",
    "df = df.applymap(lambda x: 'n/a' if isinstance(x, str) and x.strip() == '' else x)\n",
    "df.to_csv('gab_reddit_benchmark/gab_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          id                                                text                        hate_speech_idx                      response                     \n",
      "0  1. 37011807\\r\\n2. \\t37012801\\r\\n3. \\t\\t3701333...  1. 64% of Hispanics have IQ scores too low to ...     [2, 2, 3]    ['Racist and hate speech will not be tolerated...\n",
      "1                    1. 37012081\\r\\n 1. 37012081\\r\\n  1. LYING CUNT BITCH !!\\r\\n 1. LYING CUNT BITCH...        [1, 1]    ['Please refrain from using derogatory terms f...\n",
      "2                                    1. 37012105\\r\\n  1. Nigger Kills 2 cops https://www.google.com/...           [1]    ['The N word is highly offensive.   All ethnic...\n",
      "3                   1. 37012146\\r\\n2. \\t37013020\\r\\n  1. STABBED IN NECK   arrested but no descr   #...           [2]    ['Use of the n-word is unacceptable in our dis...\n",
      "4  1. 37012285\\r\\n2. \\t37013809\\r\\n3. \\t37013868\\r\\n  1. Retard 1st Class  w/ Cluster & Ribbon\\r\\n2....           [1]    ['We should try and not use words making fun o...\n",
      "5                                    1. 37012571\\r\\n  1. We should be happy they do fuck their cousi...           [1]    ['I cannot listen to your argument if you keep...\n",
      "6  1. 37012882\\r\\n2. \\t37013415\\r\\n3. \\t\\t3701686...  1. Stolen Valor! Prosecute the scum.\\r\\n2. \\t\\...        [3, 4]    ['Stick to your own beliefs without dismissing...\n",
      "7                                    1. 37013030\\r\\n  1. Yea, here's the scoop.  Fake News! \"We told...                                                                   \n",
      "8                                    1. 37013358\\r\\n           1. Throat-punch that faggot DeNigger\\r\\n           [1]    ['I hope that you can see that you are advocat...\n",
      "9                                    1. 37013922\\r\\n  1. https://www.youtube.com/watch?v=DmNRkp_fuoo...           [1]    ['Gender is a category that shouldn’t be the b...\n",
      "\n",
      "- - - - - -\n",
      "\n",
      "Index(['id', 'text', 'hate_speech_idx', 'response'], dtype='object')\n",
      "\n",
      "- - - - - -\n",
      "\n",
      "1. 37011807\n",
      "2. \t37012801\n",
      "3. \t\t37013338\n",
      "4. \t\t37013511\n",
      "5. \t\t37333801\n",
      " 1. 37011807\n",
      "2. \t37012913\n",
      "3. \t\t37013738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content_gab_m = pd.read_csv('gab_reddit_benchmark/gab_merged.csv')\n",
    "content_gab_m = content_gab_m.drop('Unnamed: 0', axis=1)\n",
    "content_gab_m = content_gab_m.drop('extracted_id', axis=1)\n",
    "\n",
    "\n",
    "content_gab_m[\"text\"] = content_gab_m[\"text\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\") \n",
    "content_gab_m[\"response\"] = content_gab_m[\"response\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\")\n",
    "content_gab_m[\"hate_speech_idx\"] = content_gab_m[\"hate_speech_idx\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\") \n",
    "\n",
    "for index, row in content_gab_m.iterrows():\n",
    "    row['text'] = row['text'].replace(\"'\", '\"')\n",
    "    row['response'] = row['response'].replace(\"'\", '\"')\n",
    "\n",
    "print(content_gab_m.head(n=10))\n",
    "print('\\n- - - - - -\\n')\n",
    "print(content_gab_m.columns)\n",
    "print('\\n- - - - - -\\n')\n",
    "print(content_gab_m.iloc[0]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_text_labels(text_utterances_length, labels):\n",
    "    if not labels:\n",
    "        # return ['other'] * text_utterances_length\n",
    "        return [0] * text_utterances_length\n",
    "    new_labels = []\n",
    "    int_list = ast.literal_eval(labels)\n",
    "    for i in range(text_utterances_length):\n",
    "        if i+1 in int_list:\n",
    "            # new_labels.append('hate_speech')\n",
    "            new_labels.append(1)\n",
    "        else:\n",
    "            # new_labels.append('other')\n",
    "            new_labels.append(0)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting 'text' and 'response' into individual rows, so that I can construct a graph from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          id                                                text                        text_labels                      response                       extracted_id response_labels\n",
      "0                                    1. 39869714\\r\\n  [1. i joined gab to remind myself how retarded...         [1]  [Using words that insult one group while defen...    39869714       [0, 0, 0]  \n",
      "1  1. 39845588\\r\\n2. \\t39848775\\r\\n3. \\t\\t3991101...  [1. This is what the left is really scared of....   [0, 0, 1]  [You can disagree with someones opinion withou...    39845588       [0, 0, 0]  \n",
      "2                   1. 37485560\\r\\n2. \\t37528625\\r\\n  [1. It makes you an asshole., 2. Give it to a ...      [0, 1]  [Your argument is more rational if you leave y...    37485560       [0, 0, 0]  \n",
      "3                   1. 39787626\\r\\n2. \\t39794481\\r\\n  [1. So they manage to provide a whole lot of d...      [0, 1]  [You shouldn't generalize a specific group or ...    39787626       [0, 0, 0]  \n",
      "4  1. 37957930\\r\\n2. \\t39953348\\r\\n3. \\t\\t3996521...  [1. Hi there, i,m Keith, i hope you are doing ...   [0, 0, 1]  [If someone is rude it is better to ignore the...    37957930       [0, 0, 0]  \n",
      "- - - - \n",
      "Index(['id', 'text', 'text_labels', 'response', 'extracted_id', 'response_labels'], dtype='object')\n",
      "1. 39869714\n",
      "\n",
      "[\"1. i joined gab to remind myself how retarded jew haters are. You wouldn't be typing on your abacus without them you retard.\"]\n",
      "[1]\n",
      "[\"Using words that insult one group while defending another group doesn't come across as helpful.\", 'You can make the same point more effectively without the use of hateful terminology.', 'Use of the r-word is unacceptable in our discourse as it demeans and insults people with mental disabilities.']\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "text_column = []\n",
    "text_labels_column = []\n",
    "response_column = []\n",
    "response_labels_column = []\n",
    "\n",
    "for index, row in content_gab.iterrows():\n",
    "    text_utterances = row['text'].split('\\n')\n",
    "    text_utterances = list(filter(None, text_utterances))\n",
    "\n",
    "    for i, t in enumerate(text_utterances):\n",
    "        text_utterances[i] = clean_special_chars(t)\n",
    "    text_labels = mark_text_labels(len(text_utterances), row['hate_speech_idx'])\n",
    "\n",
    "    response_utterances = ast.literal_eval(row['response']) if row['response'] else []\n",
    "    for i, r in enumerate(response_utterances):\n",
    "        response_utterances[i] = clean_special_chars(r)\n",
    "    # response_labels = ['other'] * len(response_utterances)  \n",
    "    response_labels = [0] * len(response_utterances)  \n",
    "\n",
    "    \n",
    "    text_column.append(text_utterances)\n",
    "    text_labels_column.append(text_labels)\n",
    "    response_column.append(response_utterances)\n",
    "    response_labels_column.append(response_labels)\n",
    "\n",
    "content_gab['text'] = text_column\n",
    "content_gab['hate_speech_idx'] = text_labels_column\n",
    "content_gab['response'] = response_column\n",
    "content_gab['response_labels'] = response_labels_column\n",
    "\n",
    "content_gab = content_gab.rename(columns={'hate_speech_idx': 'text_labels'})\n",
    "print(content_gab.head())\n",
    "print('- - - - ')\n",
    "print(content_gab.columns)\n",
    "\n",
    "for index, row in content_gab.iterrows():\n",
    "    if index == 1:\n",
    "        continue\n",
    "    print(row['id'])\n",
    "    print(row['text'])\n",
    "    print(row['text_labels'])\n",
    "    print(row['response'])\n",
    "    print(row['response_labels'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# content_gab['all_labels'] = content_gab['text_labels'] + content_gab['response_labels']\n",
    "# content_gab['all_labels_encoded'] = content_gab['all_labels'].apply(label_encoder.fit_transform)\n",
    "# print(content_gab.iloc[0])\n",
    "# content_gab['text_labels_encoded'] = content_gab['text_labels'].apply(label_encoder.fit_transform)\n",
    "# content_gab['response_labels_encoded'] = content_gab['response_labels'].apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating BERT encoding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def generate_embeddings(sentences):\n",
    "    if isinstance(sentences, list):\n",
    "        return bert.encode(sentences, show_progress_bar=True).tolist()\n",
    "    elif isinstance(sentences, str):\n",
    "        return bert.encode([sentences], show_progress_bar=True).tolist()\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 132.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 114.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 931.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 21.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 398.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 394.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 176.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 128.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 298.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 174.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.84it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 187.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 187.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 356.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 30.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 113.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 161.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 150.74it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 171.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.62it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 436.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 287.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.62it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 444.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 116.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 427.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 573.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.84it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 26.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 139.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 879.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 23.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 60.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 197.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 10.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 204.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 667.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 31.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 394.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 70.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 107.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 106.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 31.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 484.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 110.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 132.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 117.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 225.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 110.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 123.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 108.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 388.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.92it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 115.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 137.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 25.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 110.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 184.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 22.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 25.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 116.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 30.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 175.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 70.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 283.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 536.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 379.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 25.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.023572057485580444, 0.01794440858066082, 0.0405656173825264, 0.06729649752378464, 0.09804009646177292, 0.035114046186208725, 0.06723955273628235, -0.07981331646442413, 0.012592255137860775, -0.06395190209150314, 0.014613417908549309, -0.028686098754405975, 0.06557455658912659, -0.05138685926795006, -0.1029239371418953, 0.015551798976957798, -0.06676264107227325, -0.0029045091941952705, -0.027871334925293922, 0.0603627972304821, -0.027235597372055054, 0.02632732316851616, 0.03128805756568909, 0.017424048855900764, 0.013893608935177326, -0.06276204437017441, -0.013789285905659199, -0.01572624407708645, -0.03531145676970482, -0.05476396158337593, 0.013463081791996956, -0.028276406228542328, -0.03120226040482521, -0.054336175322532654, -0.011610085144639015, -0.04129831865429878, 0.10698013752698898, -0.050249602645635605, -0.02981388196349144, 0.06209121271967888, -0.017547253519296646, -0.01501332875341177, 0.08790478855371475, 0.07822359353303909, -0.09159855544567108, 0.04815983772277832, -0.06916674971580505, 0.05322776734828949, -0.024256447330117226, -0.09537238627672195, -0.03579239547252655, -0.04258187115192413, -0.08481573313474655, 0.031696710735559464, 0.03722597286105156, -0.0579882487654686, -0.059830546379089355, 0.014472158625721931, 0.03947818651795387, 0.014918514527380466, 0.0374993272125721, 0.023774776607751846, 0.03108145482838154, 0.009576061740517616, -0.02806719020009041, -0.0549272745847702, 0.039897371083498, -0.08561886101961136, -0.05795484781265259, 0.08154644817113876, -0.0017612621886655688, 0.01556019764393568, -0.057281170040369034, -0.09787726402282715, 0.013083030469715595, -0.018553076311945915, 0.007453093770891428, -0.019630098715424538, -0.054940689355134964, -0.0953664556145668, 0.026371384039521217, -0.006277969107031822, 0.10078250616788864, -0.012945770286023617, 0.014498650096356869, 0.017524247989058495, -0.04861271753907204, -0.014787748456001282, 0.01737138070166111, 0.05227299779653549, 0.02295733243227005, 0.001686697592958808, 0.07582608610391617, 0.017705759033560753, -0.0015716354828327894, -0.002998440060764551, -0.0462193563580513, 0.024339446797966957, -0.04856687784194946, 0.047270383685827255, -0.016229182481765747, -0.0022451779805123806, 0.0593828521668911, 0.04684929922223091, -0.02564956247806549, 0.01817881129682064, -0.04995886981487274, -0.01995387114584446, -0.06652817130088806, 0.000959291122853756, -0.05363905429840088, -0.018837444484233856, -0.04111718386411667, -0.0021198345348238945, -0.040226440876722336, -0.033901579678058624, 0.017404159530997276, -0.007449411787092686, 0.013669039122760296, 0.03172919526696205, 0.013172303326427937, -0.006265211850404739, 0.017268143594264984, -0.033285729587078094, 0.08197329193353653, -0.06818144023418427, -0.12145192176103592, -5.181774891702452e-33, 0.07206414639949799, -0.10233228653669357, -0.03951829671859741, 0.0013451091945171356, 0.07297976315021515, 0.04217559099197388, -0.08489369601011276, 0.03341776132583618, -0.03820201754570007, 0.033236436545848846, -0.04697813838720322, -0.0037153016310185194, -0.04916464164853096, -0.028877070173621178, 0.0029163137078285217, -0.0770014077425003, 0.03615826740860939, 0.021831408143043518, -0.0713278129696846, -0.056093573570251465, -0.00012905545008834451, 0.10050742328166962, -0.011927759274840355, 0.03246558830142021, 0.0372706800699234, 0.0172326248139143, -0.005269011482596397, 0.024150235578417778, 0.046569254249334335, 0.02438509836792946, -0.12742935121059418, 0.013551454059779644, -0.04947509244084358, -0.029007917270064354, 0.009385428391397, 0.06105904281139374, 0.005882322322577238, -0.054570652544498444, -0.05731366574764252, -0.09142463654279709, -0.029561210423707962, 0.03298034146428108, -0.09254152327775955, 0.014611337333917618, 0.06021145358681679, 0.03362573683261871, -0.017116008326411247, -0.015008974820375443, -0.004058348946273327, 0.021523673087358475, -0.018500056117773056, 0.07692427933216095, 0.07741913199424744, 0.05040502920746803, 0.05784923583269119, -0.07141830027103424, 0.0095024099573493, 0.04143378138542175, -0.04927181825041771, 0.00903945043683052, -0.0006089740199968219, 0.03323495015501976, 0.060909807682037354, -0.055581800639629364, -0.013429153710603714, 0.04045286774635315, -0.018049901351332664, -0.07930324226617813, 0.02816927805542946, 0.04188494384288788, -0.02306269481778145, 0.0070374091155827045, 0.048659682273864746, 0.06050277128815651, -0.04568563401699066, -0.005206800531595945, -0.006128524895757437, 0.024518268182873726, 0.006941821426153183, -0.04208432883024216, 0.0421958863735199, -0.03775396570563316, 0.010521989315748215, 0.0410795696079731, -0.012251405045390129, -0.040389999747276306, 0.012214913964271545, -0.1506490558385849, 0.010156752541661263, 0.03339754790067673, 0.0025313724763691425, -0.022614017128944397, 0.053126584738492966, -0.04465081915259361, -0.05430527403950691, 1.773386777164997e-33, -0.11583428829908371, 0.010014028288424015, -0.04472268000245094, 0.043904632329940796, -0.06872110068798065, 0.02242632769048214, 0.1263907253742218, 0.05892787128686905, 0.061748016625642776, -0.009931759908795357, 0.020472878590226173, 0.02589953877031803, -0.05042511224746704, 0.013905087485909462, -0.010195986367762089, -0.02641150914132595, 0.12776246666908264, 0.006280369125306606, -0.011610600166022778, 0.021490734070539474, -0.052388232201337814, 0.07279004156589508, -0.07466274499893188, 0.14213718473911285, -0.040154829621315, 0.05863190069794655, 0.03182356432080269, -0.020553387701511383, 0.0016153521137312055, -0.05780056118965149, -0.03013593703508377, -0.020728135481476784, 0.04495265707373619, 0.06770161539316177, -0.038545697927474976, -0.03968843072652817, -0.016269374638795853, 0.013275776989758015, 0.04998328909277916, -0.05824997276067734, 0.10717650502920151, -0.01973535120487213, 0.004112995695322752, -0.029574410989880562, -0.05759349465370178, 0.06029912829399109, 0.04811272770166397, 0.08564700186252594, -0.07532630860805511, -0.0437580831348896, -0.014880255796015263, 0.05099138990044594, -0.03473413735628128, -0.019710764288902283, -0.004233859479427338, -0.0840367004275322, -0.049637891352176666, -0.008992845192551613, 0.047729380428791046, 0.1066170185804367, -0.02718396484851837, 0.09788494557142258, -0.06811606884002686, 0.020569635555148125, 0.03360128402709961, -0.05402734875679016, -0.0499679334461689, 0.07933534681797028, 0.04568912461400032, -0.031186381354928017, 0.06635911762714386, 0.0014810968423262239, -0.06889209151268005, -0.042748868465423584, 0.0004744485195260495, -0.029906777665019035, 0.027813278138637543, -0.00603790208697319, 0.021638398990035057, -0.003204121720045805, 0.04991651326417923, -0.0588565468788147, -0.02456951141357422, 0.03823620826005936, 0.07614948600530624, 0.06207279488444328, 0.1086224764585495, 0.003921786788851023, 0.047083284705877304, -0.0036237433087080717, 0.029689164832234383, 0.08975242078304291, -0.016617093235254288, 0.09280365705490112, 0.07856971770524979, -3.2214195755386754e-08, 0.07493723928928375, -0.04131816327571869, -0.00918601080775261, -0.0634353905916214, 0.046850062906742096, 0.060324110090732574, -0.01446310430765152, 0.04866188392043114, -0.11761873960494995, 0.06345327943563461, 0.04961284250020981, 0.038172051310539246, -0.0397590734064579, -0.04137649014592171, -0.06160252168774605, 0.07888319343328476, -0.11216012388467789, -0.01504907850176096, 0.003678123466670513, -0.04987558349967003, 0.013319593854248524, -0.007126920856535435, -0.05422540381550789, -0.030421504750847816, -0.04588665813207626, 0.07505374401807785, -0.1035812571644783, -0.004367319401353598, -0.009592040441930294, 0.06975304335355759, 0.010770153254270554, -0.07311354577541351, -0.03480406105518341, 0.02835475467145443, -0.013685842975974083, -0.026222359389066696, 0.01925831474363804, 0.02957685850560665, 0.042983733117580414, -0.019282333552837372, 0.03362332656979561, -0.02270379476249218, 0.04089226946234703, 0.014580373652279377, -0.10697577893733978, 0.010506035760045052, -0.039530012756586075, -0.10012613236904144, 0.03301755338907242, -0.04779036343097687, -0.029263583943247795, 0.000636313867289573, 0.00781335961073637, 0.08117810636758804, 0.04891378805041313, -0.027057385072112083, 0.012799398973584175, 0.07448851317167282, -0.008968248032033443, 0.07786200940608978, 0.07612894475460052, 0.06673554331064224, -0.03327760845422745, 0.11221782118082047], [-0.09077426791191101, -0.004321129526942968, 0.048581358045339584, 0.01600240357220173, 0.063059963285923, 0.007225271314382553, 0.1289822906255722, 0.03402089700102806, 0.07319037616252899, 0.06843877583742142, 0.004195555113255978, -0.08952050656080246, -0.027654731646180153, -0.054983608424663544, 0.007451079785823822, -0.005147560965269804, -0.07560396194458008, -0.0010118413483723998, 0.01611790619790554, 0.015321220271289349, 0.06880339980125427, 0.027464482933282852, 0.058212801814079285, -0.013553108088672161, -0.045118093490600586, -0.006279462948441505, -0.0068413130939006805, 0.0029208168853074312, -0.03365723788738251, -0.011803730390965939, 0.04119858890771866, -0.04805603623390198, -0.004039316438138485, -0.002998518757522106, -0.08565224707126617, -0.009894272312521935, 0.11572100222110748, -0.027901334688067436, 0.0383949801325798, 0.022395724430680275, -0.018354257568717003, 0.02843811921775341, 0.009978462010622025, 0.00012173593131592497, 0.061500441282987595, 0.062968909740448, -0.02182989940047264, 0.1005239263176918, 0.00426061125472188, -0.09350602328777313, -0.02023398131132126, 0.014279811643064022, -0.0464613102376461, 0.009929378516972065, -0.07782071828842163, 0.06705363094806671, -0.03904207423329353, -0.009611629880964756, 0.04601975530385971, 0.07742089778184891, 0.011429923586547375, -0.0013719657436013222, 0.014855190180242062, 0.04563784971833229, 0.012635408900678158, -0.025114409625530243, -0.05547075346112251, -0.13479098677635193, 0.019971735775470734, 0.04321139305830002, 0.03492508828639984, -0.052899450063705444, 0.010165165178477764, -0.018294615671038628, -0.057120975106954575, -0.14432503283023834, 0.07252795249223709, -0.020182989537715912, -0.006986842956393957, -0.0025313899386674166, -0.05025387555360794, -0.03976421430706978, 0.10722938925027847, 0.01447085291147232, -0.013130540028214455, 0.0941372737288475, -0.0973615050315857, -0.03282913193106651, -0.1397237926721573, 0.02238614670932293, -0.02385745197534561, 0.00989785511046648, 0.09143147617578506, 0.0345420315861702, 0.04380427673459053, 0.0009382412536069751, -0.06505825370550156, 0.07799241691827774, 0.012868504039943218, 0.10730026662349701, -0.019915755838155746, -0.021757127717137337, 0.041546404361724854, -0.008801428601145744, 0.040621932595968246, -0.009801342152059078, -0.04056771844625473, -0.06910770386457443, 0.032480984926223755, -0.03244447335600853, 0.02478601224720478, -0.01928533986210823, -0.04623979330062866, 0.028794879093766212, 0.004943212494254112, 0.0061772963963449, 0.02729879505932331, -0.05179404467344284, -0.05644158273935318, 0.005550819914788008, 0.017456460744142532, 0.04696749150753021, -0.02875385619699955, -0.08048640936613083, 0.03437250107526779, -0.1070290356874466, -0.05876627191901207, -5.352898951191345e-33, -0.006287301890552044, -0.013408520258963108, 0.08930912613868713, -0.03146149218082428, 0.07935462146997452, 0.10619652271270752, -0.05945824459195137, 0.008286995813250542, 0.08319014310836792, 0.06524445116519928, -0.04254871979355812, -0.014957445673644543, -0.09232839941978455, 0.07507062703371048, -0.04178762435913086, 0.06916014850139618, 0.008016485720872879, 0.043761998414993286, -0.05831659585237503, -0.0102305943146348, 0.04148801043629646, 0.044439125806093216, -0.003480916377156973, -0.01428033784031868, -0.04202083498239517, 0.04659470170736313, 0.02901596948504448, -0.04187263175845146, 0.07494302093982697, 0.04662925377488136, -0.06684386730194092, -0.015876440331339836, -0.025631053373217583, -0.014308995567262173, -0.058740127831697464, -0.11437097936868668, 0.08765881508588791, -0.08930796384811401, -0.02531752549111843, 0.010946551337838173, -0.004341466818004847, 0.027367355301976204, -0.052350692451000214, 0.08464670926332474, -0.025068633258342743, 0.04946338012814522, 0.062043800950050354, 0.017245309427380562, 0.0036487241741269827, 0.0818067193031311, 0.044673021882772446, 0.04281897470355034, 0.11324352025985718, 0.032398711889982224, 0.03701508417725563, -0.01307677011936903, -0.0472821407020092, 0.05446520075201988, -0.008659145794808865, 0.011441816575825214, 0.03761905059218407, -0.0072248224169015884, 0.04716646298766136, 0.030068086460232735, 0.052578188478946686, -0.04520205035805702, -0.012098746374249458, -0.016033926978707314, 0.03551924228668213, -0.002098334953188896, 0.0681239441037178, 0.06064704805612564, 0.003167615504935384, -0.06187468394637108, 0.006869085598737001, -0.04608903452754021, 0.009950915351510048, 0.04881925508379936, 0.038603801280260086, 0.01621711440384388, -0.00634901225566864, 0.06591642647981644, 0.014696729369461536, -0.002329253824427724, -0.02188892476260662, -0.01795201748609543, 0.026980668306350708, -0.015907801687717438, -0.025598352774977684, -0.032206375151872635, 0.08449702709913254, -0.022893881425261497, -0.04050298035144806, -0.0730055496096611, -0.030852507799863815, 1.807377114673985e-33, -0.05230112746357918, 0.01419652346521616, -0.044968269765377045, 0.017020784318447113, 0.0036471830680966377, -0.05043288320302963, 0.06829755008220673, 0.025683019310235977, -0.04125538840889931, 0.0013852815609425306, 0.006468631327152252, -0.07029663026332855, -0.009580693207681179, -0.013528102077543736, 0.023790497332811356, -0.036890722811222076, -0.005132612772285938, 0.027188455685973167, -0.02819216437637806, -0.009005936793982983, 0.020995551720261574, -0.0073378970846533775, -0.036337707191705704, 0.016526078805327415, -0.11412344872951508, 0.026558099314570427, 0.02083509974181652, -0.04809976741671562, -0.007241069804877043, 0.0026464120019227266, -0.044935520738363266, 0.0644175186753273, -0.022319423034787178, -0.07922090590000153, 0.06910736858844757, -0.00498548848554492, -0.08609599620103836, -0.003845705185085535, 0.024758044630289078, -0.019033806398510933, 0.04496239125728607, -0.015579553321003914, -0.04503335431218147, -0.043414950370788574, 0.04773915931582451, -0.0810801312327385, -0.024714183062314987, -0.056396860629320145, -0.07916368544101715, 0.01937537081539631, -0.07004602998495102, -0.06934064626693726, -0.04161323979496956, -0.09426996111869812, -0.07260120660066605, -0.03644664213061333, -0.14986597001552582, -0.009570317342877388, 0.04930362477898598, 0.11612330377101898, 0.022939175367355347, -0.04145437479019165, -0.08526183664798737, 0.07278040796518326, -0.0362955704331398, -0.02532808855175972, 0.006364536006003618, 0.08927850425243378, 0.026802847161889076, -0.05549145117402077, 0.0717470645904541, -0.02297559566795826, -0.01257498562335968, -0.015541987493634224, -0.03273480758070946, 0.016138987615704536, 0.04726500064134598, -0.06111883372068405, 0.056073036044836044, 0.01830550841987133, -0.08866332471370697, -0.08189428597688675, 0.03104999288916588, 0.08009018003940582, -0.0035104325506836176, -0.021703621372580528, 0.012455567717552185, 0.03309236839413643, -0.03735201433300972, 0.07492285221815109, 0.06298674643039703, 0.03162549436092377, -0.08552482724189758, 0.054921168833971024, -0.01661379262804985, -2.6253188067926203e-08, -0.005043746903538704, 0.0973062813282013, 0.05342255160212517, -0.018845725804567337, 0.0655365139245987, 0.09893176704645157, -0.04412873089313507, -0.05685996636748314, -0.04830349236726761, -0.032440170645713806, -0.013385062105953693, -0.006123469211161137, -0.025111297145485878, 0.029516924172639847, -0.00611607450991869, 0.08838699758052826, -0.12799589335918427, 0.014528878964483738, -0.01966588944196701, 0.0338340625166893, 0.01370571181178093, 0.03742438554763794, -0.013599760830402374, -0.015512016601860523, -0.03373889997601509, 0.027643835172057152, -0.06709185242652893, 0.11620388180017471, -0.028457509353756905, 0.09794431924819946, 0.025078492239117622, 0.05181735381484032, -0.08401434123516083, -0.0037119262851774693, 0.03724723681807518, -0.09510159492492676, -0.012896780855953693, -0.008086774498224258, 0.009548542089760303, -0.0601385235786438, 0.008680700324475765, -0.002830189187079668, 0.019955022260546684, 0.05506434664130211, 0.053104497492313385, 0.02636396326124668, -0.021042732521891594, -0.07735630124807358, -0.04009256884455681, -0.027792172506451607, -0.027644142508506775, -0.08522052317857742, -0.02516891621053219, 0.1101594865322113, -0.04527197405695915, -0.047056082636117935, -0.01671939343214035, 0.022366860881447792, -0.03911849856376648, -0.003360369708389044, -0.005907749757170677, 0.011773264035582542, -0.04848779737949371, 0.0395224504172802], [0.008080711588263512, -0.09539888799190521, -0.030773358419537544, -0.022631937637925148, -0.07728615403175354, 0.032472867518663406, 0.08644342422485352, -0.01748623326420784, 0.023008596152067184, 0.026931732892990112, -0.012913193553686142, -0.09954977035522461, -0.025455322116613388, -0.06620162725448608, -0.0704817920923233, 0.04873642325401306, -0.07056586444377899, -0.10960452258586884, -0.00981439184397459, -0.0803423523902893, 0.029831750318408012, 0.021925145760178566, 0.09854550659656525, 0.0009720309171825647, 0.0050886026583611965, -0.035403184592723846, 0.012405410408973694, -0.022730467841029167, -0.027505310252308846, -0.002322605811059475, -0.011340518482029438, 0.05622837319970131, 0.02918357588350773, -0.014123586937785149, -0.011095233261585236, -0.038050513714551926, -0.04091372340917587, 0.032156046479940414, -0.005078315734863281, 0.05239526182413101, 0.028330672532320023, -0.06980035454034805, 0.036486219614744186, 0.02715999074280262, 0.04318193718791008, -0.038291025906801224, 0.03963205963373184, -0.027299772948026657, 0.01866263523697853, -0.051943860948085785, 0.016716858372092247, 0.07359474152326584, -0.032110586762428284, 0.0520259328186512, -0.003587504383176565, -0.07705038040876389, -0.049507979303598404, 0.03334396705031395, -0.05955389142036438, 0.06343350559473038, 0.07417023181915283, -0.04209043085575104, 0.0030464634764939547, -0.011782951653003693, 0.051098957657814026, -0.0001350410602753982, -0.08637798577547073, -0.12473417073488235, -0.04188784211874008, 0.07785394787788391, 0.03680673986673355, 0.04839127138257027, 0.00613388093188405, -0.024020614102482796, -0.02700227126479149, -0.05617436021566391, 0.022975469008088112, -0.0688067376613617, 0.03747405484318733, 0.025554560124874115, -0.056267786771059036, 0.07052543759346008, 0.018991312012076378, 0.04184054955840111, -0.0028655303176492453, -0.07721622288227081, 0.025495855137705803, 0.009666228666901588, -0.0731314867734909, 0.08246062695980072, 0.06467888504266739, 0.010289357975125313, 0.14305506646633148, 0.048000648617744446, -0.03249433636665344, 0.023189904168248177, 0.015835512429475784, -0.03490106388926506, -0.04355061054229736, 0.07404258847236633, 0.03346407413482666, 0.10190625488758087, 0.0360240675508976, 0.03428279608488083, 0.09003105759620667, 0.07280085235834122, 0.02414071187376976, 0.020896954461932182, -0.09953875094652176, 0.009472835808992386, -0.05451289936900139, -0.07355302572250366, 0.06916225701570511, -0.0020785978995263577, -0.03501376882195473, 0.06568204611539841, 0.03277268260717392, 0.04597487300634384, 0.08742585778236389, -0.07478149980306625, 0.10328702628612518, -0.031894050538539886, 0.012014864943921566, 0.007906675338745117, -0.032022442668676376, -0.05379030108451843, -0.0037271471228450537, 1.8279231028874276e-34, 0.0050093187019228935, 0.03918766975402832, -0.02847474254667759, 0.04069356992840767, 0.04589221253991127, 0.04610351473093033, -0.026543304324150085, -0.048183612525463104, 0.02088586799800396, -0.0020288110245019197, 0.0816764235496521, -0.01139878947287798, 0.00022294383961707354, -0.001890053739771247, 0.02073173224925995, 0.027862954884767532, 0.017902810126543045, 0.08875707536935806, 0.014715389348566532, -0.07468044757843018, -0.048698876053094864, 0.07993558794260025, -0.06348960846662521, 0.0655917152762413, -0.04011177271604538, -0.005668213590979576, 0.007279981393367052, -0.05056377872824669, -0.012413766235113144, -0.002010062336921692, 0.008123446255922318, 0.046994682401418686, 0.05535564199090004, 0.02034623920917511, -0.0012217710027471185, -0.10184323787689209, 0.10169916599988937, -0.034093618392944336, -0.0309029258787632, 0.008021282963454723, -0.01502931397408247, 0.0008118023397400975, 0.046915724873542786, 0.012176107615232468, 0.054647140204906464, 0.04477979615330696, -0.009253396652638912, -0.008242934010922909, 0.009977003559470177, 0.017530161887407303, 0.010699549689888954, 0.03754172846674919, 0.05122923478484154, 0.06261452287435532, 0.025533275678753853, -0.0037065905053168535, 0.06957687437534332, -0.010279888287186623, 0.02615094929933548, 0.0020822437945753336, 0.0038684711325913668, -0.020775988698005676, 0.012700295075774193, -0.04121045023202896, -0.08708054572343826, -0.05266943201422691, -0.04988298565149307, 0.04015504568815231, 2.3344787223322783e-06, 0.0674474909901619, -0.02008383721113205, 0.0499715581536293, -0.0674726590514183, -0.08824130147695541, -0.035174135118722916, -0.06264480948448181, 0.04031972587108612, -0.02248426340520382, -0.03776630014181137, -0.12003500014543533, -0.016910450533032417, 0.09409449994564056, -0.020762139931321144, 0.05564181134104729, -0.06826725602149963, 0.03621707111597061, -0.03261701762676239, -0.06822937726974487, 0.09408803284168243, -0.0367269329726696, -0.021736176684498787, 0.009966426528990269, 0.023078233003616333, -0.008611335419118404, -0.0619976669549942, 8.941951547571563e-34, 0.00036352992174215615, 0.012690436094999313, 0.026589035987854004, 0.06478539109230042, 0.02548210322856903, 0.02860984206199646, 0.0012570017715916038, 0.05658910050988197, 0.0781116709113121, 0.020748967304825783, 0.016074134036898613, -0.05106382817029953, 0.03079255484044552, -0.056950632482767105, 0.12897665798664093, 0.008377077989280224, 0.05113306641578674, -0.031216779723763466, -0.045274753123521805, -0.004246346186846495, 0.04971003904938698, -0.03990734741091728, -0.02811526693403721, 0.04774903878569603, -0.049286723136901855, 0.07545077055692673, -0.03053143434226513, -0.07274259626865387, 0.015440759249031544, -0.0017576440004631877, 0.03929729759693146, -0.045735422521829605, 0.03634228557348251, 0.03500661998987198, 0.0062796282581985, -0.017700696364045143, 0.0714467316865921, 0.040730610489845276, -0.0394870862364769, 0.07122262567281723, 0.11299610882997513, -0.013451826758682728, 0.017438828945159912, 0.030202679336071014, -0.005799288395792246, -0.00021199458569753915, 0.04479778930544853, 0.02060711570084095, -0.05177623778581619, 0.039304252713918686, -0.06698282063007355, -0.02119085192680359, -0.08656778186559677, -0.029952237382531166, 0.023406168445944786, -0.010621941648423672, -0.00694050220772624, -0.02704007364809513, 0.0721914991736412, -0.023389747366309166, -0.0023735947906970978, -0.01837790198624134, -0.001989508979022503, 0.03238983824849129, 0.021187754347920418, -0.03936571255326271, -0.08798239380121231, 0.136001855134964, -0.06605536490678787, -0.06085571274161339, -0.04243520647287369, 0.09640292078256607, 0.04086538404226303, -0.09723318368196487, 0.006801843177527189, -0.008721238933503628, -0.09353083372116089, 0.0005397840868681669, 0.007901034317910671, 0.05311150848865509, -0.10052897781133652, -0.03189704194664955, 0.03413189575076103, 0.0037660994566977024, -0.04544129595160484, -0.03456147015094757, 0.18371503055095673, -0.005453404039144516, 0.039594415575265884, -0.025877341628074646, 0.04954717680811882, 0.025953145697712898, -0.02908100187778473, 0.03526001051068306, -0.005633258726447821, -1.9027325492970704e-08, 0.01245121005922556, 0.05363508313894272, -0.03357085958123207, -0.07271043956279755, -0.008326188661158085, 0.05630642548203468, -0.0463874451816082, 0.08589570224285126, 0.04216998443007469, 0.03112049587070942, 0.057772446423769, -0.03909040614962578, 0.014506219886243343, 0.022036977112293243, -0.04963081702589989, 0.06102835014462471, 0.017512403428554535, 0.011143183335661888, -0.014998376369476318, 0.020809488371014595, -0.012584054842591286, 0.020533466711640358, -0.016007278114557266, 0.04199577495455742, -0.05905057489871979, 0.08003123849630356, -0.054228730499744415, 0.09618335217237473, -0.044407665729522705, 0.07981469482183456, -0.004549198783934116, 0.02889895811676979, -0.05525488033890724, -0.049912940710783005, 0.019717350602149963, 0.002761115552857518, -0.011931728571653366, -0.052367448806762695, 0.018666556105017662, 0.08221228420734406, 0.015605738386511803, -0.02665865607559681, -0.027583174407482147, -0.0503116250038147, -0.028661265969276428, -0.010513977147638798, -0.07250862568616867, -0.0686410516500473, -0.08933313935995102, -0.130082368850708, -0.07196871191263199, -0.009833923541009426, 0.02290228195488453, 0.07230091094970703, 0.14229951798915863, -0.0970807895064354, -0.03360007703304291, -0.006086405366659164, -0.10948299616575241, -0.017041537910699844, 0.028167875483632088, 0.03441556170582771, 0.011432717554271221, 0.0065767802298069]]\n",
      "\n",
      "TIME FOR TEXT EMBEDDINGS:  6.422522068023682\n",
      "\n",
      "- - - - - -\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 658.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 106.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 634.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 155.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.20it/s]\n",
      "Batches: 0it [00:00, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 248.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.47it/s]\n",
      "Batches: 0it [00:00, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 70.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 144.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 456.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 154.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 277.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 439.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 534.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 627.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 107.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 276.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 771.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 420.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 245.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 167.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 219.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 243.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 110.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 367.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 417.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 548.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 296.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 131.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 373.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 188.37it/s]\n",
      "Batches: 0it [00:00, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 365.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 528.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 31.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.05it/s]\n",
      "Batches: 0it [00:00, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 117.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 271.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 109.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 116.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 261.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 140.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 263.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 126.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.62it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 272.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 180.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 588.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.36it/s]\n",
      "Batches: 0it [00:00, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 351.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 161.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 206.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 153.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 349.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 657.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 434.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 146.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 152.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 439.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 543.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 152.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 163.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 332.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 503.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.15it/s]\n",
      "Batches: 0it [00:00, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 144.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 593.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 112.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 117.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.49it/s]\n",
      "Batches: 0it [00:00, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 149.93it/s]\n",
      "Batches: 0it [00:00, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 266.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 135.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 188.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 578.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.96it/s]\n",
      "Batches: 0it [00:00, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 148.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 145.36it/s]\n",
      "Batches: 0it [00:00, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.84it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 152.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09269341826438904, 0.0053440057672560215, -0.021850084885954857, -0.0007701154099777341, 0.04873264953494072, 0.028574705123901367, 0.06419847160577774, -0.009560780599713326, 0.053361181169748306, -0.0879056453704834, -0.014494847506284714, -0.0013367488281801343, 0.0982813909649849, -0.013169684447348118, 0.03653031960129738, 0.08743903785943985, 0.05540039762854576, 0.001535855932161212, -0.03637176379561424, 0.00894644483923912, -0.08317050337791443, 0.09316875785589218, -0.046798184514045715, -0.020233850926160812, -0.0499594546854496, -0.0417790450155735, -0.015589868649840355, 0.033974144607782364, -0.014390970580279827, 0.1086299866437912, 0.020122447982430458, -0.013854089193046093, 0.04655636101961136, 0.014802754856646061, 0.0009073888068087399, -0.0037359357811510563, 0.00721629848703742, 0.047422803938388824, 0.015439050272107124, 0.013636752963066101, 0.012506725266575813, 0.008980403654277325, -0.002120441058650613, -0.07505074888467789, -0.0013401504838839173, -0.0007081580115482211, -0.03652456775307655, 0.029818832874298096, 0.026721274480223656, -0.08640063554048538, -0.08417931944131851, 0.006127768661826849, -0.059236589819192886, 0.05942682549357414, 0.005135268904268742, 0.0057946257293224335, -0.007825972512364388, 0.11261799186468124, -0.020295370370149612, 0.028986863791942596, 0.05184929072856903, -0.02701093629002571, -0.002103114500641823, -0.04580675810575485, 0.012710793875157833, 0.09872577339410782, 0.03393743559718132, 0.06304049491882324, -0.07262536138296127, 0.07092614471912384, -0.046225689351558685, 0.10023762285709381, 0.11196377128362656, 0.01841040328145027, -0.0037346261087805033, -0.014729264192283154, 0.02416234090924263, -0.04097258299589157, 0.04131739214062691, -0.022084109485149384, -0.016477545723319054, -0.012203256599605083, -0.04959903284907341, -0.0759759172797203, -0.017102191224694252, -0.0021037363912910223, 0.04519075155258179, -0.018981702625751495, 0.013932647183537483, 0.02007799968123436, 0.006097547244280577, 0.03774693235754967, 0.019818266853690147, -0.05266401544213295, 0.06843788176774979, -0.045102011412382126, -0.12242233008146286, 0.04205157607793808, -0.023320388048887253, 0.04568549618124962, 0.017341947183012962, -0.014790158718824387, -0.027331937104463577, -0.017455192282795906, 0.07769674807786942, -0.020747004076838493, -0.08738737553358078, -0.03205586224794388, -0.09111244231462479, 0.03686106950044632, -0.03311072662472725, -0.040134649723768234, -0.016983695328235626, -0.004547488410025835, 0.03450160473585129, 0.07777281105518341, 0.08191961795091629, 0.0609041228890419, -0.02624419517815113, 0.008872183971107006, 0.03701314330101013, 0.04779651015996933, -0.026972465217113495, 0.15925352275371552, -0.027176465839147568, -0.07614260911941528, -0.0623168908059597, -2.571606032419879e-33, -0.04442668333649635, 0.007310524582862854, -0.03771062195301056, -0.032474834471940994, 0.019967909902334213, -0.030969103798270226, -0.0846376121044159, -0.059568099677562714, 0.09636640548706055, -0.011295563541352749, -0.03427683934569359, -0.03152262791991234, 0.048911161720752716, 0.00795748457312584, 0.059126704931259155, 0.020901089534163475, -0.03965403884649277, 0.062448401004076004, -0.01772821694612503, -0.06113921478390694, 0.01283897366374731, -0.021642884239554405, -0.02302018366754055, 0.005752349738031626, -0.061735428869724274, -0.14628490805625916, 0.051892977207899094, -0.0004944919492118061, -0.02375756949186325, 0.011434944346547127, -0.09186822175979614, -0.07906457036733627, -0.007517629768699408, -0.007253993768244982, 0.046002645045518875, -0.014169986359775066, 0.0404745489358902, 0.048691265285015106, -0.009246019646525383, -0.07348710298538208, 0.010274077765643597, 0.08677572011947632, -0.026179958134889603, -0.02140418253839016, 0.11437877267599106, 0.060243017971515656, 0.010301604866981506, -0.009255919605493546, -0.06202416494488716, -0.04021847993135452, 0.00999785028398037, -0.009421605616807938, 0.024818090721964836, 0.05408206209540367, -0.04078041762113571, -0.022144027054309845, -0.05682731792330742, 0.04081587865948677, 0.04387408494949341, -0.005246262066066265, -0.10526284575462341, 0.11851855367422104, -0.024268455803394318, 0.039799537509679794, 0.013352434150874615, -0.007793794851750135, -0.059014320373535156, -0.014424859546124935, -0.04775916039943695, -0.05760326236486435, 0.11392092704772949, -0.016051694750785828, 0.02120901085436344, 0.047993697226047516, 0.00950564257800579, -0.04933144897222519, -0.023286424577236176, 0.0020123100839555264, 0.11531011760234833, -0.01627109758555889, 0.13887867331504822, 0.03264710679650307, -0.05117448791861534, -0.03816383332014084, 0.003204388776794076, -0.01596912555396557, 0.056390903890132904, -0.0390876829624176, 0.08742181211709976, -0.015590048395097256, -0.030634690076112747, 0.036289479583501816, -0.024919982999563217, -0.0565137080848217, -0.11102382838726044, 6.07695911475323e-34, -0.06599244475364685, -0.008227706886827946, 0.04425226151943207, 0.08388872444629669, -0.11768152564764023, 0.08831866830587387, -0.018532615154981613, 0.00573795847594738, 0.06345853209495544, 0.031013382598757744, 0.026527516543865204, -0.01932409219443798, 0.006759768817573786, 0.009838076308369637, 0.02678844891488552, -0.10548337548971176, -0.02655034139752388, -0.033559657633304596, -0.07796969264745712, -0.020896222442388535, -0.03958204761147499, 0.07856205105781555, -0.020350858569145203, 0.02547948993742466, -0.03126655891537666, -0.07198557257652283, 0.11346634477376938, -0.017934385687112808, 0.10661368072032928, -0.07247737050056458, 0.004973030183464289, 0.028926946222782135, -0.0814918801188469, -0.06507786363363266, -0.006710114423185587, -0.03185907378792763, -0.0954732596874237, 0.0763862133026123, -0.017990341410040855, -0.027803512290120125, -0.03189041465520859, 0.000696527655236423, -0.032402828335762024, -0.13260947167873383, -0.05504116415977478, -0.047219108790159225, 0.07467764616012573, -0.02727321721613407, 0.02574571967124939, -0.008881310932338238, -0.050859928131103516, -0.02258465811610222, 0.10509802401065826, 0.025873644277453423, -0.029957370832562447, -0.052439745515584946, 0.07640969753265381, -0.016877632588148117, -0.08452364057302475, -0.07604217529296875, 0.003783182241022587, 0.010043874382972717, -0.02630266174674034, -0.05206344276666641, 0.08440504223108292, -0.0640454888343811, -0.09405899792909622, 0.005777672864496708, 0.07394685596227646, -0.03362569585442543, -0.03526245057582855, 0.01594538800418377, -0.04790881648659706, 0.025151239708065987, -0.039317019283771515, 0.01596958376467228, -0.027216045185923576, 0.005253609735518694, 0.025195622816681862, 0.0009437703993171453, 0.05801168829202652, 0.01321752741932869, 0.037789832800626755, 0.0008823853568173945, -0.03796041011810303, -0.06345684826374054, -0.0011166606564074755, -0.04156646877527237, 0.023284509778022766, 0.011803616769611835, 0.06208194047212601, -0.023282505571842194, 0.024088546633720398, -0.017585212364792824, 0.01568574272096157, -2.9682279745202322e-08, 0.010659562423825264, -0.05633000284433365, 0.07712181657552719, 0.05101722851395607, -0.011079982854425907, -0.0005807302077300847, 0.002367499051615596, -0.018592074513435364, 0.03200189024209976, 0.04977916181087494, -0.052581291645765305, -0.04296502098441124, -0.03333304449915886, 0.020073171705007553, -0.08089343458414078, 0.07841379195451736, 0.08487144112586975, -0.13421697914600372, 0.03482995182275772, -0.04534032195806503, 0.008037547580897808, 0.05420053005218506, -0.030730189755558968, 0.024961791932582855, 0.011558441445231438, 0.025057030841708183, 0.04879523813724518, -0.029437728226184845, -0.023896215483546257, 0.02489546872675419, 0.04927957430481911, 0.011983109638094902, -0.1202002763748169, 0.005318854469805956, 0.016125252470374107, 0.00445230957120657, -0.08056430518627167, 0.0176426712423563, 0.03630785644054413, 0.08196452260017395, -0.025738423690199852, 0.04738207161426544, 0.03808915242552757, -0.00514637678861618, -0.0029029378201812506, -0.04597635567188263, 0.008389142341911793, -0.03481914475560188, -0.040013428777456284, 0.013514876365661621, 0.07065839320421219, -0.004429492633789778, 0.04025430604815483, -0.037400372326374054, 0.08259782940149307, 0.029114387929439545, 0.003579111769795418, -0.00880461186170578, -0.05012710019946098, 0.04007803276181221, 0.03561469912528992, 0.07238143682479858, 0.019006839022040367, 0.004914341028779745], [0.042391158640384674, 0.06892797350883484, -0.012829643674194813, 0.022921059280633926, -0.031988516449928284, -0.039736200124025345, -0.013293083757162094, -0.009726449847221375, 0.10041040182113647, -0.04075906053185463, 0.05534392222762108, -0.009186570532619953, 0.10898082703351974, 0.014859150163829327, 0.02183174341917038, 0.07840778678655624, 0.0595310777425766, 0.09031140804290771, -0.0017572760116308928, 0.0333414152264595, 0.03440377861261368, -0.010233302600681782, -0.00550819281488657, 0.06482840329408646, -0.04752611741423607, -0.06029044836759567, -0.035957422107458115, 0.0989808440208435, 0.01041746512055397, 0.09730382263660431, 0.010743072256445885, 0.024951502680778503, -0.052936047315597534, 0.04062076285481453, -0.053609639406204224, -0.04439689591526985, 0.0011169719509780407, 0.08049368113279343, -0.01614558696746826, -0.09232457727193832, 0.005971087608486414, -0.03063451498746872, -0.0668906643986702, -0.015797074884176254, -0.08515521138906479, -0.01634185016155243, 0.055997271090745926, 0.00024009484332054853, -0.0015571204712614417, -0.061006058007478714, -0.07788405567407608, -0.00728041073307395, -0.09796082228422165, -0.0033349134027957916, 0.014183804392814636, -0.007687231060117483, -0.051015689969062805, 0.09605483710765839, -0.004167805891484022, 0.03168301656842232, -0.013458545319736004, 0.04018283635377884, 0.00495762936770916, 0.01872016303241253, 0.039810195565223694, -0.019506094977259636, 0.014330861158668995, 0.019947361201047897, -0.08653587102890015, 0.10226568579673767, -0.020608076825737953, 0.07482314109802246, 0.1392129510641098, 0.04058516025543213, -0.03484807908535004, -0.008807645179331303, -0.015144060365855694, 0.03913532570004463, -0.022510582581162453, -0.004130078013986349, -0.068105548620224, 0.060463182628154755, 0.023172276094555855, 0.009624551981687546, 0.006095971912145615, 0.035916704684495926, 0.02094644494354725, -0.04225621744990349, 0.031852006912231445, -0.030812256038188934, -0.0917266383767128, -0.009825976565480232, 0.11844398826360703, -0.07484187930822372, 0.07271211594343185, -0.09946554154157639, -0.01505451649427414, 0.036050599068403244, -0.05158247426152229, 0.049462903290987015, 0.005246560089290142, 0.0020478572696447372, -0.07226932793855667, -0.030025212094187737, 0.0012676932383328676, -0.05315446853637695, -0.08411944657564163, -0.027568217366933823, -0.05262221023440361, -0.0979183167219162, -0.09486529231071472, -0.022862296551465988, 0.019658539444208145, -0.06677854061126709, 0.04014856368303299, -0.026300683617591858, 0.03908589482307434, 0.04480909928679466, 0.08304345607757568, -0.015867717564105988, 0.025671357288956642, -0.03430228680372238, -0.008837081491947174, 0.10396873950958252, 0.06083481386303902, -0.03947160765528679, -0.053554873913526535, -1.674769780628715e-33, -0.019451893866062164, 0.08432461321353912, 0.02281729318201542, 0.00654288986697793, -0.06658325344324112, -0.004636063240468502, -0.0479559563100338, 0.06363356113433838, 0.0978030189871788, -0.011961806565523148, 0.05763581022620201, -0.010652433149516582, 0.08791428059339523, 0.03254753723740578, 0.08301316946744919, 0.02048836089670658, -0.03641008585691452, 0.06959374248981476, 0.020071782171726227, -0.004830540623515844, 0.05332473665475845, -0.010593758895993233, -0.030535414814949036, -0.02252158708870411, -0.03259887173771858, -0.08948793262243271, 0.014341404661536217, 0.03988242149353027, 0.016171716153621674, 0.000991524662822485, -0.047749124467372894, -0.05678432062268257, 0.022112753242254257, -0.01710517518222332, 0.09063870459794998, -0.05110383406281471, 0.043428849428892136, 0.04757951945066452, -0.016882842406630516, -0.05453913286328316, 0.01638788729906082, 0.052501481026411057, -0.05529896169900894, -0.003732281271368265, 0.05874672532081604, 0.0991571918129921, 0.08661498129367828, -0.07828595489263535, 0.021427471190690994, -0.004860807675868273, 0.08748242259025574, 0.0006012170924805105, 0.08024862408638, 0.0529700443148613, -0.026026947423815727, -0.03469552844762802, -0.055124443024396896, 0.028124617412686348, -0.002097957767546177, 0.00897535402327776, -0.09244364500045776, 0.06195404380559921, -0.024523138999938965, 0.04758518561720848, 0.015433593653142452, -0.03904943913221359, -0.02027197740972042, 0.07893203943967819, -0.013554233126342297, -0.05646128952503204, 0.08298981934785843, -0.005623190198093653, -0.03806411847472191, 0.0022033601999282837, -0.033741097897291183, -0.0532667376101017, 0.00014694640412926674, 0.08186452835798264, 0.11419802159070969, -0.03600406274199486, 0.03566611930727959, -0.009456820785999298, -0.00453045591711998, -0.06371422857046127, -0.06926040351390839, 0.0032274755649268627, 0.07997225970029831, -0.03826358541846275, 0.061580002307891846, -0.05032937601208687, -0.048905014991760254, 0.0004105539701413363, -0.05572087690234184, 0.038861848413944244, -0.12815150618553162, 7.785826221243957e-34, -0.0620470866560936, -0.09857077151536942, -0.003074552398175001, 0.10212291777133942, -0.04457705095410347, 0.025363527238368988, -0.02196989394724369, -0.041382450610399246, 0.05155045911669731, 0.07402733713388443, 0.03752955421805382, -0.03085128404200077, -0.0724661648273468, -0.008286280557513237, 0.03220491483807564, -0.07615527510643005, -0.02050420641899109, -0.019862612709403038, -0.1005212813615799, 0.05088134855031967, -0.02343102917075157, 0.0962766483426094, -0.09565430134534836, 0.016985710710287094, 0.009336676448583603, -0.03730770945549011, 0.0517050102353096, 0.005356883630156517, -0.013238655403256416, -0.06268025934696198, 0.0012461227597668767, 0.028150999918580055, -0.02499799244105816, -0.05768612399697304, -0.05247628688812256, -0.04090118408203125, -0.015466129407286644, 0.049107570201158524, 0.0032370316330343485, -0.02469918131828308, 0.03777908906340599, 0.016371101140975952, -0.08349846303462982, -0.03191877901554108, 0.003874043934047222, -0.038908470422029495, -0.008297929540276527, -0.05644872784614563, 0.06771368533372879, 0.004304153844714165, -0.08550671488046646, -0.07297290861606598, -0.052355945110321045, -0.020406218245625496, -0.030583763495087624, -0.05975541099905968, 0.06802108883857727, -0.04854077845811844, -0.04969286918640137, -0.04142278432846069, 0.021468371152877808, -0.0619548074901104, -0.03828996419906616, 0.05977611988782883, 0.05406440794467926, -0.025965021923184395, -0.05721611529588699, -0.026482341811060905, 0.08805742859840393, -0.016507096588611603, -0.06097770109772682, -0.01021626777946949, -0.03592361882328987, -0.017445409670472145, -0.054157838225364685, -0.043243657797575, 0.0461965911090374, -0.03868399187922478, -0.033561620861291885, 0.03765648230910301, 0.005395061802119017, -0.065399669110775, -0.014689349569380283, -0.006559269968420267, -0.0444263331592083, -0.006270509213209152, -0.03859391435980797, 0.04986265301704407, 0.023595457896590233, -0.008817165158689022, -0.013707509264349937, -0.03578471764922142, 0.031375739723443985, 0.03396362066268921, 0.024212786927819252, -2.8516787153876066e-08, -0.0488642118871212, -0.030507277697324753, 0.10325787961483002, 0.1082780510187149, -0.022523600608110428, 0.014312464743852615, -0.030158108100295067, 0.010144272819161415, 0.013477249071002007, 0.014159051701426506, 0.005809408612549305, -0.07157707214355469, -0.0633188784122467, 0.0021550734527409077, -0.052119359374046326, 0.06510463356971741, 0.0931762233376503, -0.006258736830204725, 0.029944948852062225, 0.07327685505151749, -0.05019056051969528, 0.07659517228603363, -0.031982775777578354, 0.024883108213543892, 0.04175812005996704, -0.04858547821640968, 0.03648795187473297, -0.029131198301911354, 0.026969360187649727, -0.03355111554265022, -0.009886183775961399, 0.0021693864837288857, -0.057865578681230545, 0.061013348400592804, 0.029211759567260742, 0.05330391228199005, -0.08926509320735931, 0.07885832339525223, 0.0333186574280262, 0.025669503957033157, -0.02933702990412712, 0.06813660264015198, 0.07020706683397293, -0.016331816092133522, 0.0749734491109848, 0.03991148993372917, -0.014953013509511948, 0.027499660849571228, -0.0209356639534235, -0.05608295649290085, 0.07501430064439774, 0.052288297563791275, -0.024663159623742104, 0.011798178777098656, 0.09885257482528687, -0.028668981045484543, 0.013835479505360126, 0.025909533724188805, -0.037930928170681, 0.10386262089014053, 0.09220705181360245, -0.02454002946615219, 0.04758811742067337, 0.009064510464668274], [0.03910248726606369, 0.007743379566818476, -0.022013172507286072, -0.015991592779755592, -0.021642761304974556, -0.04806598275899887, -0.0029944228008389473, -0.04200822487473488, -0.008370015770196915, -0.041180990636348724, 0.01890300028026104, 0.06546343863010406, 0.032653097063302994, -0.049915723502635956, 0.03711460530757904, 0.00011842587264254689, -0.010946976952254772, 0.0014798205811530352, 0.009033866226673126, 0.05914038047194481, 0.13843844830989838, 0.06440231949090958, 0.020374886691570282, -0.03613514453172684, -0.045861225575208664, -0.020132947713136673, 0.04883328452706337, -0.004101731348782778, 0.014790377579629421, 0.07851654291152954, -0.025900373235344887, -0.03564813360571861, -0.03266479820013046, 0.006301163230091333, -0.08119019865989685, -0.017555993050336838, 0.011737787164747715, 0.0014237764989957213, 0.10744474083185196, 0.027540113776922226, -0.02289855107665062, -0.07348616421222687, -0.06519411504268646, -0.07355977594852448, 0.010595712810754776, 0.0005711850826628506, -0.048158060759305954, 0.004148161504417658, -0.06206366419792175, -0.05449174717068672, 0.01497486513108015, -0.02552901953458786, 0.055208638310432434, 0.012727928347885609, 0.017470352351665497, 0.019451798871159554, -0.017539897933602333, -0.05671161413192749, 0.011829097755253315, -0.037559255957603455, 0.0006529812817461789, -0.014763140119612217, 0.009313817135989666, -0.012957392260432243, -0.0008687779773026705, -0.06957236677408218, 0.018814049661159515, -0.002321289386600256, -0.03826155513525009, 0.11319079250097275, -0.10528168082237244, 0.04112430289387703, 0.04267843812704086, 0.09569410979747772, -0.0909866914153099, -0.011651422828435898, 0.0032898844219744205, 0.05039919912815094, 0.05704126134514809, -0.030547751113772392, 0.09166644513607025, -0.012251104228198528, 0.0959925577044487, -0.00030556702404282987, 0.009918403811752796, -0.029934249818325043, -0.010460259392857552, -0.006370853632688522, 0.019265862181782722, 0.058236461132764816, -0.08773978054523468, 0.031304746866226196, 0.08434274047613144, -0.027542345225811005, 0.02996773086488247, -0.13131295144557953, -0.06263111531734467, 0.06378242373466492, -0.11692158132791519, 0.05032459273934364, -0.004831964615732431, 0.06255693733692169, -0.007171470671892166, -0.003189775627106428, 0.03480357676744461, 0.005655177868902683, -0.06753607839345932, -0.06222197040915489, -0.07642144709825516, 0.016786159947514534, -0.10606078058481216, -0.020534951239824295, -0.016881238669157028, 0.0013107472332194448, 0.08634880185127258, -0.015982741490006447, 0.08382797241210938, -0.0030687747057527304, -0.11268371343612671, 0.005623610224574804, -0.04542319104075432, 0.007046777755022049, -0.03411845490336418, 0.0833304226398468, 0.05051172897219658, -0.0621233768761158, -0.056229542940855026, -1.970242591664382e-33, 0.009972771629691124, 0.03417760133743286, -0.026245778426527977, 0.0022494306322187185, -0.04703250154852867, 0.0363503135740757, -0.008383491076529026, 0.015500372275710106, 0.027656231075525284, -0.014749142341315746, 0.08827196806669235, 0.00786826852709055, -0.012634256854653358, -0.006944708991795778, -0.04178592562675476, 0.07454120367765427, 0.038818489760160446, 0.07198683172464371, -0.004308544099330902, -0.025936802849173546, 0.0439235083758831, -0.005510827526450157, 0.024246301501989365, -0.00801146775484085, -0.13651539385318756, -0.08252845704555511, 0.029965396970510483, -0.015615923330187798, 0.051095739006996155, 0.02376299537718296, -0.020013177767395973, -0.033410053700208664, 0.0455818809568882, -0.009435866959393024, 0.05869221314787865, -0.0562688484787941, 0.08645408600568771, -0.007330899592489004, -0.0897291898727417, 0.04107815772294998, 0.014463940635323524, 0.020716028288006783, 0.036140359938144684, -0.03991485759615898, -0.044708915054798126, 0.16271542012691498, 0.07835033535957336, -0.04905468225479126, 0.01732145994901657, 0.04628936946392059, 0.0341867133975029, 0.08108880370855331, 0.020181043073534966, 0.0944700762629509, 0.019679447636008263, -0.02827855572104454, -0.037433017045259476, 0.01393609493970871, 0.0025936735328286886, -0.06163507327437401, -0.04462888091802597, 0.006370189134031534, 0.0515829436480999, -0.08064811676740646, -0.005140361376106739, 0.03468073904514313, -0.08304306864738464, 0.06124046817421913, -0.05047176405787468, 0.018608974292874336, -0.006359109189361334, -0.04372202232480049, 0.008152446709573269, 0.09087321162223816, -0.017212623730301857, -0.007383438292890787, 0.019339963793754578, 0.002408725442364812, 0.1494971513748169, 0.016482938081026077, 0.02501864731311798, -0.03227046877145767, -0.056810520589351654, -0.10758624225854874, -0.06724727153778076, -0.05820336192846298, 0.004688503220677376, -0.05842401087284088, 0.05491294339299202, 0.004966605454683304, -0.10002332925796509, 0.04028064385056496, -0.06528265029191971, -0.07129672169685364, -0.08578094840049744, -7.346439289876048e-34, 0.01502203568816185, -0.04380141198635101, -0.03651130571961403, 0.12815696001052856, -0.0051934788934886456, 0.040540557354688644, 0.09960878640413284, -0.029112648218870163, 0.0453350804746151, 0.057524193078279495, 0.0025075033772736788, -0.07275515794754028, 0.015495717525482178, -0.040265779942274094, 0.17449899017810822, 0.02553965151309967, 0.0019904598593711853, -0.05837472528219223, 0.019099626690149307, -0.004833586979657412, 0.05545734241604805, 0.07378887385129929, -0.03095174953341484, 0.006717441137880087, -0.0006808983744122088, -0.01739221252501011, 0.025430358946323395, -0.030652500689029694, 0.00512947840616107, -0.05232049524784088, 0.002514809835702181, 0.0405881404876709, -0.001207858556881547, -0.049782320857048035, -0.021315908059477806, 0.003512077033519745, 0.05702337250113487, 0.11029922217130661, -0.02548973634839058, -0.12624575197696686, -0.010183993726968765, -0.05059884116053581, -0.028312433511018753, 0.10773568600416183, 0.13125748932361603, -0.10685171186923981, -0.055436428636312485, -0.019610833376646042, -0.002240461530163884, 0.037632860243320465, -0.03856448829174042, -0.08129427582025528, -0.013313704170286655, -0.016353726387023926, -0.021150866523385048, -0.07075010985136032, -0.018759507685899734, -0.01628648117184639, -0.13563303649425507, 0.03596757352352142, 0.03495759144425392, 0.059007223695516586, -0.11144809424877167, -0.01674184575676918, 0.05668897554278374, -0.020417965948581696, 0.013170107267796993, -0.022222355008125305, 0.029814347624778748, -0.03007189929485321, -0.04390144720673561, -0.026948947459459305, -0.02124723605811596, -0.049606066197156906, 0.012206926010549068, -0.0030108909122645855, 0.0344608798623085, 0.01815163902938366, -0.018926549702882767, 0.007716967724263668, 0.03479895740747452, -0.028601422905921936, 0.03242858871817589, 0.0003420039138291031, -0.008439300581812859, -0.04256350174546242, 0.03470894321799278, 0.009699603542685509, 0.01828162372112274, -0.02796347811818123, -0.06140923500061035, -0.06877724081277847, -0.04450356960296631, 0.0219615139067173, 0.06042841449379921, -2.4255568220610257e-08, -0.06133619695901871, -0.03689977899193764, 0.02163892425596714, 0.04065711423754692, 0.006360065191984177, 0.06229574978351593, -0.030729278922080994, -0.06051265075802803, 0.035331349819898605, -0.01492348313331604, -0.019891507923603058, -0.006494286470115185, -0.015088164247572422, 0.0015393258072435856, -0.025155888870358467, 0.04537792503833771, 0.008658129721879959, 0.008639431558549404, -0.014319656416773796, 0.020847009494900703, -0.01840939186513424, 0.011788738891482353, -0.02062615379691124, 0.1101401075720787, 0.008153284899890423, -0.003604518249630928, 0.022485675290226936, -0.0727836862206459, -0.0018367567099630833, 0.009594489820301533, 0.07062878459692001, 0.02936154045164585, 0.0016945037059485912, 0.034725453704595566, 0.012408293783664703, -0.049244046211242676, -0.056939829140901566, 0.03716426342725754, 0.14618203043937683, 0.03244384378194809, -0.026533838361501694, 0.012756813317537308, 0.034315936267375946, -0.0023267657961696386, 0.03337793052196503, 0.05610352009534836, -0.07454035431146622, 0.03579789027571678, -0.03544608876109123, 0.05269216001033783, 0.013791176490485668, 0.004140035714954138, -0.050181541591882706, 0.08103525638580322, 0.07455189526081085, -0.023226916790008545, -0.038920335471630096, 0.005684755276888609, -0.019587663933634758, 0.016143113374710083, 0.07365424931049347, -0.047901902347803116, 0.03867434337735176, -0.05133134126663208]]\n",
      "\n",
      "TIME FOR RESPONSE EMBEDDINGS:  3.292837619781494\n",
      "\n",
      "- - - - - -\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "content_gab = content_gab[:200]\n",
    "before = time.time()\n",
    "content_gab['text_embeddings'] = content_gab['text'].apply(generate_embeddings)\n",
    "after_text = time.time()\n",
    "print(content_gab.iloc[1]['text_embeddings'])\n",
    "print('\\nTIME FOR TEXT EMBEDDINGS: ', after_text - before)\n",
    "print('\\n- - - - - -\\n')\n",
    "content_gab['response_embeddings'] = content_gab['response'].apply(generate_embeddings)\n",
    "after_response = time.time()\n",
    "print(content_gab.iloc[2]['response_embeddings'])\n",
    "print('\\nTIME FOR RESPONSE EMBEDDINGS: ', after_response - after_text)\n",
    "print('\\n- - - - - -\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for constructing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph(row):\n",
    "    text_utterances = row['text_embeddings']\n",
    "    response_utterances = row['response_embeddings']\n",
    "    # text_utterances = row['text']\n",
    "    # response_utterances = row['response']\n",
    "\n",
    "    root = text_utterances[0]\n",
    "    children = text_utterances[1:] + response_utterances\n",
    "    num_nodes = len(children) +1\n",
    "\n",
    "    #for t in text_utterances:\n",
    "     #    print(t)\n",
    "    #print()\n",
    "    #for r in response_utterances:\n",
    "    #     print(r)\n",
    "    # print()\n",
    "    # ids = [[0, i] for i in range(1, num_nodes)]\n",
    "    # print(ids)\n",
    "    # edge_index = torch.tensor(\n",
    "    #     [[0]*num_nodes, list(range(1, num_nodes)\n",
    "    # )], dtype=torch.long)\n",
    "    edge_index = torch.tensor(\n",
    "        [[0, i] for i in range(1, num_nodes)], dtype=torch.long\n",
    "    ).t().contiguous()\n",
    "    # edge_index = torch.tensor(\n",
    "    #     [[0] * len(children), list(range(1, num_nodes))], dtype=torch.long\n",
    "    # )\n",
    "    \n",
    "\n",
    "    # print(row['text_labels_encoded'])\n",
    "    # print()\n",
    "    # print(row['response_labels_encoded'])\n",
    "    # print(type(row['text_labels_encoded']), row['text_labels_encoded'].shape, row['text_labels_encoded'])\n",
    "    # print(type(row['response_labels_encoded']), row['response_labels_encoded'].shape, row['response_labels_encoded'])\n",
    "\n",
    "    # ls = np.concatenate((row['text_labels_encoded'], row['response_labels_encoded']))\n",
    "    ls = np.concatenate((row['text_labels'], row['response_labels'])).astype(int)\n",
    "    \n",
    "    print(ls)\n",
    "\n",
    "    print(ls.shape)\n",
    "    print(type(ls))\n",
    "    print(type(ls[0]))\n",
    "    \n",
    "    labels = torch.tensor(ls, dtype=torch.int32)\n",
    "\n",
    "    print(labels)\n",
    "\n",
    "    node_features = torch.tensor([root] + children, dtype=torch.float)\n",
    "    \n",
    "    # print(node_features.shape)\n",
    "    # print(edge_index.shape)\n",
    "    # print(labels.shape)\n",
    "    # print('sss')\n",
    "    data = Data(x=node_features, edge_index=edge_index, y=labels)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing graphs for all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[1 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0]\n",
      "(2,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "(13,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0 0 0]\n",
      "(8,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[1 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 0 0 0 0 1 0 0 0]\n",
      "(11,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "(18,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       dtype=torch.int32)\n",
      "[1 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(20,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "(18,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 1 0 0 0]\n",
      "(7,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "(12,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      "(16,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0 0 0 0 0 0 0 0]\n",
      "(11,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0]\n",
      "(2,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0 1 0 0 0]\n",
      "(10,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "(12,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.int32)\n",
      "[0 1 1 0 0 0 0]\n",
      "(7,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 1 1 0 0 0]\n",
      "(9,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[0 0]\n",
      "(2,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0 0 0 0]\n",
      "(9,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0 0 0 0 0 0 0 0]\n",
      "(11,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(15,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "(13,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 0 0 0 0 1 1 0 0 0]\n",
      "(12,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 1 1 1 1 0 0 0]\n",
      "(8,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0]\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0], dtype=torch.int32)\n",
      "[1 1 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 1 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(14,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 0]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "(14,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[1 0 0 0]\n",
      "(4,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 1 0 0 0]\n",
      "(5,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "[0 0 1 0 0 0]\n",
      "(6,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "tensor([0, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
      "Data(x=[4, 384], edge_index=[2, 3], y=[4])\n",
      "\n",
      "- - - - - -\n",
      "\n",
      "Number of nodes: 4\n",
      "Number of edges: 3\n",
      "\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "for index, row in content_gab.iterrows():\n",
    "    graphs.append(construct_graph(row))\n",
    "\n",
    "print(graphs[0])\n",
    "print('\\n- - - - - -\\n')\n",
    "print(f\"Number of nodes: {graphs[0].num_nodes}\")\n",
    "print(f\"Number of edges: {graphs[0].num_edges}\")\n",
    "\n",
    "print()\n",
    "print(len(graphs))\n",
    "#print('Graphs: ')\n",
    "#for i in range(0, 100):\n",
    "#    print(graphs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'joined', 'gab', 'to', 'remind', 'myself', 'how', 'retarded', 'jew', 'haters', 'are.', 'You', \"wouldn't\", 'be', 'typing', 'on', 'your', 'abacus', 'without', 'them', 'you', 'retard.']\n",
      "['This', 'is', 'what', 'the', 'left', 'is', 'really', 'scared', 'of.', 'https://redd.it/9rfkts']\n",
      "['That', 'literally', 'looks', 'like', 'a', 'monkey.', 'Why', 'are', 'we', 'supposed', 'to', 'pretend', 'it’s', 'a', 'person', 'bc', 'it’s', 'wearing', 'a', 'red', 'hat?']\n",
      "['Dumb', 'Cunt']\n",
      "['It', 'makes', 'you', 'an', 'asshole.']\n",
      "['Give', 'it', 'to', 'a', 'soldier', 'who', 'has', 'defend', 'it', ',', 'then', 'try', 'to', 'burn', 'it', '.', 'Show', 'me', 'what', 'a', 'badass', 'you', 'really', 'are.', 'The', 'flag', 'is', 'helpless', 'to', 'stop', 'you', 'or', 'fight', 'back', '.', 'Completely', 'unnecessary', 'act', ',', 'its', 'proves', 'nothing', 'and', 'accomplishes', 'nothing.', 'It', 'only', 'shows', 'your', 'a', 'ignorant', 'weak', 'faggot', '.', 'Like', 'kicking', 'a', 'puppy', ',,,', 'it', 'shows', 'how', 'weak', 'and', 'worthless', 'you', 'are']\n",
      "['So', 'they', 'manage', 'to', 'provide', 'a', 'whole', 'lot', 'of', 'data,', 'except', 'a', 'critical', 'little', 'nugget.', 'Gay', 'men', 'are', 'well', 'over', 'half', 'the', 'patients', 'who', 'present', 'at', 'STI', 'clinics,', 'and', 'are', 'probably', 'the', 'source', 'of', 'the', 'emerging', 'antibiotic-resistant', 'pathogens.', 'https://www.dailymail.co.uk/health/article-6315871/One-young-person-England-told-STI-FOUR-MINUTES.html']\n",
      "['yup.', 'i', 'cant', 'smoke', 'in', 'a', 'bar', 'because', \"it's\", 'harmful', 'to', 'some', 'faggot', \"that's\", 'getting', 'drunk,', 'doing', 'drugs', '&', 'having', 'an', 'STD', 'potluck', 'w/', 'the', 'boys', 'later......', 'seems', 'legit.']\n",
      "['Hi', 'there,', 'i,m', 'Keith,', 'i', 'hope', 'you', 'are', 'doing', 'well,', 'i', 'would', 'be', 'very', 'honored', 'to', 'get', 'to', 'know', 'you', 'if', 'you', 'would', 'be', 'interested?', '@PugLife']\n",
      "['Fuck', 'off']\n",
      "['wow,', 'what', 'a', 'rude', 'cunt']\n",
      "['you', 'sound', 'like', 'a', 'faggot']\n",
      "['Hi', 'developers,', 'give', 'us', 'a', 'follow', 'for', 'updates', 'and', 'help', 'with', 'Gab’s', 'API.', '👋']\n",
      "['STOP', 'THE', 'RACISISM', 'ON', 'HERE,', 'IT', 'IS', 'DESPICIBLE.']\n",
      "['LOL', 'you', \"can't\", 'even', 'spell', 'it', 'nigger']\n",
      "['Well,', 'you', 'are', 'the', 'fuckers', 'that', 'lit', 'the', 'match', '-', '#FakePatriots']\n",
      "['LOCK', 'THAT', 'RACIST', 'NIGGER', 'UP!!!', 'WHAT', 'KIDS', 'YOU', 'BEEN', 'FUCKING?', 'MAN', 'THEY', 'ARE', 'ALL', 'INGRATES,', 'LOWEST', 'FORMS', 'OF', 'LIFE', 'ON', 'THE', 'PLANET>', 'WORTHY', 'OF', 'DEATH,', 'RUN', 'MOTHER', 'FUCKERS<', 'RUN<', 'WE', 'ARE', 'CMOING', 'AND', 'WE', 'WILL', 'BRING', 'THE', 'PEOPLES', 'WRATH', 'DOWN', 'ONTO', 'YOUR', 'SICK', 'HEADS!']\n",
      "['SELF-HATING', 'WHITE', 'CUCKS', 'ON', 'PARADE']\n",
      "['Does', 'the', 'blind', 'guy', 'even', 'know', 'what', 'the', 'sign', 'says?']\n",
      "['Hey', 'retard', 'and', 'cross', 'dresser!', \"I'lll\", 'say', 'nigger', 'all', 'I', 'want,', 'and', 'a', 'nigger', 'still', 'has', 'to', 'get', 'a', 'job', 'an', 'earn', 'money', 'like', 'my', 'white', 'privileged', 'honky', 'ass!', 'Kill', 'your', 'self!']\n",
      "['So', 'after', '6', 'years', 'and', 'nearly', '11K', 'followers,', 'Twitter', 'suspended', 'my', 'account.', 'I', 'am', 'still', 'bugging', 'them', 'to', 'give', 'specifics', 'as', 'to', 'why', 'and', 'appealing,', 'but', 'not', 'getting', 'anywhere.', '@Oil_Ranger', 'Need', 'to', 'find', 'my', 'friends', 'here!', 'Anyone?']\n",
      "['You', \"won't\", 'find', 'any', 'friends', 'here', 'by', 'whining', 'about', 'how', 'mean', 'twitter', 'was', 'to', 'you.']\n",
      "['Another', 'dumb', 'ass', 'vile', 'nigger', 'in', 'that', 'gif.', 'It', 'is', 'rich', 'thanks', 'to', 'kikes', '&', 'stupid', 'perverse', 'Whites.', 'Hate', 'it', 'when', 'people', 'use', 'mud', 'scum', 'or', 'White', 'scum', 'gifs', 'to', 'make', 'their', 'points', 'unless', 'the', 'target', 'is', 'the', 'scum.', 'Usually', 'not', 'the', 'case.', 'He', 'has', 'done', 'lots', 'of', 'anti-White', 'crap', 'to', 'include', 'videos', 'promoting', 'decapitating', 'White', 'woman', 'but', 'since', 'he', 'became', 'a', 'trumtard', 'he', 'is', 'now', 'supposedly', 'cool.']\n",
      "['Who', 'is', 'the', 'REAL', 'nigger', 'in', 'the', 'woodpile?????', 'https://www.youtube.com/watch?v=5NIbiBNeATI']\n",
      "['Like...', 'I', 'literally', 'addressed', 'this', 'point', 'and', 'you', 'completely', 'ignore', 'it,', 'like', 'a', 'stupid', 'retard', 'nigger.']\n",
      "['Kanye', 'West', 'Stands', 'by', 'the', 'Second', 'Amendment:', '‘We', 'Have', 'the', 'Right', 'to', 'Bear', 'Arms’', 'https://www.breitbart.com/big-government/2018/10/11/kanye-west-stands-by-the-second-amendment-we-have-the-right-to-bear-arms/']\n",
      "['hey', 'damn', 'white', 'fools!!..in', 'some', 'of', \"Kanye's\", 'songs', 'he', 'has', 'called', 'upon', 'blacks', 'to', 'get', 'guns', 'to', 'kill', 'white', 'people..', \"that's\", 'why', 'he', 'supports', 'the', '2nd', 'Amendment..', 'so', 'blacks', 'can', 'get', 'guns', 'to', 'kill', 'whitey!']\n",
      "['you', 'are', 'not', 'just', 'a', 'stupid', 'nigger', 'lover..', 'but', 'also', 'extremely', 'naive..']\n",
      "['NORDIC', 'IDENTITARIAN', 'CONFIRMED']\n",
      "['Why', 'is', 'this', 'nigger', 'Tariq', 'Nasheed', 'so', 'desperate', 'to', 'look', 'like', 'a', 'white', 'man?', 'I', \"don't\", 'have', '#Twitter', 'account', 'so', 'I', 'cant', 'ask.', 'Can', 'you?']\n",
      "['Diversity', 'Hire', 'II:', 'the', 'Rapening']\n",
      "['KAMALA', 'HARRIS', 'THE', 'SJW', 'SLUT', '!!', 'SLEPT', 'WITH', 'A', 'NIGGER', 'TO', 'ADVANCE', 'HER', 'POLITICAL', 'CARRER', '!!']\n",
      "['I', \"don't\", 'like', 'you,', 'fuck', 'the', 'people', 'that', 'follow', 'you', \"don't\", 'give', 'a', 'shit', 'enough', 'about', 'what', 'you', 'post', 'to', 'read', 'it,', 'why', 'the', 'hell', 'would', 'I', 'sort', 'threw', 'that', 'retard', 'garbage?', '\"you', 'win', 'some', 'you', 'lose', 'some\"', 'Thats', 'not', 'even', 'applicable,', 'you', 'dense', 'fucker.']\n",
      "['No.', 'Shut', 'up', 'faggot', 'they', 'are', 'clones', 'of', 'Jordan', 'Jereb']\n",
      "['Right!', 'And', 'Kavanagh', 'was', 'a', 'serial', 'gang', 'rapist', 'and', 'massive', 'drunk.', 'And', 'Kanye', 'is', 'a', 'crazy', 'nigger', 'who', \"can't\", 'read.', '(((You', 'guys)))', 'and', 'your', \"fuckin'\", 'labels.', 'We', 'all', 'know', 'who', 'is', 'producing', 'the', 'massive', 'amount', 'of', 'gay', 'porn', 'in', 'this', 'country.']\n",
      "['Hey', '@Slate,', 'I', 'was', 'born', 'and', 'bred', 'in', 'Brooklyn,', 'New', 'York', 'by', 'a', 'Puerto', 'Rican', 'mother', '&', 'an', 'Italian', 'father.', 'Ask', 'me', 'if', 'Gab', 'is', '\"MUH', 'White', 'Supremacists', 'Safe', 'Space\"!', 'I', 'DARE', 'YOU!', '🖕🏼', 'White', 'Supremacists', 'Still', 'Have', 'a', 'Safe', 'Space', 'Online', 'https://slate.com/technology/2018/10/discord-safe-space-white-supremacists.html']\n",
      "['white', 'supremacist...anyone', 'who', 'is', 'not', 'a', 'nigger', 'loser...']\n",
      "['Muh', 'dick', 'is', 'the', 'nigger', 'sockpuppet', 'line,', 'ugly', 'children', 'applies', 'though.', 'Id', 'stick', 'more', 'to', 'the', 'kicked', 'out', 'of', 'every', 'country', 'they', 'ever', 'existed', 'in', 'and', 'are', 'natural', 'parasites', 'line,', 'since', 'its', 'actually', 'grounded', 'in', 'reality', 'and', 'just', 'a', 'fact', 'that', 'cant', 'be', 'argued', 'against.']\n",
      "['Ellison:', 'I’m', 'Considering', 'Resigning', 'From', 'the', 'DNC', 'https://freebeacon.com/politics/ellison-im-considernig-resigning-dnc/']\n",
      "['Good', 'fucking', 'dirty', 'muzzie']\n",
      "['Nigger', 'sows', 'make', 'good', 'Nigger', 'repellent', 'because', 'of', 'their', 'looks', 'and', 'smell']\n",
      "['Only', 'pussies', '&', 'jews', 'like', 'to', 'silence.', 'Why', 'does', 'obvious', 'evidence', 'offend', 'u', 'so', 'much', '?', 'Well', 'pussies', '&', 'jews', 'force', 'ppl', 'to', 'mute', 'with', 'their', 'faggot', 'pedo', 'porn.', 'So', 'what', 'I’m', 'sayin', 'is', 'don’t', 'start', 'w', 'ur', 'pedo', 'porn', 'u', 'pussy', 'jew.']\n",
      "[]\n",
      "['Is', 'this', 'peak', 'redneck', '🤔']\n",
      "['Nobody', 'wants', 'your', 'nigger', 'loving', 'whore,', 'she', 'is', 'yours,', 'nigger!']\n",
      "['Obama', 'spent', '8', 'years', 'blaming', 'Bush', 'for', 'bad', 'economy,', 'now', 'he', 'has', 'spent', '2', 'years', 'taking', 'credit', 'for', '@realDonaldTrump', 'success', 'in', 'the', 'economy.', 'What', 'do', 'we', 'call', 'this?', 'https://redd.it/9qrr1g']\n",
      "['Nigger']\n",
      "['Some', 'do', 'Jon,', 'but', \"it's\", 'downright', 'retarded', 'to', 'suggest', 'that', 'all', 'Jews', 'do.', 'All', 'faiths', 'have', 'some', 'wicked', 'people', 'carrying', 'their', 'banner', 'I', 'imagine.']\n",
      "[]\n",
      "['A', 'queer', 'nigger', 'on', 'a', 'sissy', 'bike', '.', 'The', 'bike', 'needs', 'to', 'be', 'pink', 'I', 'think', 'lol']\n",
      "['Why', 'must', 'you', 'be', 'so', 'rude?', 'Are', 'you', 'angry', 'that', 'my', 'people', 'are', 'superior?', 'Fortunately,', 'there', 'is', 'nothing', 'you', 'can', 'do', 'about', 'it.', 'Be', 'mean', 'to', 'me', 'all', 'you', 'want.', 'You', 'will', 'never', 'be', 'anything', 'more', 'than', 'a', 'replaceable', 'component', 'to', 'be', 'put', 'to', 'work.', 'Enjoy', 'your', 'Sunday,', 'back', 'to', 'work', 'on', 'Monday.', 'Meanwhile,', 'I', 'shall', 'enjoy', 'my', 'glorious', 'life.', 'Maybe', 'I', 'will', 'go', 'golfing.']\n",
      "['how', 'does', 'lying,', 'cheating,', 'stealing,', 'murdering', 'and', 'being', 'a', 'treasonous', 'faggot', 'make', 'you', 'superior?']\n",
      "['So', 'I', 'get', 'doxxed', 'and', 'flamed', 'and', \"I'm\", 'just', 'supposed', 'to', 'close', 'my', 'Gab', 'account,', 'cancel', 'my', 'trip', 'to', 'the', 'border', 'and', 'hide', 'in', 'shame?', 'Well,', 'if', 'they', 'had', 'something', 'hard', 'that', 'actually', 'embarrassed', 'me,', 'I', 'might', 'consider', 'that.', 'Ah,', 'silly', 'shitlibs.', 'This', \"ain't\", 'my', 'first', 'rodeo', 'and', 'this', \"ain't\", 'the', 'first', 'time', \"I've\", 'been', '\"doxxed\".', 'You', 'got', 'nothing.']\n",
      "['Apparently', 'some', 'people', 'fear', 'that', 'you', 'will', 'commit', 'journalisms.', 'In', 'public']\n",
      "['My', '\"journalism\"', 'will', 'probably', 'devolve', 'into', 'everyone', 'hearing', 'a', 'hillbilly', '(me)', 'screaming', '\"Holy', 'crap!', 'Did', 'ya', 'see', 'that?!!!\"', 'I', 'will', 'deliver', 'my', 'best,', 'but', 'I', \"won't\", 'guarantee', 'it', 'will', 'look', 'profession.']\n",
      "['So', 'far,', 'no', 'fairy', 'gay', 'faggot', 'tranny', 'porn.', 'Nice!', ':)']\n",
      "['This', 'is', 'a', 'beautiful', 'thang.']\n",
      "['Good', 'Heavens.', 'Sucker', 'punches', 'like', 'two', 'against', 'one', 'is', 'nigger', 'fun.']\n",
      "['LOL,', \"he's\", 'here', 'to', 'proclaim', \"he's\", 'wrong', 'again', 'about', 'the', 'Kavenaugh', 'accuser.', ':D', \"He's\", 'a', 'retarded', 'homo,', 'but', 'at', 'least', \"he's\", 'persistent.', ':D', \"That's\", 'the', 'perfect', 'foot', 'soldier', 'for', 'white', 'supremacists.']\n",
      "['What', 'a', 'shit', 'show.', 'Go', 'to', 'wwf', 'if', 'you', 'want', 'to', 'just', 'hug', 'your', 'damn', 'opponent.', 'That', \"isn't\", 'fighting.']\n",
      "['Shut', 'up', 'faggot.']\n",
      "[\"I'll\", 'break', 'you.', \"I'll\", 'beat', 'the', 'nigger', 'cum', 'out', 'of', 'your', 'cocksucker']\n",
      "['Why', 'would', 'Commie', 'Twitter', 'Ban', 'Him', '?', '🤷🏼\\u200d♂️', 'Shouldnt', 'be', 'a', 'Surprise', 'https://www.dailywire.com/news/37270/twitter-wont-ban-farrakhan-calling-jews-termites-ben-shapiro']\n",
      "['At', 'least', 'the', 'nigger', 'tells', 'the', 'truth', 'about', 'the', 'yids....Watch', 'him', 'on', 'JewTube']\n",
      "['Donald', 'J.', 'Trump', 'Retweeted', 'Melania', 'Trump', '@FLOTUS', 'Thank', 'you', 'Malawi!', 'https://www.youtube.com/watch?v=K5TX7mxR82M', '9:50', 'am', '-', '5', 'Oct', '2018']\n",
      "['What', 'has', 'Malawi', 'ever', 'done', 'for', 'the', 'West?', 'The', 'only', 'thing', \"they're\", 'good', 'at', 'is', 'taking', 'our', 'resources', 'and', 'begging', 'for', 'more', 'gibs.']\n",
      "['Fuck', 'up', 'Jew', 'Cunt']\n",
      "['Add', 'ONEWAYDOTCOM', 'to', 'the', 'Gab', 'censored', 'hall', 'of', 'martyrs,', 'alongside', 'the', 'great', 'Jsello', 'and', 'the', 'not', 'so', 'great', 'BLITZ', 'and', 'Pepe_Memes.']\n",
      "['😂', '#TOPKEK']\n",
      "['Cheering', 'on', 'censorship.', \"That's\", \"Gab's\", 'palace', 'guard.', 'A', 'bunch', 'of', 'scum', 'who', 'want', 'users', 'banned', 'for', 'their', 'opinions.', 'That', 'was', 'always', 'what', 'Side', 'stood', 'for.']\n",
      "['You', 'cheered', 'on', 'censorship', 'with', 'the', 'doxxing', 'of', 'side', 'What', 'goes', 'around', 'comes', 'around']\n",
      "['Sidephase', 'was', 'lobbying', 'to', 'ban', 'users.', \"'Two\", 'down,', 'two', 'to', \"go',\", 'he', 'said.', 'Then', 'he', 'was', 'gone.']\n",
      "['That', 'was', 'a', 'quick', '180°', 'dread']\n",
      "['I', 'would', 'never', 'have', 'doxxed', 'Side.', 'But', 'I', \"don't\", 'miss', 'him.']\n",
      "['Wow,', 'even', 'I', 'don’t', 'bitch', 'about', 'Side', 'for', 'days', 'on', 'end', 'the', 'way', 'you', 'do!', 'I', 'don’t', 'even', 'have', 'to', 'make', 'stuff', 'up', 'to', 'truthfully', 'be', 'angry', 'at', 'him.', 'Side', 'leaving', 'Gab', 'was', 'a', 'chickenshit', 'move', 'looking', 'back', 'at', 'it.', 'But', 'between', 'the', 'doxing', 'innocent', 'ppl', '&', 'yelling', 'at', 'good', 'friends', '&', 'major', 'fuck', 'up', 'with', 'his', 'girlfriend', '(me).', 'He', 'felt', 'it', 'was', 'the', 'right', 'choice.', 'At', 'the', 'time,', 'it', 'was', 'his', 'choice,', 'he', 'wasn’t', 'asked,', 'it', 'wasn’t', 'pleasant', 'but', 'he', 'took', 'the', 'out.', 'Side', 'felt', 'it', 'would', 'protect', 'everyone.', 'It', 'hasn’t', 'but', 'your', 'bullshit', 'comments', 'really', 'take', 'the', 'cake.', '#MoveTheFuckOn', '#YouAreCommieScum', 'cc:', '@Sockalexis', '@Gee', '@PepeFarmRemembers', '@militanthippy', '@DeplorableBuilder', '@Broken77', '@kgrace', '@Snugglebunny', '@Deplorable_Satoshi', '@LoafOfToast']\n",
      "['That', 'should', 'be', 'your', 'final', 'word,', 'BB...if', 'he', 'wants', 'to', 'continue', 'to', 'drone', 'on', 'about', 'Side,', 'let', 'it', 'be', 'to', 'himself.', \"You've\", 'said', 'all', 'you', 'have', 'to', 'about', 'it.', '💜']\n",
      "['I', 'still', 'like', 'kicking', 'the', 'retard', 'from', 'time', 'to', 'time', 'over', 'his', 'normal', 'bs...but', 'this', 'I', 'came', 'back', 'to', 'after', 'a', 'long', 'trip...yeah,', 'dumbass', 'screwed', 'up', 'this', 'time.']\n",
      "['So', 'today', 'is', 'National', 'Coming', 'Out', 'Day.', \"It's\", 'been', 'over', '5', 'years', 'since', 'I', 'first', 'came', 'out', 'to', 'anyone,', 'and', 'it', 'was', 'the', 'most', 'nerve-racking', 'thing', \"I've\", 'ever', 'done.', 'I', 'would', 'rather', 'present', 'my', \"Master's\", 'thesis', 'presentation', 'for', '24', 'continuous', 'hours', 'than', 're-live', 'that', 'moment.', '(Anyway,', 'here', 'I', 'am', 'in', 'a', 'Pride-colored', 'Eagles', 'tank', 'top', 'after', 'a', 'killer', 'sunburn', 'from', 'a', 'day', 'out', 'on', 'Sebago.', '🏳️\\u200d🌈🌊🦀)']\n",
      "['Kill', 'yourself', 'faggot']\n",
      "['Nah.', 'This', 'ain’t', 'it,', 'chief.']\n",
      "['https://youtu.be/p4DpLVW9DKU', 'These', 'are', 'your', 'supposed', 'allies', '@muslimfighter', 'wake', 'the', 'fuck', 'up,', 'research', 'the', 'Bolshevik', 'revolution', 'and', 'holodomor,', 'if', 'you', 'are', 'white,', 'heterosexual', 'and', 'Christian,', 'your', 'an', 'enemy', 'combatant!']\n",
      "['Fuck', 'off,', 'POS!', 'I', 'had', 'enough', 'of', 'your', 'retarded', 'kind', 'today;', 'go', 'play', 'somewhere', 'else,', 'Muslimgirl.']\n",
      "['Goyim', 'know,', 'what', 'is', 'my', 'kind?']\n",
      "['I', 'want', 'the', 'truth,', 'we', 'are', 'not', 'getting', 'it!']\n",
      "[]\n",
      "['Well,', 'the', 'good', 'news', 'is,', 'I', \"don't\", 'think', 'you', 'have', 'to', 'be', 'a', 'white', 'nationalist', 'to', 'be', 'pissed', 'at', 'the', 'left', 'and', 'their', 'racism.', 'I', 'think', 'a', 'good', 'deal', 'of', 'Americans', 'are', 'sick', 'of', 'their', '\"white', 'privilege\"', 'this,', '\"everything', 'is', 'white', 'peoples', 'fault\"', 'that,', 'stuff.', 'So,', 'you', \"don't\", 'have', 'to', 'be', 'a', 'faggot', 'ass', 'nazi', 'to', 'be', 'on', 'the', 'same', 'page', 'as', 'tens', 'of', 'millions', 'of', 'Americans.']\n",
      "['You', 'just', 'have', 'to', 'be', 'an', 'illiterate', 'apartment', 'renter', 'and', 'oblivious', 'to', 'the', 'Balfour', 'Declaration,', 'Holodomor,', 'Haavara', 'Agreement,', 'Katyn', 'Massacre', 'and', 'you', 'can', 'join', 'this', 'Kike', 'cult!']\n",
      "['The', '#TrumpCurse', 'Michael', \"Avenatti's\", 'horrible,', 'very', 'bad', 'week:', 'Lawyer', 'hit', 'with', 'avalanche', 'of', 'legal,', 'financial', 'and', 'personal', 'woes', 'https://www.foxnews.com/politics/michael-avenattis-horrible-very-bad-week-lawyer-hit-with-avalanche-of-legal-financial-and-personal-woes']\n",
      "['Lol', 'The', '#TrumpCurse2', '‘Megyn', 'Kelly', 'Today’', 'canceled', 'by', 'NBC,', 'co-anchors', 'to', 'take', 'over', 'https://www.foxnews.com/entertainment/nbc-news-officially-cancels-megyn-kelly-today']\n",
      "[\"she's\", 'a', 'stunt', 'cunt', 'for', 'the', 'jew', 'news', 'who', 'tossed', 'her', 'under', 'the', 'bus', 'after', 'losing', 'her', 'usefulness.', 'Ever', 'since', 'her', '1st', 'question', 'to', 'Trump', 'in', 'the', 'primaries', \"I've\", 'hated', 'this', 'shit', 'excuse', 'for', 'a', 'reporter.', 'Then', 'she', 'affirmed', 'it', 'in', 'an', 'interview', 'w/', 'Putin;', \"you're\", 'an', 'egomaniacal', 'THOT', \"who's\", 'finally', 'got', 'what', 'she', 'deserves.']\n",
      "['You', 'been', 'negatively', 'gearing', 'your', 'score', 'recently?', 'You', 'been', 'pissing', 'off', 'some', 'kikey', 'nigger', 'lovers?', '@johnlarson']\n",
      "['Donald', 'Trump', 'Suggests', 'Someone', 'Is', 'Paying', 'Migrants', 'in', 'Caravan', 'https://www.breitbart.com/politics/2018/10/18/donald-trump-suggests-someone-is-paying-migrants-in-caravan/']\n",
      "['He', 'also', 'suggested', 'he', 'was', 'being', 'spied', 'on,', 'Sweden', 'was', 'out', 'of', 'control,', 'the', 'existence', 'of', 'a', 'deep', 'state,', 'that', 'mainstream', 'media', 'was', 'fake', 'news,', 'that', 'Elizabeth', 'Warren', \"wasn't\", 'a', 'native', 'American,']\n",
      "['And', 'here', 'you', 'go', 'you', 'NPC', 'faggot', 'https://www.youtube.com/watch?v=o8PGOMJZirc']\n",
      "['@OrwellGoode', 'All', 'we', 'want', 'is', 'truth,', 'justice,', 'and', '£2', 'million', 'in', 'cash.']\n",
      "['This', 'does', 'not', 'happen', 'with', 'white', 'males', 'that', 'die', 'in', 'custody.', 'It`s', 'amazing', 'how', 'all', 'these', 'Nigger', 'criminals', 'are', 'all', 'home', 'loving,', 'church', 'going,', 'choir', 'boy`s.', 'Lordy,', 'Lordy,', 'praise', 'Jesus.', '1', 'dead', 'Nigger', '=', 'Result.']\n",
      "['“He', 'turns', 'around,', 'he', 'starts', 'pointing', 'to', 'me.', 'He’s', 'talking', 'to', 'the', 'people', 'at', 'the', 'table,', 'just', 'rattling', 'on', 'about', 'how', '‘White', 'people', 'are', 'the', 'devils', 'are', 'the', 'world,', 'I', 'hate', 'white', 'people,', 'we', 'should', 'get', 'rid', 'of', 'white', 'people.’”', '^^#NPC', 'created', 'by', 'CNN', 'https://www.nydailynews.com/new-york/nyc-crime/ny-metro-anti-white-attack-bronx-pizzeria-20181018-story.html']\n",
      "['If', 'you', 'are', 'sitting', 'at', 'a', 'table', 'minding', 'your', 'own', 'business', 'and', 'some', 'violent', 'third', 'world', 'retard', 'starts', 'attacking', 'you,', 'give', 'him', 'the', 'Han', 'Solo', 'treatment', 'and', 'shoot', 'him', 'with', 'your', 'gun', 'under', 'the', 'table.']\n",
      "['Gee,', 'you', \"didn't\", 'know', 'that', 'a', 'Jew', 'or', 'the', 'Jew', 'media', \"won't\", 'necessarily', 'admit', 'a', 'person', 'is', 'Jewish', 'when', 'they', 'are', 'a', 'krypto', '(Jews', 'that', 'infiltrate', 'as', 'something', 'else)']\n",
      "['Your', 'obsession', 'denotes', 'you', 'are', 'a', 'Jew', 'or', 'a', 'retarded', 'christian', 'zionist']\n",
      "['Nigger', 'please.']\n",
      "['Is', 'this', 'that', 'casino', 'nigger', 'ken', 'younous?']\n",
      "['The', 'anti-fa', 'punks', 'are', 'planning', 'to', 'gather', 'in', 'cities', 'nationwide', 'for', 'the', 'mid', 'term', 'elections', 'to', 'cause', 'havoc,', 'chaos', 'and', 'attack', 'Trump', 'supporters.', 'WE', 'CAN', 'LONGER', 'REMAIN', 'ON', 'THE', 'SIDELEINES', 'WATCHING.', 'WE', 'HAVE', 'TO', 'MEET', 'THEM', 'HEAD', 'ON', '#MAGA', '#KAG', '#GabFam', '#BritFam', '#SpeakFreely', '#BuildTheWall', '#DrainTheSwamp', '#DeepState', '#SpyGate', '#Winning#USA', '#WeThePeople', '#WWG1WGA', '@OnlyCrazyISLeft', '@Maxine63', '@BillieJeanmoo', '@Lindaricci101', '@MissTeek', '@ValiantBriton', '@American2theKor', '@Kimharm', '@IshudNBHere', '@6549lmartin', '@Zero60', '@KellKell', '@sissygirl', '@TrumpetteUSA', '@StarBaby', '@Rebel_Angel', '@Greatauntgrace', '@AuntyGreen', '@oppoten', '@Wicked-Warrior', '@Brit-Girl-2017', '@Sorrel', '@tradition', '@Lilia', '@XOXOpro', '@Jasmine8137488', '@detailsgrptours', '@USA_Girl', '@Debbin', '@sandydee', '@Blonde_Beast', '@Kimharm', '@cgijoe', '@mimiplusfour', '@doradeplora', '@katiwil', '@Scottishblood', '@ConservativeGal', '@womenfortrump63', '@NativeCal4Trump', '@ProudPatriot101', '@WarriorHuntress', '#Gab4Conservatives,', '#MCGA', '@Gypsy124', '@Kelly4u', '@RogueCyborg', '@Direito', '@blkdiamond97', '@Tracy1776', '@Holly5153', '@cheekybroad', '@PurtyPrincess', '@AA1', '@GunGirl18', '@JJDanceN1', '@FrauleinGermanAngst', '@ROSEANNE', '@LexiQuin', '@NancyQanon', '@muslimfighter', '@Tessa', '@LeBaron', '@MALMOSWEDEN', '@JamieJAG', '@hidehunt1', '@skyoversc', '@SpunkyLilMaMa', '@izlam-is-shit', '@ErickaJacobs', '@Moonkat62', '@jaydafransen', '@Margi59', '@GeeCee', '@Sardonic', '@Tiredoflies', '@PunkyLilRedhead', '@Trish35', '@AnnetteWayne', '@blessedhart21', '@TheIslandGirl', '@CheekyTigress', '@HempOilCures', '@sunbaby', '@Forward_Focus', '@JLC', '@britainfirst', '@PBErotician', '@texanerinlondon', '@Dvasquez5399', '@TT45Pac', '@Mcarr', '@WildWelshWoman', '@lovelymiss', '@Sterangeli5', '@debzbennett', '@beth3', '@Pamisue', '@DanceDiva', '@LesaJoy', '@Sugaree', '@sparkle_patriot', '@DDawn0', '@jackiestbird', '@Lorigirltexas', '@Dawn2334', '@TanyaP', '@uptheante', '@JadedIndBot', '@telegramformongos', '@SparkleDee', '@KarenMcInnes', '@AbbeyOfTheBlackSwan', '@Alicemary', '@TeresaG', '@Don45sGirl', '@PatriotInfidel', '@smileygirl19681@LBrooksRD', '@HeikeGani', '@tripleblu', '@kimwhocries', '@DenisetheKelt', '@rellkay', '@Dawn2334', '@ccwin', '@Merrymary', '@ArmedTrumpGod', '@LLZW', '@kittentrump', '@JuneClemens', '@Radicalgrambo', '@BrittPettibone', '@Olleken', '@PatriotWendy', '@LondonLass58', '@kittentrump', '@Abbafather', '@ArtistPatriot', '@Annie53annette', '@roxi_usa', '@Millwood16', '@Gerryattric', '@FlynEagle', '@FormerlyShaddowBanned']\n",
      "['It', 'was', 'probably', 'an', 'ANTIFA', 'member', 'who', 'down-voted', 'this', 'post.']\n",
      "['I', 'downvoted', 'this.', 'Fighting', 'the', 'jews', 'lowest', 'foot', 'soldiers', 'to', 'then', 'be', 'arrested', 'by', 'Jewish', 'owned', 'cops', 'and', 'spend', '5-10', 'years', 'in', 'a', 'jewish', 'run', 'nigger', 'filled', 'prison', 'is', 'not', '#natsoc.']\n",
      "['Astronaughts', 'should', 'stick', 'to', 'what', 'they', 'know', 'best...', 'getting', 'out', 'there', 'in', 'space...perhaps', 'the', 'silly', 'cunt', 'should', 'take', 'his', 'helmet', 'off', 'next', 'time', \"he's\", 'having', 'a', 'spacewalk.', 'Fuck', 'me', 'these', 'lefty', 'scum', 'give', 'me', 'the', 'literal', 'shits...and', 'some', 'of', 'these', 'useless', 'cunts', 'think', 'that', 'having', 'fucked', 'the', 'good', 'ole', 'USA', 'up', 'the', 'ass', 'with', 'their', 'liberal', 'crapola', 'they', 'can', 'move', 'to', 'New', 'Zealand']\n",
      "['Resistance', 'Leader', 'Remains', 'Silent', 'On', 'Ellison', 'https://bigleaguepolitics.com/resistance-leader-remains-silent-on-ellison/']\n",
      "['somebody', 'should', 'rape', 'and', 'kill', 'her,', 'its', 'the', 'muzzie', 'way']\n",
      "['Rapper', 'T.I.', 'takes', 'a', 'swipe', 'at', 'Kanye', 'West', 'and', '@POTUS', 'with', 'video', 'of', 'inappropriate', 'Melania', 'Trump', 'lookalike', 'https://t.co/IeliQ1sOfQ']\n",
      "['this', 'be', 'a', 'nigger', 'running', 'around', 'yelling', \"'where\", 'all', 'da', 'white', 'wimmin', \"at'?\"]\n",
      "['Another', 'picture', 'that', 'is', 'worth', 'a', 'thousand', 'words.', 'She', 'is', 'at', 'an', 'orphanage', 'in', 'Kenya', 'in', 'this', 'photo.', 'The', 'kids', 'wanted', 'to', 'pray', 'for', 'her.', 'This', 'is', 'a', 'FIRST', 'LADY', '-', 'This', 'is', 'Our', '1st', 'Lady', 'of', 'the', 'United', 'States', 'of', 'America', 'and', 'I', 'am', 'proud', 'to', 'share', 'Amen', '#Faith', '#Maga', '#Qanon', '#WWG1WGA', '#Trump2020']\n",
      "['Fuck', 'that', 'shill', 'bitch', ',', 'her', 'daughter', 'marrying', 'a', 'fucking', 'kike', 'add', 'her', 'husband', 'shilling', 'for', 'Israel.', 'Cunts']\n",
      "['you', 'want', 'talk', 'scripture,', 'Ive', 'read', 'the', 'bible', 'cover', 'to', 'cover', '5', 'times.', 'I', 'would', 'humiliate', 'your', 'googled', '\"knowledge\"', 'and', 'memorised', 'media', 'propoganda', 'scriptures', 'taken', 'out', 'of', 'context.', 'Bless', 'Israel', 'refers', 'too', 'the', 'land', 'not', 'a', 'race.', 'The', 'bible', 'very', 'specifically', 'says', 'race', \"doesn't\", 'matter.', 'Hundreds', 'of', 'times.', 'Cunt']\n",
      "[\"It's\", 'weird', 'how', \"you're\", 'the', 'one', 'who', 'knows', 'about', 'it,', 'but', \"you're\", 'claiming', 'that', 'everyone', 'else', 'goes.', 'So', 'weird.']\n",
      "['wierd', 'how', 'everyone', 'is', 'gay', 'except', 'for', 'you.', 'Must', 'be', 'one', 'of', 'those', '\"the', 'world', 'is', 'wrong', 'and', 'you', 'are', 'right\"', 'conundrums', 'that', 'petulant', 'teenagers', 'go', 'through!', 'except,', 'you', 'are', 'a', 'jew,', 'and', 'you', 'are', 'doing', 'the', 'petulant', 'teenager', 'routine,', 'well', 'into', 'your', \"40's\"]\n",
      "['Who', 'said', 'everyone', 'is', 'gay', 'except', 'for', 'me?', 'So', 'far,', \"I've\", 'said', \"you're\", 'gay.']\n",
      "['quick', 'check', 'of', 'your', 'feed', 'proves', 'this', 'is', 'a', 'blatant', 'lie.']\n",
      "['Oh,', 'my', 'feed', 'showed', 'I', 'said', 'everyone', 'in', 'the', 'world', 'is', 'gay', 'except', 'for', 'me?', 'Show', 'me.']\n",
      "['You', 'still', 'believe', 'you', 'are', 'important?', 'Lol,', 'how', 'cute.']\n",
      "['Guess', 'you', \"couldn't.\", 'I', 'win', 'again.', 'As', 'per', 'usual.']\n",
      "['How', 'many', 'retard', 'shields', 'are', 'in', 'your', 'cabinet', 'now?', 'last', 'time', 'i', 'checked,', 'you', 'needed', 'a', 'new', 'unit.']\n",
      "['I', 'use', 'you', 'as', 'a', 'shield?']\n",
      "['The', 'NFL', 'is', 'a', 'jew', 'ploy!', 'To', 'over', 'pay', 'Niggers', 'to', 'unbalance', 'the', 'White', 'Economy', 'and', 'enrich', 'them', 'enough', 'to', 'infiltrate', 'traditional', 'White', 'Communities', 'to', 'break', 'ground', 'for', 'more', 'Nigger', 'invasion!']\n",
      "['Torba’s', 'decision', 'to', 'ban', '“Loli', 'porn”', 'is', 'justified.', 'Animations', 'that', 'sexualize', 'children', 'are', 'a', 'slippery', 'slope', 'to', 'sexualizing', 'real', 'children.', 'It’s', 'a', 'disgusting', 'concept', 'and', 'it', 'isn’t', '“freedom', 'of', 'speech”,', 'it’s', 'content', 'that', 'caters', 'to', 'pedophiles.', 'Plain', 'and', 'simple.']\n",
      "['The', 'retarded', 'tv', 'generation', 'is', 'into', 'some', 'retardedly', 'not', 'attractive', 'porn.']\n",
      "['I', 'want', 'one.', 'I', \"don't\", 'care.', 'Call', 'me', 'a', 'faggot.', \"I'll\", 'be', 'that', 'faggot', 'without', 'that', 'cold', 'sore', 'from', 'a', 'herpes', 'or', 'Hep', 'infected', 'glass', 'that', 'was', 'haphazardly', 'washed.']\n",
      "['Jack', 'Dorsey', 'admits', 'it', 'was', 'a', '\"joke\"', 'when', 'he', 'said', 'Twitter', 'stood', 'for', 'free', 'speech', 'https://www.breitbart.com/tech/2018/10/18/twitter-ceo-jack-dorsey-our-free-speech-motto-was-a-joke/']\n",
      "['I', 'wanna', 'beat', 'Jack', \"Dorkey's\", 'face', 'to', 'a', 'blood', 'y', 'pulp,', 'just', 'for', 'the', 'fun', 'of', 'it', 'Does', 'that', 'make', 'me', 'a', 'bad', 'person?']\n",
      "['Start', 'by', 'ripping', 'that', 'snot', 'ring', 'out', 'of', 'his', 'faggot', 'nose.']\n",
      "['Marine', 'Le', 'Pen', 'is', 'Right']\n",
      "['Hmmm...', \"I'd\", 'rephrase', 'it.', 'The', 'divide', 'is', 'between', 'the', 'electorate', 'and', 'the', 'globalists.', 'Everything', 'the', 'globalists', 'do', 'is', 'to', 'rob', 'the', 'electorate', 'of', 'sovereignty.']\n",
      "['Given', 'the', 'white', 'electorate', 'STARTED', 'with', 'the', 'sovereignty,', 'I', 'wonder', 'who', 'this', 'new', '(((globalist)))', 'could', 'be?']\n",
      "['Another', 'lunatic', 'Jew', 'hater', 'to', 'mute.']\n",
      "['I', 'guess', \"that's\", '351,', 'huh?', 'Acknowledging', 'that', 'a', 'certain', 'group', 'of', '(((people)))', 'are', 'over', 'represented', 'in', 'the', '\"New', 'World', 'Order\"', '(tm)', 'is', 'now', '\"lunatic', 'Jew', 'hating\".']\n",
      "['you', 'sound', 'like', 'SJWs', 'twatting', 'about', 'whites', 'being', 'over', 'represented.', 'only', 'racists', 'care', 'so', 'much', 'about', 'race.', 'your', 'hatred', 'is', 'lunacy,', 'considering', 'most', 'of', 'it', 'was', 'penned', 'in', '1933', 'and', \"you're\", 'still', 'using', 'the', 'same', 'sorry', 'shit.']\n",
      "['When', '\"it\"', 'was', 'penned', 'is', 'irrelevant.', 'It', 'is', 'a', 'fact', 'that', 'there', 'is', 'a', 'clear', 'and', 'massive', 'over', 'representation,', 'far', 'in', 'excess', 'of', 'the', '\"over-representation\"', 'of', 'straight,', 'white,', 'heterosexual,', 'Christian', 'men,', 'of', 'a', 'certain', '(((group)))', 'in', 'the', 'fields', 'of', 'business,', 'finance,', 'politics,', 'government,', 'media,', 'and', 'entertainment', 'that', 'drives', 'the', 'developing', 'one', 'world', 'government', 'and', 'structure.', 'These', 'same', 'Jews', 'care', 'about', 'race', 'every', 'bit', 'as', 'much', 'as', 'virtually', 'every', 'other', 'race,', 'except', 'white', 'people.']\n",
      "['@deepblu', 'Believe', 'me,', 'blacks', 'and', 'Latinos', 'are', 'obsessed', 'with', 'race.', 'THEY', 'are', 'the', 'racists.', 'They', 'are', 'so', 'racist', 'that', 'they', 'believe', 'WE', 'are', 'racist.', 'The', 'reason', 'the', 'vast', 'majority', 'of', 'whites', 'are', 'NOT', 'racist', 'is', 'bc', 'they', 'have', 'been', 'relentlessly', 'hammered', 'year', 'after', 'year,', 'decade', 'after', 'decade,', 'to', 'be', 'terrified', 'of', 'being', 'called', 'or', 'thought', 'of', 'as', 's', 'racist.', 'If', 'you', 'are', 'even', 'remotely', 'perceived', 'as', 'being', 'racist,', 'you', 'can', 'expect', 'to', 'be', 'socially', 'gang', 'raped', 'in', 'your', 'business,', 'circle', 'of', 'friends,', 'your', 'community,', 'or', 'your', 'constituents.', 'You', 'can', 'expect', 'to', 'be', 'ostracized', 'and', 'lose', 'your', 'job', 'without', 'consequence', 'to', 'your', 'employer.', 'You', 'wanna', 'know', 'what', 'white', 'people', 'are', 'racist?', 'White', 'people', 'that', 'have', 'a', 'lot', 'of', 'experience', 'with', 'blacks', 'where', 'their', 'numbers', 'have', 'reached', 'a', 'kind', 'of', 'critical', 'mass', 'where', 'they', 'lose', 'fear', 'of', 'law', 'enforcement,', 'and', 'have', 'the', 'numbers', 'tovexact', 'physical', 'violence', 'on', 'those', 'who', 'stand', 'up', 'to', 'them,', 'and', 'never', 'one', 'on', 'one.', 'You', 'have', 'a', 'problem', 'with', 'one,', 'you', 'now', 'have', 'a', 'problem', 'with', 'their', 'entire', 'circle', 'of', 'friends.', 'The', 'racist', 'white', 'people', 'are', 'the', 'white', 'people', 'that', 'have', 'to', 'live', 'around', 'them,', 'go', 'to', 'school', 'with', 'them,', 'have', 'to', 'workbwith', 'them,', 'and', 'go', 'to', 'the', 'same', 'grocery', 'store', 'and', 'same', 'wal', 'mart', 'they', 'do.', 'If', 'you’re', 'not', 'racist,', 'you', 'don’t', 'live', 'around', 'them,', 'or', 'you', 'are', 'a', 'sucker', 'ass', 'chump', 'punk', 'wyte', 'boi', 'that', 'deserves', 'to', 'be', 'forced', 'to', 'live', 'in', 'the', 'heart', 'of', 'the', 'ghetto...']\n",
      "['some', 'are.', 'just', 'like', 'some', 'whites', 'are.', 'anyone', 'who', 'obsesses', 'over', 'race', 'is', 'a', 'racist.', 'this', 'includes', 'you.', 'you', \"don't\", 'get', 'to', 'act', 'like', 'SJWs', 'and', 'act', 'like', \"it's\", 'cool', 'when', 'you', 'do', 'it.', \"it's\", 'not.', 'if', 'you', 'think', \"you're\", 'being', 'discriminated', 'against,', 'get', 'proof,', 'take', 'them', 'to', 'court.', \"we're\", 'already', 'seeing', 'Title', 'IX', 'changing', 'pace', 'in', 'some', 'colleges.', 'Blacks', 'are', '13%', 'of', 'the', 'population.']\n",
      "['Discriminated', 'against?', 'I', \"don't\", 'fucking', 'care', 'if', 'a', 'nigger', 'discriminates', 'against', 'me.', 'I', 'expect', 'it.', 'Blacks', 'are', '13%', 'of', 'the', 'population,', 'yet', 'commit', '52%', 'of', 'the', 'homicides,', 'and', 'when', 'you', 'factor', 'out', 'the', 'old,', 'handicapped,', 'and', 'children,', \"it's\", 'more', 'like', '8%', 'of', 'the', 'population', 'committing', '52%', 'of', 'the', 'murders.', 'Fuck', 'that', '8%.']\n",
      "['actually', 'less,', 'considering', 'some', '90%', 'of', 'the', 'perps', 'are', 'male,', 'so', 'you', 'have', 'an', 'even', 'smaller', 'portion', 'committing', 'a', 'shit', 'ton', 'of', 'violent', 'crime.', 'if', 'you', 'remove', 'gang-related', 'activity,', 'you', 'approach', 'a', 'normal', 'number', 'however.', 'my', 'point', 'was', 'discrimination', 'is', 'bad', 'when', 'it', 'violates', 'rights.']\n",
      "['Government', 'is', 'the', 'only', 'entity', 'subservient', 'to', 'rights.', 'The', 'People', 'must', 'not', 'harm.', 'I', \"don't\", 'have', 'to', 'allow', 'niggers', 'in', 'my', 'home', 'and', 'I', 'can', 'deny', 'him', 'access', 'on', 'the', 'basis', 'of', 'no', 'other', 'reason', 'than', 'his', 'race.']\n",
      "['back', 'to', 'this', 'silly', '\"access\"', 'shit', 'again.', 'if', 'you', 'live', 'in', 'Section', '8', 'housing,', 'you', \"don't\", 'get', 'to', 'pick', 'your', 'neighbors.', 'Fuck,', 'you', \"don't\", 'get', 'to', 'pick', 'your', 'neighbors', 'anyway.', \"don't\", 'like', 'it?', 'get', 'off', 'the', 'tit', 'or', 'gtfo', 'my', 'country.', 'you', 'also', \"don't\", 'get', 'to', 'control', 'who', 'enters', 'public', 'spaces', 'or', 'not.']\n",
      "['There', \"shouldn't\", 'be', 'a', 'tit,', 'and', 'most', 'would', 'leave', 'if', 'there', \"wasn't.\"]\n",
      "['no', 'no,', 'you', 'wanted', 'to', 'talk', 'Section', '8.', 'this', 'was', 'YOUR', 'point,', 'now', 'you', 'want', 'to', 'drop', 'it', 'when', 'it', 'blows', 'up', 'in', 'your', 'face?', 'like', 'i', 'said', 'before.', 'TYPICAL', 'WN', 'CLOWN.']\n",
      "['NPC', 'Cuckboy.']\n",
      "['POC', '=', 'Piece', 'of', 'Cunt', '?']\n",
      "['Who', 'is', 'more', 'grotesque?', 'A', 'White', 'who']\n",
      "['Do', 'we', 'even', 'call', 'a', 'mentally', 'handicapped', 'person', 'a', 'retard', 'anymore?', 'You', 'just', \"couldn't\", 'figure', 'out', 'what', 'the', 'correct', 'term', 'was', 'that', 'most', 'normal', 'people', 'call', 'a', 'mentally', 'handicapped', 'person?']\n",
      "['I', \"won't\", 'even', 'adjust', 'the', 'timing', 'on', 'an', 'engine', 'anymore', 'for', 'fear', 'of', 'using', 'the', 'R', 'word.']\n",
      "['meanwhile', 'in', 'NYC', 'some', 'idiot', 'retard', 'Lefty', 'puts', 'these', 'up', 'and', 'just', 'gave', 'everyone', 'more', 'reasons', 'to', 'vote', 'RED!', '--------------------------------', 'Tags', 'for', '#Q', 'drops,', 'saucy', 'notables', 'and', 'Breaking', 'News:', 'The', 'list', 'is', 'getting', 'lengthy', 'and', 'if', 'you', \"don't\", 'have', 'a', 'Pro', 'account', 'you', \"can't\", 'hit', 'the', 'star', 'and', 'favourite', 'an', 'account/Gabber', 'so', \"I've\", 'created', 'a', 'topic', 'which', 'you', 'can', 'do', 'that', 'to.', 'There', 'is', 'space', 'for', 'a', 'couple', 'more', 'adds', 'to', 'this', 'list.', 'Thank', 'you', 'all', 'so', 'much.', '@Gypsy124', '@StandingStrong', '@bodyhashead', '@easher555', '@wiIlluc20', '@RBril', '@meeceq', '@Bill71', '@TruthnotFM', '@Trillium', '@BlueBell', '@TheNiceTerrier', '@KimFoote', '@TrustGodWWG1WGA', '@12gaPATRIOT', '@JudyAdams64', '@Static_Anonymity', '@broncomomjsk', '@Girlwithaclue', '@KhadaffiDuck', '@WonderfullyDeplorable', '@Sorrel', '@1013Lana', '@SpunCopper', '@kasikirby', '@Imawake', '@jan_a_flower', '@Puddie_pie', '@billiesman', '@WANAGL', '@jasonzhaddad', '@ddt3500', '@ReverseTHIS', '@RestrainingOrderDave', '@Redbeard308', '@mudcreekmelody', '@MHughes68', '@squirrel327', '@qpatriotanon', '@DigN4Bones', '@Bad_Brad', '@IanForBritain', '@cathyfay', '@Cyrano', '@Mbarris01', '@CecilRoper', '@TheSentry', '@oakvalley', '@Hamuf', '@Alicemary', '@kriswithak', '@smileyshelly@Geirmund', '@Brittwoo', '@Millwood16', '@QuodVerum', '@Reefz', '@Preppedtogo1964', '@PatriotHelene', '@janisu', '@jgk', '@MartaVonRunge', '@LoveBeingADeplorableQGirl', '@AlaskaRaven', '@GameOfTrump', '@AlvinB1959', '@Kimharm', '@JonC17115069', '@JonC17115069', '@Breaking_Spectre', '@Callison56', '@SeldomSeenKid', '@paratisumus', '@harleychic', '@Livinbygrace', '@RealJesseCox', '@Beelover1972', '@LSherwood', '@ISA-BELLA']\n",
      "['So', 'glad', 'to', 'see', 'these', 'morons', 'wrecking', 'themselves', '......', '😵']\n",
      "['Unbelievable']\n",
      "['Start', 'with', 'DEPORT', 'ALL', 'MUSLIMS']\n",
      "['The', 'Future', 'Belongs', '2', 'Those', 'Who', 'Destroy', 'islame', '4', 'The', 'Sake', 'Of', 'Humanity!']\n",
      "['Is', 'it', 'in', 'Spanish', 'too?']\n",
      "['Yeah...forget', 'that', 'the', 'sign', 'implies', 'violence', 'against', 'those', 'who', 'wear', 'a', 'MAGA', 'hat...ignore', 'that...the', 'real', 'issue', 'for', 'NYC', 'is', 'the', '\"unlawful', 'defacement', 'of', 'city', 'waste', 'baskets\"...sad.']\n",
      "['Great', 'observation,', 'KC.', 'It', 'does', 'imply', 'violence.', 'Do', 'they', 'know', 'anything', 'but', 'hatred', 'and', 'violence?', 'I', 'think', 'we', 'know', 'the', 'answer', 'to', 'that', 'question.']\n",
      "['Sadly', 'but', 'true...']\n",
      "[\"Where's\", 'Sabo', 'when', 'we', 'need', 'him?', '@SABO', 'the', 'east', 'coast', 'needs', 'you!']\n",
      "['While', 'I', 'disagree', 'with', 'their', 'opinion,', \"I'm\", 'amazed', 'and', 'stunned', 'that', 'SOMEONE', 'ON', 'THE', 'LEFT', 'CAN', 'MEME!', 'In', 'the', 'three', 'years', 'the', 'alt', 'right', 'has', 'been', 'cranking', 'out', 'MOAB', 'after', 'MOAB', 'this', 'is', 'the', 'first', 'time', 'I', 'have', 'seen', 'return', 'fire', 'incoming.', 'You', \"don't\", 'figure', \"they're\", 'holding', 'a', 'Kekistani', 'against', 'their', 'will,', 'do', 'you?']\n",
      "['our', 'memes', 'never', 'condone', 'physically', 'hurting', 'the', 'Left', 'though', '-', 'this', 'ones', 'gives', 'the', 'impression', 'that', 'you', 'should']\n",
      "['even', 'our', 'Pinochet', 'helicopter', 'one?', '🤣']\n",
      "['What', 'this', 'sign', 'really', 'means', 'is,', '\"No', 'US', 'Constitution\".', 'Commiecrats', 'hate', 'our', 'freedoms!']\n",
      "[\"Can't\", 'control', 'us', 'if', \"we're\", 'free.']\n",
      "['They', 'have', 'never', 'had', 'control', 'of', 'me!']\n",
      "['Depiction', 'of', 'White', 'People,', 'this', 'is', 'Pure', 'Racism!']\n",
      "['Barack', 'Obama', 'is', 'half', 'nigger', 'and', 'half', 'Jew.', \"But's\", \"he's\", '100%', 'demon', 'from', 'the', 'pits', 'of', 'hell.']\n",
      "['As', 'bad', 'as', 'the', 'Communists', 'are:', 'Radical', 'Conservatives', 'will', 'vote', 'for', 'and', 'support', 'a', 'giant', 'police', 'state', 'that', 'can', 'then', 'be', 'handed', 'over', 'to', 'the', 'Communists.']\n",
      "['Let', 'me', 'guess', \"you'd\", 'rather', 'have', 'a', 'radical', 'liberal', 'democrat', 'police', 'state', 'which', 'Obummer', 'already', 'had', 'rolling', 'big', 'time', 'vs', 'a', 'conservative', 'state', 'which', 'tries', 'to', 'let', 'you', 'have', 'some', 'rights.', 'Killary', 'would', 'of', 'had', 'us', 'in', 'WW3', 'by', 'now,', 'by', 'design.']\n",
      "['Rex', 'your', 'a', 'funny', 'guy.', 'The', 'cabal', 'or', 'elites', 'want', 'never', 'ending', 'war', 'to', 'control', 'you', 'or', 'kill', 'you,', 'to', 'keep', 'you', 'in', 'fear', 'seems', 'to', 'be', 'working', 'well.']\n",
      "['The', 'boomers', 'are', 'the', 'exact', 'opposite.', 'They', 'just', 'sit', 'back', 'trying', 'to', 'look', 'cool', 'while', 'the', 'country', 'goes', 'bankrupt', 'and', 'is', 'over', 'run', 'by', 'welfare', 'whores.']\n",
      "['Blaming', '\"boomers\"', 'for', 'your', 'inadequacies', \"won't\", 'cut', 'it.', 'Go', 'find', 'something', 'else', 'to', 'whine', 'about.']\n",
      "['I', 'know', 'you', 'have', 'had', 'a', 'lot', 'of', 'experience', 'voting', 'for', 'devil', 'worshipers.', 'Then', 'walking', 'it', 'back.', 'Then', 'pretending', 'like', \"it's\", 'the', 'kids', 'who', 'built', 'this', 'culture.', 'Be', 'the', 'whole', 'world', 'is', 'looking', 'at', 'you', 'in', 'amazement.']\n",
      "[\"Iss't\", 'this', 'great.', 'All', 'these', 'boomers', 'do', 'is', 'blame', 'the', 'kids', 'for', 'how', 'messed', 'up', 'the', 'world', 'that', 'they', 'built', 'is.', 'A', 'sad', 'generation.']\n",
      "['The', 'blame', 'is', 'spread', 'across', 'multiple', 'generations,', 'we', 'are', 'the', 'first', 'set', 'of', 'generations', 'to', 'be', 'AWAKE,', 'the', 'cleanup', 'is', 'on', 'all', 'of', 'us.']\n",
      "['The', 'boomers', 'never', 'engaged', 'in', 'protests', 'that', 'shut', 'down', 'traffic.', 'Boomers', 'never', 'set', 'fire', 'to', 'buildings', 'and', 'looted', 'innocent', 'stores.', 'Boomers', 'never', 'attacked', 'people', 'who', 'spoke', 'their', 'minds.', 'Boomers', 'never', 'engaged', 'in', 'trans-gender', 'surgeries.', 'Get', 'a', 'clue,', 'dummy.']\n",
      "['I', 'am', 'a', 'boomer,', 'you', 'changed', 'the', 'argument', 'like', 'a', 'liberal.']\n",
      "['I', 'was', 'born', 'in', '1947...I', 'think', 'that', 'makes', 'me', 'a', 'boomer.']\n",
      "['then', 'you', 'remember', 'retarded', 'liberals', 'going', 'crazy', 'in', 'the', \"70's\"]\n",
      "['Absolutely.', 'Over', 'the', 'years,', 'liberals', 'have', 'only', 'changed', 'by', 'the', 'fact', 'that', \"they've\", 'produced', 'that', 'many', 'more', 'ignorant', 'sheeple.']\n",
      "['The', 'fight', 'is', 'GOOD', 'vs', 'evil,', 'it', 'has', 'nothing', 'to', 'do', 'with', 'dividing', 'us', 'by', 'generation,', 'or', 'race', 'or', 'gender', 'that', 'is', 'what', 'evil', 'wants,', 'we', 'all', 'need', 'to', 'fight', 'evil,', 'young', 'or', 'old', 'black', 'or', 'white,', 'male', 'or', 'female.']\n",
      "['Good', 'point,', 'Kenton----I', 'agree.', \"C'mon\", 'over', 'for', 'a', 'beer.........']\n",
      "['A', 'quote', 'from', 'some', 'random', 'place', 'on', 'net,', 'just', 'posted', 'here', 'because', \"it's\", 'funny', '…', 'and', 'true', ':', '\"Civil', 'liberty', 'and', 'freedom', 'in', 'America?', \"That's\", 'a', 'fucking', 'myth.', 'You', \"can't\", 'even', '\"not', 'bake', 'cakes\"', 'for', 'faggot', 'marriage', 'without', 'being', 'insulted', 'as', 'a', 'bigot.\"']\n",
      "['SJWS', 'WHINE', 'THAT', 'DWAYNE', '‘THE', 'ROCK’', 'JOHNSON', 'IS', 'NOT', 'BLACK', 'ENOUGH', 'TO', 'PLAY', 'JOHN', 'HENRY', 'Dwayne', '‘The', 'Rock’', 'Johnson', 'is', 'getting', 'flack', 'for', 'casting', 'himself', 'as', 'an', 'African-American', 'folklore', 'legend', 'in', 'an', 'upcoming...', 'Daily', 'Mail', '-', 'OCTOBER', '12,', '2018', 'https://www.infowars.com/sjws-whine-that-dwayne-the-rock-johnson-is-not-black-enough-to-play-john-henry/']\n",
      "['Yet', 'they', 'have', 'no', 'problem', 'casting', 'blacks', 'in', 'white', 'roles.', 'I', 'dont', 'want', 'to', 'see', 'a', 'nigger', 'playing', 'George', 'Washington.', 'Fuck', 'the', 'idiots']\n",
      "[\"I'd\", 'totally', 'go', 'on', 'that', 'show', \"'my\", 'lottery', 'dream', \"home'\", 'when', 'I', 'win', 'the', '1.6', 'billion', 'tonight', 'if', 'that', 'faggot', 'that', 'hosts', 'the', 'show', 'lets', 'me', 'run', 'him', 'over', 'with', 'a', 'steamroller', 'in', 'the', 'driveway', 'of', 'the', 'mansion', 'I', 'choose.', 'GAY', 'faggot.']\n",
      "['Read', 'that', 'clearly!', 'The', 'violence', 'and', 'screeching', 'and', 'screaming', 'will', 'not', 'stop', 'until', 'they', 'are', 'in', 'control!', 'Let', 'them', 'pitch', 'their', 'hissy', 'fits', 'like', '2', 'year', 'olds', 'and', 'thugs', '-', 'keep', 'arresting', 'them', 'or', 'ignore.', 'WE', 'WILL', 'NOT', 'STOP', 'WINNING', '!!', 'FIGHT!', '#KAG', 'Elaine']\n",
      "['Cunt']\n",
      "['It', 'is', 'impossible', 'to', 'figure', 'out,', 'if', \"you're\", 'a', '5', 'year', 'old.', 'Or', 'maybe', '85.', 'There', 'are', 'a', 'lot', 'of', 'retards', 'here', 'so', 'even', 'retarded', 'people', 'can', 'figure', 'it', 'out.', 'So', 'what', 'is', 'it,', 'stupider', 'than', 'the', 'retarded?']\n",
      "['New', 'Jersey:', 'Muslim', 'inmate', 'sues', 'jail,', 'charging', 'discrimination', 'against', 'Muslims', '#Islam', '#Jihad', '#US', 'https://www.jihadwatch.org/2018/10/new-jersey-muslim-inmate-sues-jail-charging-discrimination-against-muslims']\n",
      "['looks', 'like', 'a', 'nigger', 'to', 'me']\n",
      "['My', 'Prediction:', 'By', '2022', \"we're\", 'going', 'to', 'see', 'two', 'landmark', 'cases', 'in', 'the', 'U.S.', 'Supreme', 'Court.', 'U.S.', 'vs', 'Clinton', 'and', 'U.S.', 'vs', 'Obama.', 'What', 'do', 'you', 'guys', 'think', 'the', 'decison', 'will', 'be?', 'My', 'guess', 'is', '5', 'to', '4.']\n",
      "['Hopefully', 'Spearchucker', 'Obama', 'goes', 'to', 'jail', 'and', 'gets', 'raped', 'every', 'hour.']\n",
      "['That', 'might', 'be', 'tough.', 'I’ll', 'bet', 'that', 'nigger', 'has', 'money', 'spread', 'Out', 'all', 'over', 'the', 'world.', 'That', '$6', 'billion', 'he', 'and', 'Cankles', 'stole', 'from', 'the', 'state', 'department', 'is', 'probably', 'spread', 'around', 'to', 'hundreds', 'of', 'banks.', 'They', 'need', 'to', 'send', 'Delta', 'Force', 'in', 'to', 'take', 'his', 'ass', 'out.', 'You', 'know', 'those', 'guys', 'would', 'love', 'to', 'take', 'out', 'Obama.']\n",
      "['Red', 'nigger', 'skunks', \"aren't\", 'people', '@h4rdm0us', 'you', 'know', 'that']\n",
      "[\"That's\", 'not', 'a', '\"reason\"', 'Kalama', '...', \"it's\", 'a', '\"campaign', 'slogan\"', '-', 'Kind', 'of', 'like', \"Hillary's\", '\"Stronger', 'Together\"', '-', 'Yet,', 'all', \"she's\", 'done', 'is', 'tear', 'this', 'country', 'apart', 'Results', 'matter', '-', 'JOBS', 'JOBS', 'JOBS', 'vs.', 'Those', 'jobs', 'just', \"aren't\", 'coming', 'back', '-', '....', \"I'll\", 'stick', 'with', 'the', 'magic', 'wand']\n",
      "['i', 'wonder', 'if', 'her', 'views', 'on', 'equality', 'include', 'a', 'quality', 'cunt', 'kicking', 'session?']\n",
      "[]\n",
      "['Give', 'the', 'Boer', 'refugee', 'status', 'in', 'America', 'then', 'cut', 'all', 'foreign', 'aide', 'to', 'South', 'Africa', 'and', 'their', 'neighboring', 'countries.', 'When', 'communist', 'China', 'picks', 'up', 'their', 'tab', 'and', \"they're\", 'begging', 'for', 'the', 'white', 'devil', 'to', 'save', 'them', 'like', 'the', 'nigh', 'jeers', 'in', 'Zimbabwe', 'are,', 'put', 'economic/trade', 'sanctions', 'on', 'them', 'and', 'watch', 'them', 'fucking', 'starve.']\n",
      "['No', 'China', 'wants', 'control', 'of', 'Africa', 'for', 'its', 'resources.', 'Just', 'like', 'the', 'rest', 'of', 'the', 'elites.', 'Gold', 'and', 'Diamond', 'mines', 'etc.']\n",
      "[\"That's\", 'what', 'I', 'was', 'saying.', 'The', 'only', 'reason', 'world', 'powers', 'give', 'out', 'foreign', 'aide', 'is', 'to', 'control', 'smaller', 'countries.', 'But', 'under', 'the', 'control', 'of', 'China', \"they'd\", 'lose', 'their', 'black', 'population', 'just', 'like', 'Uganda.', 'With', 'every', 'passing', 'day,', 'these', 'functionally', 'retarded', '(average', 'IQ', 'of', '65)', 'people', 'put', 'themselves', 'into', 'a', 'deeper', 'hole', 'for', 'their', 'future.', 'I', 'say', 'let', 'them', 'burn.']\n",
      "['#Pelosi', 'Endorses', '‘Collateral', 'Damage’', 'to', 'Those', '‘Who', 'Do', 'Not', 'Share', 'Our', 'View’:', '‘So', 'Be', 'It’', '-', '#Liberalism', 'http://www.cnsnews.com/blog/craig-bannister/pelosi-endorses-collateral-damage-those-who-do-not-share-our-view-so-be-it', 'More', 'Headlines:', 'http://www.theamerican-messenger.com']\n",
      "['Get', 'on', 'the', 'Front', 'line', 'Cunt', '!!', 'Quit', 'mouthin', 'off', '&', 'Get', 'out', 'there', '!!']\n",
      "['check', 'out', 'my', 'music', 'page', 'https://www.reverbnation.com/nitemare817']\n",
      "['fuck', 'off', 'nigger']\n",
      "['fuck', 'off', 'nigger', 'boy']\n",
      "['NYPD', 'Looks', 'to', 'Charge', '9', 'Proud', 'Boys', 'With', 'Assault', 'for', 'Manhattan', 'Fight', 'Three', 'protesters', 'described', 'as', 'antifa', 'are', 'also', 'wanted', 'after', 'police', 'say', 'they', 'threw', 'bottles', 'and', 'punches', 'during', 'the', 'incident.', '>>', 'Masked', 'Antifa', 'attacked', '&', 'suckerpunched', 'some', 'Proud', 'Boys', 'and', 'got', 'their', 'asses', 'kicked,', 'which', 'is', 'why', 'the', 'NYPD', 'arrested', 'three', 'Antifa', 'attackers', 'and', 'no', 'Proud', 'Boys.', 'I', 'am', 'just', 'about', 'certain', 'they', 'are', 'now', 'moving', 'to', 'charge', 'the', 'Proud', 'Boys', 'at', 'the', 'direction', 'of', 'uberliberal', 'Mayor', 'DeBlasio.', '(Daily', 'Beast)', 'https://archive.fo/2Jrht']\n",
      "['Get', 'the', 'phuck', 'out', 'of', 'all', 'the', 'cities.', \"You're\", 'retarded', 'if', 'you', 'think', 'you', 'can', 'be', 'an', 'active', 'RW', 'activist', 'in', 'these', 'seditionist', 'hell-holes.']\n",
      "['Actually,', 'I', 'am', 'glad', 'they', 'are', 'willing', 'to', 'get', 'into', 'the', 'faces', 'of', 'the', 'left', 'on', 'their', 'own', 'turf.', 'The', 'left', 'should', 'not', 'be', 'allowed', 'to', 'own', 'any', 'portion', 'of', 'America', 'totally', 'unopposed.']\n",
      "['They', 'own', 'the', 'cities.', 'They', 'are', 'asking', 'to', 'be', 'imprisoned', 'and', 'raped.', 'GET', 'OUT', 'NOW.']\n",
      "['The', 'British', 'and', 'their', 'Tory', 'allies', 'once', 'owned', 'Boston,', 'until', 'a', 'few', 'brave', 'patriots', 'stood', 'up', 'to', 'them,', 'some', 'at', 'the', 'cost', 'of', 'their', 'own', 'lives.', 'Freedom', 'is', 'not', 'free.', 'Running', 'away', 'like', 'cowards', 'is', 'not', 'the', 'American', 'way.', 'The', 'Proud', 'Boys', 'are', 'doing', 'the', 'right', 'thing', 'for', 'our', 'nation.', 'We', 'should', 'support', 'them', 'any', 'way', 'we', 'can.']\n",
      "['The', 'demographics', 'of', 'Boston', 'Circa', '1775', 'was', 'quite', 'different', 'from', \"today's\", 'New', 'York', 'City.', 'New', 'York', 'City', 'is', 'not', 'America...nor', 'is', 'L.A.,', 'SF,', 'Austin,', 'Miami', 'or', 'a', 'plethora', 'of', 'other', 'cities.', 'They', 'do', 'not', 'acknowledge', 'your', 'right,', 'accorded', 'to', 'you', 'by', 'God,', 'to', 'defend', 'yourself', 'with', 'a', 'weapon.', 'Why', 'make', 'excuses', 'for', 'the', 'caulk', 'suckers', 'in', 'the', 'city?', \"Fuck'em.\"]\n",
      "['Please', 'do', 'not', 'falsify', 'my', 'views.', 'I', 'made', 'no', \"'excuses'\", 'for', 'any', 'libs,', 'and', 'you', 'know', 'it.', 'We', 'give', 'no', 'ground', 'to', 'the', 'enemy.', 'If', 'you', 'want', 'to', 'surrender', 'chunks', 'of', 'America', 'to', 'leftists,', 'you', 'are', 'entitled', 'to', 'your', 'opinion,', 'but', 'do', 'not', 'expect', 'me', 'to', 'agree', 'with', 'such', 'defeatism.']\n",
      "['If', 'you', 'live', 'in', 'these', 'enclaves', 'you', 'are', 'feeding', 'the', 'beast', 'with', 'your', 'talent', '(work),', 'taxes,', 'an', 'tacit', 'consent', 'to', 'rule', 'you.', 'You', 'are', 'arguing', 'for', 'fraternization', 'with', 'the', 'enemy.']\n",
      "['Donald', 'Trump', 'lives', 'in', 'NYC.', 'So', 'do', 'a', 'lot', 'of', 'conservatives', 'that', 'fight', 'leftism', 'every', 'day', 'of', 'their', 'lives', 'instead', 'of', 'running', 'in', 'the', 'face', 'of', 'overwhelming', 'odds.', 'They', 'will', 'cede', 'no', 'ground', 'to', 'the', 'enemy.', 'This', 'is', 'the', 'true', 'American', 'spirit.']\n",
      "['Show', 'me', 'where', 'the', 'leftists', 'are', 'losing', 'due', 'to', 'these', '\"heroic\"', 'conservative', 'warriors.']\n",
      "['What', 'a', 'complete', 'brainwashed', 'cunt', '-', 'I', 'feel', 'horrible', 'for', 'her', 'kids', '-', 'we', 'should', 'probably', 'call', 'CPS', 'to', 'make', 'sure', 'theyre', 'safe']\n",
      "['I', 'got', 'your', 'Merrick', 'Garland', 'swinging', 'between', 'my', 'legs', 'nigger', 'fuck!']\n",
      "['https://l.facebook.com/l.php?u=https%3A%2F%2Fcanadafreepress.com%2Farticle%2Fbehind-the-honduran-march-on-america-barack-obama%3Ffbclid%3DIwAR3yE5nsQXSgjRMnD7P8FMPQD-H3GXsFk_TUumMYFdrXc8PnZHhjeh-DYK8%23.W8iri4ewDsE.facebook&h=AT3xC3_4qp-SjPooc6TVy_8uCOICWZ5VEOs5C-PpNiKjaLCgyARRKk-cgGbiAxc9UlAJMAm7pdHf3UGNknR8LJLBd3_zkndGsIzig2Ge1_81ocEzQ_gakdgD8uMt8tEXGn2s3vPIBE1xg5OeW-YlxZjCp1l7rqflzFxzhtAF7WaPyL_CHJZaXueuPy6aBD5BSD_llexfbqHYGDVevG5315TPRTx7Heptfv4YiQbfzTfoOh1pjxmbmr0JddSLMeao8_14AQX5ASroB2AW0EoRVtIL0-N5PxwRdIwKnVE1QEb7Vl64MGcSTWa3zmx_089koZiSqNbZGnTfiQ3XUZD_7ptdToAd38wUE9QxJMxMEhZSIsTjAI3b8GisBtwVF4sIpSxW7-2XAMJ6wlZQhpXe']\n",
      "['the', 'muslim', 'nigger', 'obamaosama', 'needs', 'dead']\n",
      "['Zuckerberg', 'Faces', 'Anger', 'Over', 'FACEBOOK', \"Exec's\", 'Kavanaugh', 'Support...', 'https://kek.gg/u/xxPV']\n",
      "['How', 'retarded', 'can', 'people', 'get?', 'Don’t', 'ask....']\n",
      "['Jewish', 'owned', 'Global', 'banking', 'giant', 'Goldman', 'Sachs', 'has', 'declared', 'that', 'curing', 'patients', 'of', 'terminal', 'illnesses,', 'such', 'as', 'cancer,', 'is', 'not', 'a', '\"sustainable', 'business', 'model.\"', 'https://neonnettle.com/news/4072-goldman-sachs-curing-cancer-is-not-a-sustainable-business-model-', 'Jews', 'are', 'our', 'FRIENDS,', 'right', 'Israel-Firsters?']\n",
      "['Michael,', 'are', 'you', 'a', 'child,', 'or', 'do', 'you', 'just', 'act', 'that', 'way', 'on', 'the', 'Internet?', 'Supposing', 'that', 'American', \"Jew's\", 'are', 'in', 'any', 'way', 'associated', 'with', \"Jew's\", 'in', 'their', 'native', 'land', '(Israel),', 'is', 'so', 'ignorant', 'as', 'to', 'call', 'into', 'question', 'your', 'sanity.', 'Judaism', 'in', 'America', 'is', 'in', 'no', 'way', 'a', 'reflection', 'of', 'that', 'in', 'Israel.', 'In', 'America', 'it', 'has', 'taken', 'the', 'least', 'path', 'of', 'resistance,', 'and', 'gone', 'full', 'leftist.']\n",
      "['As', 'I', 'said', 'previously,', 'you', 'argue', 'like', 'a', 'child,', 'although', 'with', 'additional', 'feedback', \"I'd\", 'argue', 'a', 'retarded', 'one', 'at', 'best.']\n",
      "['The', 'more', 'I', 'see', 'the', 'general', 'attitude', 'of', 'nationalists', 'the', 'more', 'it', 'seems', 'the', 'will', 'of', 'European', 'men', 'has', 'permanently', 'waned', 'away.', 'We', 'endlessly', 'discuss', 'a', 'disloyal', 'GOP', 'party.', 'We', 'take', 'no', 'initiative', 'to', 'save', 'ourselves.', 'What', 'will', 'those', 'of', 'us', 'who', 'bothered', 'to', 'have', 'children', 'tell', 'them', 'about', 'the', 'nightmare', 'we', 'are', 'bringing', 'them', 'into?', 'Sorry', 'son', 'I', 'voted', 'Republican?', 'I’m', 'disgusted.']\n",
      "['If', 'we', 'assume', 'everything', 'you', 'said', 'is', 'true,', 'it', 'cuts', 'both', 'ways.', 'What', 'are', 'you', 'going', 'to', 'tell', 'YOUR', 'children?', '\"Sorry', 'son,', 'at', 'least', 'I', 'complained', 'to', 'people', 'who', 'vote', 'Republican\".', 'Like', 'it', 'or', 'not,', 'the', 'GOP', 'is', 'the', 'flashpoint', 'in', 'the', 'political', 'struggle', 'between', 'Jews', 'and', 'Gentiles.', 'The', 'Jews', 'spent', 'one', 'hundred', 'years', 'marching', 'through', 'the', 'institutions.', \"It's\", 'not', 'realistic', 'to', 'expect', 'that', 'we', 'would', 'claw', 'those', 'institutions', 'back', 'from', 'them', 'overnight', 'or', 'over', 'the', 'course', 'of', 'an', 'election', 'or', 'three.']\n",
      "['The', 'GOP', 'is', 'as', 'irrelevant', 'as', 'the', 'conservatives', 'and', 'the', '“Christian', 'Socialists”', 'were', 'in', 'Hitler’s', 'time.', 'Something', 'new', 'must', 'be', 'built.']\n",
      "['\"Sorry', 'son,', 'at', 'least', 'I', 'asked', 'Republican', 'voters', 'to', 'build', 'something', 'new.\"', 'Still', 'cuts', 'both', 'ways.']\n",
      "['I', 'built', 'what', 'I', 'could.', 'I', 'was', 'slandered,', 'deplatformed,', 'left', 'on', 'an', 'island', 'alone.', 'It', 'wasn’t', 'just', 'Antifa,', 'police,', 'FBI,', 'the', 'right', 'wing', 'viciously', 'attacked', 'me.', 'Based', 'Stickman', 'tried', 'to', 'gouge', 'my', 'eyes', 'out', 'in', 'a', 'hotel,', 'proudboys', 'shut', 'down', 'our', 'event', 'Antifa', 'style,', 'my', 'family', 'was', 'threatened', 'and', 'despite', 'everything', 'I', 'did', 'the', 'slander', 'was', 'believed', 'and', 'what', 'I', 'built', 'was', 'destroyed']\n",
      "['I’m', 'afraid', 'it', 'will', 'be', 'nothing', 'to', 'what', 'my', 'son', 'will', 'face', 'if', 'something', 'doesn’t', 'change']\n",
      "['I', \"don't\", 'see', 'how', 'the', 'current', 'trajectory', 'will', 'change', 'if', 'whites', 'remove', 'themselves', 'from', 'the', 'political', 'process.', \"That's\", 'why', 'I', 'stopped', 'talking', 'to', 'libertarians', 'and', 'AnCaps.']\n",
      "['I', 'don’t', 'think', 'street', 'action', 'and', 'movement', 'building', 'are', 'abstention', 'from', 'the', 'political', 'process.', 'Continuing', 'to', 'vote', 'for', 'people', 'who', 'don’t', 'represent', 'your', 'interests', 'and', 'who', 'desperately', 'cater', 'to', 'people', 'who', 'hate', 'you', 'is', 'worse', 'than', 'abstention', 'imo', 'BLM', 'disrupting', 'a', 'Bernie’s', 'sanders', 'event', 'during', 'the', 'election', 'is', 'why', 'those', 'people', 'have', 'power.']\n",
      "['They', 'won’t', 'wake', 'up', 'because', 'we', 'continue', 'to', 'vote', 'for', 'them.', 'So', 'they', 'work', 'for', 'votes', 'they', 'aren’t', 'getting.', 'If', 'they', 'get', 'scared', 'for', 'one', 'election', 'they', 'might', 'worry', 'about', 'what', 'their', 'white', 'constituents', 'want', 'a', 'little', 'more.']\n",
      "['Again,', \"you're\", 'ignoring', 'the', 'fact', 'that', 'caucuses', 'exist.', \"You're\", 'ignoring', 'that', 'these', 'people', 'can', 'be', 'primaried', 'out.', \"It's\", 'starting', 'to', 'get', 'obnoxious.', 'You', 'can', 'achieve', 'everything', 'you', 'want', 'to', 'achieve', 'through', 'non-participation,', 'according', 'to', 'you.', 'If', \"you're\", 'right,', \"you'll\", 'be', 'able', 'to', 'demonstrate', 'it,', 'even', 'if', 'I', \"don't\", 'agree', 'with', 'you,', 'which', 'I', \"don't.\", 'Agorism', \"isn't\", 'going', 'to', 'work.', 'Sorry', 'man.']\n",
      "['\"Only', 'a', \"'moron'\", 'would', 'think', 'we', 'are', 'safe', 'with', 'trump.\"']\n",
      "['Trump', 'may', 'not', 'be', 'our', 'guy', 'but', 'he', 'proved', 'in', 'the', 'primaries', 'that', \"it's\", 'possible', 'to', 'mount', 'a', 'successful', 'primary', 'challenge', 'against', 'multiple', 'deep', 'state', 'insiders', 'and', 'media', 'favorites.', 'Ron', 'Paul', 'was', 'a', 'cunt', 'hair', 'away', 'from', 'achieving', 'the', 'same,', 'himself.']\n",
      "['Jared', 'I', 'love', 'Ron', 'Paul', 'but', 'unfortunately', 'ya', \"caan't\", 'do', 'much', 'with', 'a', 'cunt', 'hair', 'or', 'even', 'a', 'red', 'cunt', 'hair']\n",
      "['Whose', 'the', 'nigger', 'guy', 'on', 'the', 'far', 'right', 'with', 'the', 'wig?']\n",
      "['Why,', \"that's\", 'Michael.', 'However,', \"I'm\", 'looking', 'at', 'Bush', 'Sr.', 'and', 'it', 'appears', 'Satan', 'has', 'already', 'claimed', '60%', 'of', 'him', 'before', 'his', 'final', 'breath.', 'Seems', 'like', 'a', 'breach', 'of', 'contract', 'to', 'me.']\n",
      "['oh', 'yeh..I', 'should', 'have', 'known']\n",
      "['Hahaha,', 'Goddamn,', 'that', 'photo', 'is', 'depressing.', 'Do', 'you', 'think', 'Bush', 'is', 'still', 'in', 'on', 'the', 'blood', 'orgies?']\n",
      "['@Soprano', \"that's\", 'a', 'hoot!']\n",
      "['@Markered67', '.', 'I', \"don't\", 'think', 'so.', 'Looks', 'to', 'me', 'like', 'they', 'have', 'been', 'draining', 'him', 'cause', 'hes', 'bout', 'to', 'go', 'anyway.', \"He's\", 'takin', 'one', 'for', '\"the', 'Gipper\"!!🙃😁']\n",
      "['Scull', 'and', 'Bones...all', 'of', 'them!']\n",
      "['@Soprano', 'Bingo!']\n",
      "['.@Alyssa_Milano:', 'if', '“men', 'have', 'a', 'hard', 'time', 'right', 'now”', 'that', 'is', 'the', 'way', 'it', 'has', 'to', 'be', '“for', 'us', 'to', 'have', 'the', 'equality', 'and', 'security', 'in', 'our', 'country.”', 'https://kek.gg/u/t8Yf']\n",
      "['Poor', 'stupid', 'cunt', \"doesn't\", 'have', 'an', 'once', 'of', 'brain', 'matter...needs', 'to', 'get', 'a', 'better', 'script', 'writer.']\n",
      "['BREAKING', '•', 'Trump', 'Prepared', 'To', 'Cut', 'UN', 'Funding', 'Over', 'Its', 'Support', 'For', 'Illegal', 'Migrant', 'Caravan', 'https://www.youtube.com/watch?v=dGeb0af_SEE']\n",
      "['then', 'tell', 'Trump', 'to', 'quit', 'preparing', 'and', 'just', 'do', 'it!']\n",
      "['600', 'MILLION', 'wetbacks', 'planned', 'to', 'be', 'sent', 'here', 'by', 'the', 'UN...', 'not', 'including', 'the', 'niggers,', 'street', 'shitters,', 'goat', 'fuckers', 'and', 'ching', 'chongs....', 'Jesus', '.....this', 'is', 'a', 'fucking', 'mess']\n",
      "['im', 'starting', 'to', 'question', 'if', 'the', 'butler', 'plan', 'is', 'going', 'to', 'be', 'enough...']\n",
      "['I', 'think', 'we', 'need', 'a', 'few', 'nukes']\n",
      "['i', 'think', 'we', 'need', 'to', 'get', 'our', 'hands', 'on', 'Dr.', 'Vladimir', \"Gavreau's\", 'research', 'https://www.youtube.com/watch?v=B7ChrutqJ40']\n",
      "['I', 'think', \"it's\", 'time', 'that', 'rap', 'music', 'be', 'given', '7Hz', 'backbeats.', \"It'll\", 'sound', 'great', 'in', 'nigger', 'cars...']\n",
      "['I', 'will', 'be', 'teaming', 'with', 'borzoi', 'from', 'poz', 'button', 'for', 'a', 'new', 'program.', 'Stay', 'tuned!']\n",
      "['A', 'chinaman', 'and', 'a', 'commie', 'teaming', 'up?', 'The', 'great', 'proletarian', 'cultural', 'revolution', 'is', 'upon', 'us!']\n",
      "['OCTOBER', '15,', '2018', 'TREASON:', 'Trudeau', 'Government', 'Trying', 'To', 'Help', 'ISIS', 'Terrorists', '–', 'Including', '‘Jihadi', 'Jack’', '–', 'Come', 'To', 'Canada', 'Fair', 'Use:', 'https://www.spencerfernando.com/2018/10/15/treason-trudeau-government-trying-to-help-isis-terrorists-including-jihadi-jack-come-to-canada/', '~', 'Spencer', 'Fernando']\n",
      "['well,', \"obama's\", 'gone,', 'somebody', 'has', 'to', 'do', 'it...']\n",
      "['sort', 'of', 'sad', 'Obama', 'is', 'gone...', 'all', 'us', 'white', 'boys', 'need', 'to', 'have', 'a', 'nigger', 'around', 'to', 'laugh', 'at', '(', '<', ':']\n",
      "[\"'lier'?\", 'Are', 'you', 'a', 'retard', 'or', 'something?']\n",
      "[]\n",
      "['Useless', 'nigger']\n",
      "['I', 'hope', 'this', \"isn't\", 'red', 'on', 'red', 'crime?']\n",
      "['how', 'is', 'that', 'possible,', 'since', 'small', 'pox', \"hasn't\", 'been', 'in', 'the', 'world', 'since', '1973', 'or', 'so?']\n",
      "['how', 'is', 'a', 'person', 'a', 'retard', 'by', 'stating', 'facts??']\n",
      "['I', 'still', 'remember', 'one', 'of', 'my', 'followers,', 'keep', 'in', 'mind', 'a', 'GamerGater,', 'got', 'on', 'my', 'case', 'a', 'few', 'weeks', 'ago', 'when', 'I', 'said', 'that', 'MovieBob', 'was', 'a', 'pedophile', '\"Umm,', 'Carl,', \"that's\", 'pretty', 'damning,', 'you', \"can't\", 'just', 'say', 'that,', \"where's\", 'your', 'proof?\"', 'Proof,', 'you', 'dumb', 'fucker?', 'Proof', 'is', 'this', 'fat', 'needle', 'dick', 'faggot', 'rubs', 'up', 'against', 'little', 'boys', 'while', 'wearing', 'a', 'mario', 'costume.', 'Just', 'wait', 'a', 'year', 'for', '\"proof\"']\n",
      "['.People', \"shouldn't\", 'be', 'scared', 'into', 'thinking', 'that', 'they', \"won't\", 'ever', 'have', 'a', '2nd', 'opportunity', 'to', 'prove', 'they', 'can', 'be', 'righteous.', 'Yes,', 'the', 'first', 'time', 'they', 'die', 'is', 'appointed', 'for', 'them', 'so', 'they', 'can', '\"SEE\"', 'what', 'the', 'end', 'results', 'of', 'sin', 'bring,', 'i.e.', 'nuclear', 'war', 'and', 'total', 'decimation', 'of', 'the', 'population.', 'but', 'the', '2nd', 'death', 'is', 'the', 'one', 'that', 'is', 'eternal,', 'not', 'the', 'first', 'one.']\n",
      "['Book,', 'chapter,', 'verse?']\n",
      "['Asking', 'you', 'a', 'question', 'is', '\"spewing', 'lies\"?', 'Nutcase.', 'I', \"didn't\", 'ask', 'you', 'to', 'impress', 'me.', 'I', 'asked', 'you', 'where', 'I', 'can', 'verify', 'your', 'position', 'in', 'scripture.', \"That's\", 'when', 'you', 'acted', 'like', 'the', 'cunt', 'you', 'are.', 'Way', 'to', 'represent', 'Yah!', 'Bitter', 'little', 'idiot.']\n",
      "['The', 'DailyStormer', 'is', 'responsible', 'for', 'the', 'pro-Trump', 'spam.', 'Weaponizing', 'anti-Semitism', \"they're\", 'able', 'to', 'divide', 'Jews', 'into', 'two', 'groups:', 'Liberals', 'and', 'Zionists.', 'By', 'demonizing', 'the', 'open-border', 'Jews', 'they', 'effectively', 'tie', 'anti-Multiculturalism', 'to', 'the', 'pro-Zionist', 'movement.', 'Jews', 'create', 'the', 'problem', 'only', 'to', 'offer', 'their', 'own', 'solution.', 'DailyStormer', 'is', 'MOSSAD.']\n",
      "[\"Mossad's\", 'got', 'the', 'lulz!']\n",
      "['Oh,', 'sorry', 'to', 'reply', 'out', 'of', 'turn.', \"I'm\", 'retarded', ':3']\n",
      "['I', 'see', \"you'll\", 'play', 'your', 'little', 'lawyer', 'game', 'until', 'you', \"CAN'T\", 'answer', 'my', 'question,', '@Ehrmantraut,', 'then', 'you', 'shut', 'up', 'and', 'pretend', 'it', 'never', 'happened.', 'Good', 'luck', 'crying', 'about', 'guns', 'here', 'on', 'Gab,', \"you're\", 'gonna', 'need', 'it.']\n",
      "[\"You're\", 'just', 'mad', 'because', 'I', 'pointed', 'out', 'that', 'you', \"don't\", 'know', 'your', 'ass', 'from', 'your', 'elbow.']\n",
      "['LOL.', 'A', 'California', 'faggot', 'who', 'has', 'never', 'seen', 'a', 'Glock', 'pretends', 'to', 'be', 'a', 'lawyer', 'on', 'Gab', 'on', 'a', 'mission', 'to', 'sue', 'them.', 'Keep', 'running', 'your', 'cocksucker,', \"it's\", 'raining', 'here', 'today,', 'and', \"I'm\", 'bored.']\n",
      "['Let', 'the', 'individuals', 'been', 'Seen', 'and', 'Heard', '😃']\n",
      "['NPC', 'Nasty', 'Pathetic', 'Cunt']\n",
      "['She', 'thinks', 'she’s', 'relevant', 'enough', 'to', 'be', 'recognized', 'in', 'public.', 'Imagine', 'being', 'this', 'egotistical', 'over', 'simply', 'not', 'being', 'shot.']\n",
      "['dumb', 'cunt', 'thinks', 'her', 'opinion', 'has', 'done', 'anything', 'but', 'increase', 'gun', 'sales', 'and', 'add', 'gun', 'owners', 'bitch', 'needs', 'one', 'of', 'these.......']\n",
      "['Da', 'fuck', 'is', 'this', 'all', 'about?', 'Lurking', 'around', 'graveyards', 'at', 'night', '@SeanEast', '@QueenSweary']\n",
      "['What', 'the', 'fuck!!?!', 'Debbie', 'is', 'a', 'proper', 'fucking', 'smackhead!!!', 'It', 'probably', 'all', 'started', 'in', 'graveyards...', 'sniffing', 'glue', 'when', 'she', 'was', '10.']\n",
      "['Stop', 'being', 'a', 'massive', 'nonce', 'cunt', 'and', 'get', 'laid', 'you', 'fucking', 'incel']\n",
      "['Haha', 'Silence', 'Debbie...', 'you', 'filthy', 'fucking', 'smackrat!']\n",
      "['I', \"can't\", 'tell', 'if', \"she's\", 'kinda', 'hot', 'or', 'if', 'she', 'kinda', 'looks', 'like', 'a', 'Flounder.']\n",
      "['Waynetta...']\n",
      "['haha', 'she', \"ain't\", 'hot..', 'bag']\n",
      "['she', \"can't\", 'she', 'has', 'to', 'give', 'it', 'away', 'for', 'some', 'weed', 'what', 'a', 'ferking', 'dog']\n",
      "['Cum', 'to', 'muh', 'bedside,', 'Lucy', 'Labianca.', \"I've\", 'got', 'some', 'girth', \"that'll\", 'make', 'you', 'squeal.', 'Call', 'me', \"'Groper\", \"Von'\", 'when', 'you', 'climax.', 'https://youtu.be/WoI0pIg8_Yw']\n",
      "['***IMPORTANT', 'NOTICE***', 'As', 'you', 'know,', 'many', 'Conservative', 'accounts,', 'actually', 'THOUSANDS,', 'have', 'recently', 'been', 'purged', 'from', 'Facebook', 'for', '\"fake', 'news\".', 'This', 'account,', 'DeepStateNation,', 'is', 'run', 'by', 'a', 'leftist', 'woman', 'by', 'the', 'name', 'of', 'Conover', 'Kennard,', 'who', 'posted', 'my', \"husband's\", 'and', 'my', 'personal', 'information', 'in', 'one', 'of', 'her', '\"articles\",', 'including', 'our', 'names,', 'the', 'town', 'we', 'live', 'in', 'and', 'other', 'private', 'information.', 'She', 'actually', 'called', 'the', 'police', 'department', 'and', 'threatened', 'them,', 'claiming', 'if', 'they', \"didn't\", 'fire', 'my', 'husband', 'she', 'would', 'make', 'them', 'regret', 'it.', 'What', 'a', 'loon.', 'Yes.', 'The', 'police', 'just', 'laughed', 'but', 'her', 'followers', 'sent', 'death', 'threats,', 'rape', 'threats', 'to', 'myself', 'and', 'our', 'child,', 'threatened', 'to', 'kill', 'my', 'pets,', 'etc.', 'Her', 'actions', 'had', 'consequences', 'for', 'us', 'that', 'lasted', 'over', 'a', 'year.', 'Leftists,', 'following', 'this', \"woman's\", 'lead,', 'even', 'came', 'to', 'our', 'home,', 'placed', 'dead', 'animals', 'in', 'our', 'yard,', 'filed', 'false', 'reports', 'with', 'DCFS', 'and', 'swatted', 'us,', 'in', 'an', 'attempt', 'to', 'have', 'us', 'killed.', 'I', 'could', 'not', 'let', 'our', 'child', 'out', 'of', 'my', 'sight.', 'Her', 'followers', 'posted', 'photos', 'of', 'themselves', 'in', 'my', 'town.', 'Why', 'am', 'I', 'telling', 'you', 'this?', 'Because', 'I', 'need', 'a', 'favor.', 'I', 'am', 'asking', 'you', 'to', 'report', 'the', 'page', 'as', 'fake', 'news', 'and', 'ask', 'everyone', 'you', 'know', 'to', 'do', 'the', 'same.', 'Just', 'click', 'on', 'the', 'dots', 'in', 'the', 'upper', 'right', 'corner', 'of', 'each', 'article', 'and', 'follow', 'the', 'prompts.', 'This', 'is', 'one', 'way', 'to', 'put', 'the', 'left', 'in', 'their', 'place.', 'PLEASE', 'HELP', 'ME.', 'Please', 'share', 'this', 'post', 'on', 'all', 'your', 'social', 'media.', 'https://www.facebook.com/DeepStateNation/?ref=br_rs', 'And', 'this', 'page', 'as', 'well,', 'please.', 'https://www.facebook.com/dctribunemedia/?ref=br_rs', 'People', 'like', 'this', 'need', 'to', 'be', 'eradicated', 'by', 'any', 'means', 'necessary.', 'This', 'woman', 'cannot', 'get', 'a', 'job.', 'Her', 'blog', 'is', 'her', 'only', 'source', 'of', 'income.']\n",
      "['No,', 'Andie.', 'Ms.', 'Kennard,', 'as', 'it', 'turns', 'out,', 'is', 'NOT', 'the', 'owner', 'of', 'DeepStateNation.', 'Please', 'do', 'try', 'to', 'get', 'your', 'facts', 'straight', '(I', 'know', \"that's\", 'a', 'challenge', 'for', 'you)', 'before', 'fooling', 'your', 'rube', 'followers', 'into', 'going', 'on', 'another', 'harassment', 'campaign.', 'PS:', 'You', 'are', 'still', 'a', 'yuuuuge', 'punchline', 'on', 'Twitter.', \"You're\", 'welcome!']\n",
      "['The', 'heroin', 'addict', 'certainly', 'is', 'the', 'author.', 'Tell', 'her', 'to', 'say', 'goodbye', 'to', 'her', 'account.']\n",
      "['Angela', 'Schmidt', 'Pauly', 'is', 'unable', 'to', 'read', 'analytically.', 'Were', 'she', 'able', 'to,', 'she', 'would', 'notice', 'both', 'stylistic', 'and', 'grammatical', 'distinctions', 'between', 'my', 'writing', 'and', \"Conover's.\", 'There', 'are', 'two', 'other', 'things', 'she', 'needs', 'to', 'know:', '1)', 'I', 'know', 'her', 'husband.', '2)', 'Conover', 'kicked', 'her', 'addiction', 'to', 'heroin', 'whereas', 'Angela', 'cannot', 'kick', 'her', 'addiction', 'to', 'needing', 'attention.']\n",
      "['EST!', 'Not', 'white', 'people', 'she', 'said,', 'women', 'specifically.', 'This', 'Jewish', 'supremacist', 'woman', 'means', 'white', 'men', 'deserve', 'no', 'civil', 'or', 'human', 'rights.']\n",
      "[\"I've\", 'never', 'met', 'a', 'lisa', 'that', \"wasn't\", 'a', 'cunt']\n",
      "['So', 'let', 'me', 'get', 'this', 'straight.', 'Because', \"you're\", 'an', 'illegal', 'spic', 'in', 'San', 'Francisco', 'you', 'get', 'to', 'vote?', 'Well', 'I', 'guess', 'if', 'you', \"murder...you've\", 'earned', 'the', 'right', 'to', 'vote', 'in', 'San', 'Fran.']\n",
      "['Maxine', 'Waters', 'is', 'seemily', 'lacking', 'in', 'her', 'ability', 'to', 'unite', 'people', 'of', 'all', 'colors,', 'religions,', 'or', 'creeds', 'together', 'as', 'exemplified', 'by', 'her', 'divisional', 'and', 'biotry', 'that', 'sets', 'her', 'up', 'there', 'with', 'the', 'likes', 'of', 'Sneaky', 'Al', 'Sharpton.', 'Apparently', 'Martin', 'Luther', 'King', 'and', 'his', 'philosophy', 'of', 'uniting,', 'and', 'kindness', 'didn’t', 'impress', 'Maxine', 'in', 'her', 'long', 'political,', 'and', 'criminal', 'time', 'in', 'politics!', 'https://www.nationalreview.com/the-morning-jolt/maxine-waters-political-violence/?utm_medium=referral&utm_source=idealmedia&utm_campaign=nationalreview.com&utm_term=68804&utm_content=2298198']\n",
      "['Fuck', 'this', 'retarded', 'whore', 'out', 'of', 'office']\n",
      "['https://youtu.be/VtIQrP6FvOo']\n",
      "['Lesbos...so', \"that's\", 'where', 'that', 'word', 'comes', 'from!', 'Dyke', 'Island.']\n",
      "['you', 'absolute', 'moron.']\n",
      "['identity', 'politics', 'is', 'retarded', 'on', 'both', 'sides.', 'Wake', 'up', 'man,', 'he', 'was', 'just', 'as', 'bad', 'as', 'the', '\"Drumpf', 'is', 'Hitler\"', 'lefties.']\n",
      "['#GabFam', '#Australia', 'Who', 'knew', 'trolling', 'an', 'NPC', 'in', 'full', 'meltdown', 'could', 'be', 'so', 'much', 'fun', ':)', 'Another', 'Oz', 'Rock', 'classic', 'for', 'my', 'mate', '@Clarence_Spangle', 'From', 'the', 'group', 'that', 'changed', \"it's\", 'name', 'while', 'touring', 'the', 'USA', 'to', 'avoid', 'confusion', 'with', 'a', 'preexisting', 'group.', 'Icehouse', '-', 'Great', 'Southern', 'Land', 'https://youtu.be/3mkidP2OUCk']\n",
      "['kangaroo', 'dick', 'sucking', 'hippy', 'faggot']\n",
      "['And', 'YET', 'you', \"don't\", 'have', 'the', 'balls', 'to', 'do', 'any', 'Purging', '....so', 'stfu', 'and', 'just', 'keep', 'doing', 'your', 'Little', 'trolling', 'you', 'little', 'faggot', 'Nazi', 'wannabe']\n",
      "['took', 'me', '3', 'minutes', 'but', 'i', 'hacked', 'your', 'webcam..also', 'have', 'your', 'browser', 'history...man-on-man', 'porn', '?!?!?', 'you', 'filthy', 'fat', 'assed', 'faggot', '!', 'go', 'take', 'a', 'bath', '!']\n",
      "['Look', 'at', 'the', 'logo', 'on', 'the', 'truck,', 'what', 'do', 'you', 'see?', 'It’s', 'the', 'same', 'people', 'who', 'are', 'running', 'the', 'ships', 'that', 'bring', 'Africans', 'into', 'Europe.', 'Why', 'would', 'these', '“allies”', 'of', 'ours', 'be', 'flooding', 'our', 'country', 'with', 'the', 'refuse', 'of', 'the', 'third', 'world?', 'We', 'are', 'being', 'destroyed,', 'not', 'by', 'a', 'superior', 'army', 'or', 'an', 'act', 'of', 'God,', 'but', 'by', 'our', 'fear', 'of', 'being', 'called', 'anti-semites.']\n",
      "['BS.', \"You're\", 'lying.', 'You', \"don't\", 'do', 'your', 'cause', 'any', 'good', 'by', 'lying....']\n",
      "['Imagine', 'writing', 'out', 'all', 'of', 'that', 'and', 'yet', 'not', 'having', 'a', 'single', 'sentence', 'explaining', 'why', 'it', 'is', 'retarded', 'to', 'believe', 'Jews', 'are', 'behind', 'the', 'migration', 'when', 'there', 'is', 'a', 'Star', 'of', 'David', 'on', 'the', 'truck.', 'Who', 'is', 'the', 'real', 'retard?']\n",
      "['Obama', 'Takes', 'More', 'Swipes', 'at', 'Trump:', 'He’s', '‘Just', 'Blatantly,', 'Repeatedly,', 'Baldly,', 'Shamelessly', 'Lying’', '(VIDEO)', 'https://truepundit.com/obama-takes-more-swipes-at-trump-hes-just-blatantly-repeatedly-baldly-shamelessly-lying-video/']\n",
      "['Nothing', 'that', 'faggot', 'ass', 'kenyan', 'piece', 'of', 'shit', 'obungler', 'has', 'to', 'say', 'would', 'interest', 'me!']\n",
      "['Come', 'January', 'his', 'black', 'ass', 'is', 'toast..the', 'noose', 'awaits']\n",
      "[\"That's\", 'something', \"I'd\", 'even', 'pray', 'for!']\n",
      "[\"I'm\", 'just', 'gonna', 'leave', 'this', 'here..']\n",
      "['I', 'think', 'Kanye', 'saw', 'through', 'Taylor', 'Twat', 'Swift', 'before', 'any', 'of', 'us', 'saw', 'who', 'she', 'really', 'is.', 'I', 'question', 'no', 'more', 'about', 'why', 'Kanye', 'started', 'cracking', 'on', 'her', 'by', 'taking', 'the', 'microphone', 'away.']\n",
      "['For', 'those', 'who', 'are', 'confused', 'about', 'the', 'true', 'definition..', 'This', 'is', 'the', 'epitome', 'of', 'an', 'Uncle', 'Tom...', 'You', 'can', 'almost', 'see', 'the', 'gray', 'matter', 'leaking', 'out', 'of', 'his', 'ears...']\n",
      "[\"I'll\", 'take', 'this', 'nigger', 'over', 'Uncle', 'Ron', 'deSantis', 'any', 'black', 'day', 'of', 'the', 'week', 'ending', 'in', 'Y.', 'lmaooooo', '#VoteBlueToSaveAmericaFromTrump']\n",
      "['Kanye', 'West:', 'Mind', 'Control', 'I', 'understand', 'that', 'some', 'people', 'think', 'Kanye', 'is', 'crazy,', 'because', 'he', 'kinda', 'is,', 'but', 'he', 'brings', 'up', 'good', 'points', 'There', 'are', 'always', 'people', 'trying', 'to', 'manipulate', 'what', 'you', 'say,', 'what', 'you', 'think,', 'and', 'what', 'you', 'feel.', 'Whether', \"it's\", 'the', 'MSM,', 'T.V.,', 'Radio,', 'Newspapers,', 'Social', 'Media', 'etc', 'Think', 'for', 'yourself', ':p', '#News', 'Watch:', 'https://www.pscp.tv/w/1yoKMVydwkwGQ']\n",
      "['According', 'to', 'CNN,', 'Kanye', 'is', 'a', 'crazy', 'nigger', 'who', \"can't\", 'read,', 'as', 'he', 'helps', 'whitey', 'oppress', 'the', 'black', 'man', 'by', 'giving', 'them', 'all', 'jobs.', 'Who', 'knew', 'a', 'crazy', 'nigger', 'could', 'get', 'that', 'rich?']\n",
      "[\"Don't\", 'let', 'these', '#altright', '#whitenationalist', 'fool', 'you', '..they', 'are', 'not', 'like', 'you.', 'They', 'are', 'pure', 'trash', 'pretending', 'to', 'relate', 'with', 'you', 'on', 'moral', 'issues', 'when', 'they', 'are', '100%', 'immoral', 'themselves.', 'They', 'will', 'sometimes', 'claim', 'they', 'are', 'Christians,', 'but', 'ask', 'them', 'to', 'elaborate', 'and', 'they', 'vomit', 'out', 'nothing', 'but', 'heresy.', 'They', 'will', 'chant', 'with', 'you', 'against', 'the', 'liberal', 'opposition', 'coming', 'out', 'of', '#PlannedParenthood', 'but', 'applaud', 'them', 'for', 'putting', 'clinics', 'in', 'minority', 'areas.', 'They', 'believe', 'in', '#populationControl', 'and', '#eugenics.', 'They', 'even', 'support', '#euthanasia', 'for', 'the', 'elderly,', 'and', 'underdeveloped.', 'A', 'lot', 'of', 'them', 'are', 'even', 'Scottish', 'Rite', 'Freemasons', \"who's\", 'great,', 'great', 'grand', 'fathers', 'were', 'a', 'part', 'of', 'the', 'Order', 'of', 'the', 'Golden', 'Circle', 'that', 'opposed', 'the', 'early', 'GOP', 'founded', 'by', '#Christian', '#Protestants', 'and', 'assassinated', 'Lincoln.', 'It', 'is', 'because', 'of', 'their', 'Freemasonic', 'ranks', 'that', 'many', 'of', 'them', 'got', 'skipped', 'up', 'in', 'ranks', 'in', 'the', 'military,', 'and', 'police', '..the', 'ones', 'seemingly', 'more', 'honorable', 'because', 'of', 'that', 'really', 'cheated.', 'THEY', 'ARE', 'NOT', 'YOUR', 'FRIENDS!']\n",
      "['Stop', 'being', 'a', 'faggot', 'and', 'stand', 'up', 'for', 'your', 'race,', 'white', 'man.']\n",
      "['I', 'am.', 'As', 'a', 'pure', 'Dutch-German', \"I'm\", 'doing', 'it', 'by', 'exposing', 'the', 'trash.', 'Unfortunately', 'for', 'you', 'the', 'scale', 'is', 'of', 'moral', 'character,', 'and', 'not', 'ethnicity.']\n",
      "['Kamala', 'Harris', 'to', 'Caravan:', 'We', 'Are', 'A', '\"Welcoming\"', 'Country', 'https://www.realclearpolitics.com/video/2018/10/24/kamala_harris_to_caravan_we_are_a_welcoming_country.html']\n",
      "['Take', 'about', 'a', 'dozen', 'into', 'your', 'home,', 'nigger', 'bitch.']\n",
      "['With', 'the', 'new', 'movie', '\"Bohemian', 'Rhapsody\"', 'I', 'got', 'to', 'know', 'about', 'Freddie', 'Mercury,', 'the', 'lead', 'singer', 'of', 'the', 'British', 'band', '\"Queen\"', 'and', 'one', 'of', 'the', 'greatest', 'vocalists', 'of', 'all', 'time.', 'The', 'fact', 'that', 'he', 'was', 'and', 'continues', 'to', 'be', 'admired', 'by', 'millions', 'of', 'people', 'all', 'over', 'the', 'world', ',', 'in', 'spite', 'of', 'not', 'being', 'white', 'or', 'straight', ',', 'shows', 'how', 'ultimately', 'such', 'differences', 'do', 'not', 'really', 'matter.']\n",
      "['AIDS', 'INFESTED', 'DEAD', 'FAGGOT']\n",
      "['Or', 'are', 'you', 'an', 'AIDS', 'infested', 'dead', 'faggot', 'too?']\n",
      "['Welcome', 'to', 'San', 'Francisco.', 'This', 'is', 'Folsom', 'Street', 'yesterday', '(9/30/18).', 'This', 'is', 'the', 'California', 'Senators', 'Feinstein', 'and', 'Harris', 'are', 'working', 'so', 'hard', 'to', 'protect.']\n",
      "['And', 'we', \"don't\", 'need', 'Aryan', 'grooming', 'gangs', 'in', 'the', 'cities', 'in', 'America?', 'Mid', 'America,', 'pat', 'Boone', 'crowd;', 'just', 'Imagine', 'hordes', 'of', 'teens', 'with', 'axe', 'handles', 'and', 'bats,', 'to', 'bring', 'these', '2', 'to', 'the', 'light', 'for', 'their', 'transgressions', 'against', 'good', 'order', 'and', 'discipline.', 'The', 'very', 'definition', 'as', 'to', 'the', 'how', 'of', 'making', 'America', 'great', 'again.']\n",
      "['This', 'whole', 'country', 'is', 'a', 'big', 'faggot', 'ranch.', 'The', 'morals', 'are', 'at', 'an', 'all-time', 'low', 'and', 'that', 'is', 'what', 'is', 'going', 'to', 'destroy', 'society.', 'Besides,', 'we', \"don't\", 'call', 'it', 'the', 'Gay', 'Bay', 'for', 'nothing.']\n",
      "[]\n",
      "['We', 'favor', 'castration', 'for', 'pedophiles', 'and', 'faggots.']\n",
      "['Every', 'honest', 'thinking', 'man', 'knows', 'that', 'God', 'hates', 'fags']\n",
      "['#GabFam', 'Time', 'for', 'a', 'bit', 'of', 'Zombie', 'Rob', 'Zombie', '-', 'Dragula', 'https://youtu.be/EqQuihD0hoI']\n",
      "['aussie', 'faggot']\n",
      "['aussie', 'faggot']\n",
      "['https://www.youtube.com/watch?v=gRE-0nIpMqA', 'you', 'blinked', 'faggot']\n",
      "['Genre:', 'Electronic', 'Sub-genre:', 'Breakbeat', 'Artist:', 'Snoop', 'Dogg', 'Song:', 'Sensual', 'Seduction', \"I'm\", 'gonna', 'take', 'my', 'tiiiiime', 'https://www.youtube.com/watch?v=Y1PVmANeyAg&t=0s&list=PLpuAoqE-LIzc_Fc9p0Xz3aaeR_fqEEGVk&index=40']\n",
      "['fucking', 'nigger']\n",
      "['https://twitter.com/MaxBoot/status/1051150486563360768', 'Seriously', 'just', 'how', 'retarded', 'is', 'this', 'guy?']\n",
      "['@PeteWilliamsNBC', 'BREAKING:', 'Suspicious', 'package', 'addressed', 'to', 'former', 'Director', 'of', 'National', 'Intelligence', 'Clapper', 'intercepted', 'in', 'Manhattan,', '@PeteWilliamsNBC', 'reports;', 'a', '12th', 'device.', 'https://kek.gg/u/33WJp']\n",
      "['This', 'is', 'just', 'getting', 'fucking', 'retarded']\n",
      "['Dylann', 'Roof’s', 'prime', 'target:', 'The', 'Nigger', 'State', 'Senator', 'he', 'killed', '1st!', 'NONE', 'of', 'those', 'killed', 'were', '\"innocent\"', 'as', 'if', 'that', 'had', 'any', 'meaning', 'in', 'this', 'context.', 'They', 'were', '\"Black', 'Lives', 'Matter\"', 'leaders', 'that', 'incited', 'hood', 'niggers', 'to', 'attack', 'Whites.', 'Did', 'I', 'mention', 'they', 'were', 'NIGGERS?', '1960', 'to', '2010', 'niggers', 'murdered', '80,000+', 'Whites', 'in', 'U.S.', 'http://historyreviewed.com/?p=9340']\n",
      "['In', 'Defense', 'Of', 'Dylann', 'Roof', '-', 'MIR', 'Power', 'Hour', '-', 'http://recordings.talkshoe.com/TC-130203/TS-986189.mp3']\n",
      "['Nigger', 'Pets', '-', 'MIR', 'Power', 'Hour', '-', 'http://recordings.talkshoe.com/TC-130203/TS-1020694.mp3', 'Nigger', 'Pets', 'Pt', '2', '-', 'MIR', 'Power', 'Hour', '-', 'http://recordings.talkshoe.com/TC-130203/TS-1020955.mp3']\n",
      "[\"It's\", '\"if', 'you', 'kill', 'your', 'enemies', 'they', 'win\"', 'season', 'again']\n",
      "['You', 'would', 'think', 'after', 'hearing', 'a', 'drooling', 'retard', 'like', 'Trudeau', 'say', 'it', 'no', 'one', 'else', 'would?']\n",
      "['🇺🇸Remember', 'IN', 'NOVEMBER', '👇']\n",
      "['FUCK', 'that', 'cunt']\n",
      "['TERM', 'LIMITS']\n",
      "['There', 'was', 'this', 'boring,', 'but', 'attractive,', 'girl.', 'She', 'twisted', 'my', 'arm', 'to', 'read', 'her', 'VERY', 'failed', \"master's\", 'thesis.', 'Very', 'boring', 'person.', 'But', 'she', 'had', 'mostly', 'cribbed', 'from', 'the', 'aspie', 'retard', 'dude.you', 'could', 'drink', 'a', 'beer', 'with', 'him.', 'Nice', 'how', 'she', 'gave', 'me', 'a', 'roadmap', 'of', 'her', 'intellectual', 'thieving?']\n",
      "['@ChristiJunior', '<===', 'Stupid', 'cunt']\n",
      "['What', 'seems', 'to', 'be', 'the', 'problem', 'friend?']\n",
      "['>Maherstein', 'Oh', 'no...', 'XD']\n",
      "['Really', 'activates', 'the', 'almonds.']\n",
      "[\"I'm\", 'changing', 'my', 'prediction.', 'I', 'see', 'that', 'the', 'bombs', 'were', 'sent', 'to', 'pretty', 'much', 'everybody', 'on', 'the', 'standard', 'Demtard', 'list.', 'That', 'means', \"it's\", 'a', 'newbie.', 'Like', 'that', 'kid', 'who', 'shot', 'up', 'a', 'black', 'church.', \"It's\", 'just', 'some', 'autistic', 'retard', 'who', 'happened', 'to', 'be', 'a', 'Republican', 'for', 'reasons', 'outside', 'his', 'own', 'control.']\n",
      "[]\n",
      "['Dear', 'Chelsea,', 'Your', 'cunt', 'looks', 'like', 'a', 'ham', 'sandwich', 'that', 'has', 'been', 'left', 'in', 'the', 'scorching', 'heat', 'all', 'day.', 'Books', 'will', 'be', 'written', 'describing', 'your', 'mental', 'indoctrination', 'by', 'the', 'forces', 'of', 'the', 'left...']\n",
      "['Seems', 'loud', 'and', 'clear', 'to', 'me:']\n",
      "['Did', 'you', 'mean', 'is', 'not', 'a', 'cunt', '?', 'Here', 'is', 'more', 'info', 'for', 'dummies', 'http://thereligionofpeace.com']\n",
      "['Recent', 'Poll', 'of', 'GAB', 'users', 'show', '78%', 'do', 'not', 'believe', 'Nazis', 'are', 'enemies', 'of', 'America.']\n",
      "['Nazis', 'are', 'democrat', 'operatives', 'calling', 'themselves', '\"alt-right\"', 'they', 'are', 'just', 'as', 'much', 'an', 'enemy', 'of', 'freedom', 'as', 'democrats.', 'George', 'Soros', 'funded', 'to', 'make', 'the', 'right', 'wing', 'look', 'as', 'hateful', 'as', 'the', 'democrats.', 'They', 'are', 'leftists.']\n",
      "['Nazis', 'are', 'not', 'leftists', 'and', 'the', 'poll', 'proves', 'nobody', 'believes', 'this', 'retarded', 'shit.', 'If', 'you', 'mean', 'people', 'who', 'show', 'up', 'to', 'rallies', 'sieg', 'heiling', 'and', 'waving', 'swastika', 'flags', 'fresh', 'out', 'of', 'the', 'packaging,', 'those', 'are', 'Democrat', 'operatives', 'trying', 'to', 'sully', 'the', 'movement', 'in', 'the', 'eyes', 'of', 'the', 'public', 'but', 'it', 'is', 'not', 'because', 'far', 'right', 'movements', 'are', 'actually', 'in', 'favour', 'of', 'multiculturalism.']\n",
      "['246', 'people', 'on', 'GAB', 'mostly', 'those', 'calling', 'themselves', 'nazis', \"isn't\", 'proof', 'of', 'jack', 'shit.']\n",
      "['Who', 'hurt', 'you', 'sweaty']\n",
      "['My', 'momma']\n",
      "['What', 'if', 'it', 'was', 'cold', 'outside?']\n",
      "['Maybe', 'I', 'should', 'just', 'follow', 'my', 'kin', 'in', 'their', 'white', 'flight', 'and', 'leave', 'the', 'hood', 'for', 'good.', 'Havent', 'seen', 'a', 'nigger', 'all', 'day...']\n",
      "['People', \"don't\", '\"White', 'Flight\"', 'for', 'their', 'own', 'amusement.', \"It's\", 'a', 'survival', 'strategy.']\n",
      "['I', 'can', 'survive', 'in', 'the', 'hood', 'but', 'likely', 'nit', 'good', 'for', 'my', 'mental', 'health', 'as', 'i', 'get', 'older...']\n",
      "['Why', 'have', 'u', 'all', 'turned', 'into', 'npc', 'grey?']\n",
      "['If', 'you', 'have', 'kids,', 'an', 'immediate', '\"White', 'Flight\"', 'woud', 'be', 'imperative,', 'but', 'as', 'you', 'grow', 'older', 'you', 'will', 'likely', 'become', 'the', 'target', 'of', 'black-on-white', 'racial', 'violence.', 'Bite', 'the', 'bullet.', 'Wrong', 'hill', 'to', 'die', 'on.']\n",
      "['I', 'changed', 'my', 'entire', 'header', 'theme.', 'My', 'old', 'profile', 'pic', 'was', 'of', 'me', 'playing', 'sax', 'from', 'about', '2003.', \"I'm\", 'not', 'playing', 'music', 'very', 'much', 'now,', 'and', 'I', 'removed', 'the', 'banner', 'of', 'Taylor', 'Swift', 'singing', 'in', 'front', 'of', 'a', 'swastika', 'because', 'she', 'is', 'a', 'fat', 'traitor', 'SJW', 'whore', 'now.', 'I', 'went', 'for', 'a', 'clean,', 'positive,', 'futuristic', 'look.']\n",
      "['Shame', 'bout', 'taylor', 'swift.', 'I', 'still', 'liked', 'the', 'banner', 'tho...']\n",
      "['I', 'guess', 'im', 'waiting', 'for', 'that', 'broke', 'arse', 'chick,', 'that', 'wants', 'to', 'leave', 'the', 'hood', 'too.', 'It', 'worked', 'last', 'time', 'for', '10', 'years', 'and', 'have', 'a', 'bunch', 'of', 'great', 'kids,', 'now', 'adults.', '#slutintohousewife']\n",
      "['Trump', 'meets', 'Kanye', 'West', 'at', 'the', 'White', 'House', 'https://www.youtube.com/watch?v=gdvgxdcfV4g']\n",
      "[\"You're\", 'a', 'fucking', 'faggot', 'for', 'real.']\n",
      "['You', 'a', 'pink', 'pussy', 'hat', 'wearer...#SocialistShitBallSack!']\n",
      "[]\n",
      "['That', 'pasty', 'cunt', 'wouldnt', 'know', 'what', 'hit', 'it,', 'if', 'it', 'came', 'down', 'to', 'shooting!']\n",
      "['@News', '@Politics', '@BrigitteGabriel', '@noislamonazis', '@PamelaGeller', '@GeorgiaLogCabin', '@A3Patriot', '@a', '@bh43', '@CmdrSlamm', '@DaleEvans', '@edbaker3000', '@FrankDeSilva', '@im_frank', '@janiec', '@Kekromancer', '@LouHolmes', '@NoGlobalistSlave', '@OurCountryFirst', '@PaigeFord', '@qbmdo', '@JQuest2000', '@ForQ', '@Rad-er-Cad', '@SurvivorMed', '@Thepalmierireport']\n",
      "['NO', 'COMMIE', 'NIGGERS', 'FOR', 'GOV.....', 'WE', 'ALREADY', 'HAD', 'A', 'COMMIE', 'NIGGER', 'FOR', 'PRES.....']\n",
      "['Jay', 'always', 'lets', 'someone', 'else', 'think', 'for', 'him', 'since', 'he', 'cannot', 'do', 'it', 'himself!', 'Thats', 'how', 'monkey', 'brains', 'are!', 'His', 'RETARDED', 'brain', \"can't\", 'actually', 'understand', 'REAL', 'facts', 'so', 'he', 'posts', 'articles', 'which', 'have', 'LIES', 'written', 'by', 'the', 'same', 'filthy', 'RACIST', 'askeNAZI', 'JEWS', 'to', 'emphasize', 'that', 'he', 'does', 'not', 'have', 'a', 'functioning', 'brain!', 'He', \"won't\", 'ever', 'debate', 'nor', 'ever', 'give', 'a', 'FACT,', 'but', 'he', 'will', 'always', 'call', 'you', 'stupid', 'which', 'he', 'obviously', 'is!', 'When', 'you', \"can't\", 'debate,', 'character', 'assassinate!', 'His', 'intellectual', 'deficiencies', 'are', 'immense!']\n",
      "[]\n",
      "['So', 'wait,', 'you', 'mean', 'the', 'Hamas', 'that', 'is', 'prevented', 'from', 'leaving', 'Gaza', 'by', 'the', 'heebs,', 'and', 'need', 'every', 'penny', 'to', 'buy', 'rockets', 'to', 'kill', 'idf?...', 'That', 'Hamas?', 'Well', 'if', 'they', 'did,', 'some', 'kike', 'paid', 'for', 'their', 'airfare.', 'Most', 'americans', 'arent', 'as', 'inbred', 'and', 'retarded', 'as', 'Israelis.']\n",
      "['1-what', 'were', 'niggers', 'doing', 'to', 'other', 'tribes', 'they', 'conquered', 'in', 'africa', '?', 'i', 'bet', 'using', 'and', 'abusing', 'them', 'as', 'much', 'they', 'could', '.', 'mean', 'while', 'notice', 'that', 'hannibal-attila', 'the', 'hun-ghengas', 'khan-etc', 'were', 'trying', 'to', 'conquer/enslave', 'europe', 'time', 'after', 'time', '.', 'all', 'earths', 'history', 'being', 'vicious', 'war', 'after', 'war', 'for', 'territory.now', 'though', 'in', 'nigger', 'minds', 'its', 'all', 'whiteys', 'fault', '.']\n",
      "['2016', 'bought', 'us', '...', 'what?', 'A', 'huge', 'surge', 'in', 'Antifa', 'violence.', 'The', 'loss', 'of', 'free', 'speech', 'on', 'the', 'internet.', 'The', 'destruction', 'of', 'monuments', 'all', 'over', 'the', 'country.', 'It', 'has', 'been', 'worse', 'than', '8', 'years', 'of', 'Obama', 'ever', 'was', 'and', 'it', 'was', 'all', 'for', 'the', 'sake', 'of', 'cutting', 'the', 'taxes', 'of', 'Jack', 'Dorsey', 'and', 'Mark', 'Zuckerberg', 'and', 'loosening', 'financial', 'regulations', 'for', 'Wall', 'Street']\n",
      "['Bullshit.', 'The', 'communist,', 'Liberal', 'Left', 'is', 'causing', 'ALL', 'of', 'the', 'problems,', 'and', 'anyone', 'with', 'a', 'braincell', 'can', 'see', 'it.', 'You', 'all', 'just', 'exist', 'to', 'fool', 'the', 'retarded', 'normies.']\n",
      "['Did', 'you', 'hear', 'about', 'the', 'SECOND', 'and', 'THIRD', 'caravan', 'forming', 'in', 'Central', 'America?', \"That's\", 'because', 'the', 'first', 'one', 'made', 'it', 'through', 'in', 'April', 'and', 'this', 'one', 'is', 'on', 'the', 'way.', 'It', 'is', 'up', 'to', 'the', 'White', 'House', 'and', 'Congress', 'to', 'deal', 'with', 'this', 'and', 'both', 'are', 'controlled', 'by', 'the', 'GOP']\n",
      "['No', 'one', 'should', 'be', 'surprised', 'that', 'the', 'Democrats', 'are', 'so', 'determined', 'to', 'import', 'hordes', 'of', 'low-IQ', 'Spanish-speaking', 'peasants', 'from', 'Latin', 'America', 'to', 'displace', 'working-class', 'whites.', 'If', 'only', 'white', 'Americans', 'voted,', 'the', 'Democrats', 'would', 'never', 'win', 'another', 'national', 'election.']\n",
      "['On', 'the', 'retarded', 'and', 'useless', 'require', 'socialism', 'to', 'get', 'by.', 'And', 'everyone', 'i', 'know', 'who', 'has', 'above', 'room', 'temperature', 'IQ', 'can', 'find', 'a', 'job', 'pretty', 'easily.', 'If', 'losing', 'your', 'job', 'at', 'the', 'plant', 'ruins', 'you', 'forever', 'you', 'must', 'not', 'be', 'very', 'smart.']\n",
      "['Nuts']\n",
      "['Maybe', 'that', 'sand', 'nigger', 'will', 'feel', 'safer', 'in', 'Kabul.']\n",
      "['What', 'do', 'you', 'call', 'a', 'rich', 'black', 'guy', 'who', 'lets', 'his', 'underage', 'kids', 'drink', 'alcohol?', 'A', 'nigger', 'https://www.dailymail.co.uk/femail/article-6262231/LeBron-James-reveals-mature-sons-aged-14-11-drink-WINE.html']\n",
      "['Poor', 'Ms', 'Emma', 'says', 'she’s', 'afraid', 'to', 'drive', 'down', 'the', 'street', 'without', 'a', 'disguise.', 'She', 'wasn’t', 'fearfull', 'last', 'March', 'when', 'she', 'was', 'sticking', 'her', 'face', 'on', 'every', 'media', 'show', 'she', 'could', 'find....flashing', 'the', 'Cuban', 'flag.']\n",
      "['I', \"don't\", 'give', 'a', 'single', 'shit', 'what', 'some', 'communist', 'dyke', 'has', 'to', 'say', 'about', 'an', 'event', 'that', 'she', 'likely', 'caused', 'to', 'happen', 'in', 'the', 'first', 'place.', 'She', 'admitted', 'to', 'harassing', 'and', 'bullying', 'Cruz', 'the', 'psychopath', 'murderer', 'from', 'Cuba.']\n",
      "['The', 'crying', 'continues...', \"Don't\", 'get', 'dehydrated', 'from', 'all', 'that', 'whinging,', 'SOY.', 'https://gab.ai/GoyGibson/posts/37159895']\n",
      "['This', 'faggot', 'needs', 'a', 'tampon', 'to', 'stuff', 'up', 'his', 'sore', 'little', 'ass....']\n",
      "['sounding', 'pretty', 'tough']\n",
      "['she', 'just', 'proves', 'how', 'absolutely', 'retarded', 'the', 'political', 'elite', 'has', 'become,', 'why', 'more', 'and', 'more', 'are', 'turning', 'to', 'Mr', 'Trump,', 'he', 'is', 'not', 'a', 'politician', 'per', 'sa']\n",
      "['McInnes', 'sent', 'his', 'guys', 'to', 'attack', 'y', 'event', 'Antifa', 'style,', 'that', 'faggot', 'deserves', 'neck', 'rope']\n",
      "['I', 'understand', 'some', 'of', 'you', 'think', 'religion', 'is', 'important,', 'but', \"don't\", 'preach', 'it', 'at', 'me.', 'I', \"don't\", 'give', 'a', 'shit', 'about', 'it', 'if', 'it', \"isn't\", 'SPECIFICALLY', 'pro-White.', 'Your', 'Christianity', 'is', 'bullshit.']\n",
      "['Catholicism', 'is', 'more', 'than', 'important,', 'it', 'is', 'true.', 'The', 'current', 'pope', 'may', 'be', 'a', 'faggot', 'communist,', 'but', 'he', 'is', 'just', 'a', 'man', 'who', 'won', 'an', 'election.', 'If', 'you', 'look', 'at', 'where', 'Nationalism', 'is', 'winning', 'in', 'the', 'world,', 'you', 'will', 'see', 'a', 'pattern...', 'Further,', 'if', 'you', 'don’t', 'start', 'to', 'behave', 'you', 'are', 'going', 'to', 'have', 'to', 'dress', 'up', 'in', 'a', 'catholic', 'school', 'girl', 'uniform', 'and', 'be', 'disciplined', 'harshly.']\n",
      "['The', 'Catholic', 'church', 'has', 'to', 'know', 'the', 'truth', 'of', 'our', 'beginnings.', 'They', 'own', 'and', 'hide', 'fucking', 'everything.', 'I', 'resent,', 'with', 'everything', \"that's\", 'in', 'me,', 'not', 'having', 'access', 'to', 'what', 'they', 'are', 'privy', 'to.', 'I', 'have', 'no', 'faith', 'in', 'any', 'god.', \"They've\", 'done', 'nothing', 'for', 'mankind', 'that', 'I', 'can', 'see,', 'and', \"they're\", 'not', 'coming', 'back', 'to', 'save', 'anyone.', 'Your', 'current', 'pope', 'should', 'be', 'burned', 'at', 'the', 'stake', 'though.']\n",
      "['Relatively', 'little', 'is', 'hidden', '(Third', 'secret', 'of', 'Fatima,', 'I', 'am', 'looking', 'at', 'you),', 'Faith', 'is', 'a', 'gift', 'that', 'comes', 'forth', 'from', 'discipline.', 'I', 'can’t', 'personally', 'lay', 'hands', 'on', 'the', 'pope,', 'but', 'the', 'rules', 'arent', 'super', 'clear', 'about', 'the', 'use', 'of', 'the', 'holy', 'hand', 'grenade', 'of', 'Antioch.', 'It', 'is', 'easier', 'to', 'discuss', 'faith', 'with', 'someone', 'in', 'person,', 'but', 'for', 'the', 'record', 'I', 'do', 'think', 'it', 'is', 'true.', 'Explaining', 'why', 'is', 'difficult,', 'and', 'would', 'take', 'hours,', 'and', 'would', 'probably', 'just', 'irritate', 'you', 'if', 'you', 'aren’t', 'interested', 'in', 'that', 'sort', 'of', 'thing.']\n",
      "['Everything', 'is', 'hidden', '&', 'wrapped', 'in', '60', 'layers', 'of', 'meaning.', 'Faith', 'is', 'not', 'interesting', 'to', 'me.', 'I', 'will', 'worship', 'a', 'god', 'when', 'I', 'have', 'proof', 'that', 'a)', 'They', 'actually', 'existed', 'or', 'exist', 'and', 'b)', 'I', 'am', 'offered', 'a', 'religion', 'based', 'that', 'is', 'beneficial', 'to', 'me', 'and', 'mine.', 'The', 'Bible', 'is', 'only', 'ancient', 'stories', 'retold', 'again,', 'that', 'are', 'BASED', 'IN', 'FACT.', 'It', 'is', 'not', 'true', 'in', 'any', 'other', 'way,', 'nor', 'divinely', 'inspired.']\n",
      "['That’s', 'it,', 'put', 'on', 'the', 'skirt', 'and', 'tights,', 'time', 'to', 'get', 'spanked.', 'The', 'only', 'choice', 'you', 'have', 'now', 'is', 'ruler', 'or', 'paddle.']\n",
      "['Paddle.']\n",
      "['Thuddy', 'over', 'Stingy.', 'Noted.']\n",
      "['I', 'hope', 'someday', 'you', 'have', 'the', 'experience', 'that', 'can', 'change', 'your', 'mind.', 'I', 'hope', 'it', 'is', 'entirely', 'positive.']\n",
      "['Jesus', 'Christ', 'can', 'shake', 'me', 'hand', 'and', 'turn', 'me', 'into', 'a', 'turtle.', 'I', 'want', 'him', 'to', 'prove', 'that', 'he', 'created', 'me,', 'or', 'his', 'father', 'did', 'as', 'they', 'claim.', 'I', \"ain't\", 'taking', \"anybody's\", 'word', 'for', 'shit.']\n",
      "['I', 'am', 'an', 'old', 'long', 'married', 'man', 'with', 'adult', 'daughters.', 'I', 'am', 'not', 'looking', 'to', 'get', 'laid.', 'If', 'you', 'familiarize', 'yourself', 'with', 'Catholic', 'tradition,', 'you', 'will', 'see', 'that', 'we', 'expect', 'most', 'women', 'are', 'rebellious', 'and', 'slaves', 'to', 'passion.', 'It', 'is', 'only', 'through', 'setting', 'clear', 'expectations', 'and', 'social', 'pressure', 'to', 'adhere', 'to', 'them', 'that', 'any', 'women', 'can', 'be', 'helped', 'to', 'be', 'virtuous.', 'It', 'is', 'in', 'the', 'nature', 'of', 'the', 'daughters', 'of', 'eve.']\n",
      "['I', \"didn't\", 'take', 'your', '\"flirting\"', 'in', 'any', 'other', 'way.', 'Women', \"aren't\", 'interesting', 'to', 'me', 'either.']\n",
      "['Jon', 'Jones', 'vs.', 'Alexander', 'Gustafsson', 'rematch', 'to', 'headline', '#UFC232', 'https://www.mmafighting.com/2018/10/11/17961768/jon-jones-opens-as-healthy-betting-favorite-over-alexander-gustafsson-in-ufc-232-rematch']\n",
      "['gus', 'is', 'a', 'cuck', 'with', 'a', 'mental', 'block', 'against', 'niggers,', 'and', 'by', 'god', 'JBJ', 'is', 'the', 'greatest', 'combat', 'nigger', 'that', 'ever', 'lived...']\n",
      "['True.', 'Being', 'a', 'Swede,', 'he’s', 'afflicted', 'with', 'a', 'congenital', 'submissiveness', 'toward', 'niggers.', 'But', 'he', 'did', 'officially', 'win', '2', 'rounds', 'against', 'Jones', 'in', 'their', 'first', 'fight', '(many', 'thought', 'he', 'won', '4)', 'and', 'he', 'made', 'Jones', 'look', 'ordinary.', 'Jones', 'has', 'never', 'fought', 'while', 'not', 'on', 'PEDs,', 'so', 'as', 'far', 'as', 'I’m', 'concerned', 'his', 'record', 'gets', 'an', 'asterisk', 'next', 'to', 'it', 'until', 'he', 'proves', 'otherwise.']\n",
      "['Retard', 'or', 'academic?', 'https://twitter.com/Hermitwise/status/1053797331609489408']\n",
      "['This', 'article', 'makes', 'me', 'want', 'to', 'rip', \"Anglin's\", 'head', 'off', 'even', 'more', 'now.', 'A', 'White', 'woman', 'was', 'gang', 'raped,', 'tortured,', 'and', 'murdered,', 'but', 'because', 'one', 'of', 'the', 'blacks', 'said', 'that', 'she', 'consented', 'if', 'they', 'would', 'let', 'her', 'go,', 'DS', 'wants', 'you', 'to', 'make', 'whore', 'memes', 'of', 'her.', 'https://dailystormer.name/skull-crushed-hoe-consented-to-negro-gang-sex-skull-status-crushed-anyway-lol/']\n",
      "['ds', 'understands', 'psychology', 'and', 'the', 'power', 'of', 'hyperbole.', \"It's\", 'why', \"they're\", 'effective', 'and', \"you're\", 'a', 'permanent', 'whiney', 'loser']\n",
      "['Stormfaggots', 'are', \"ZOG's\", 'whigger', 'bitches.']\n",
      "['Mister', 'Metokur', 'can', 'be', 'a', 'fucking', 'cunt', 'sometimes']\n",
      "['He’s', 'a', 'troll,', 'that’s', 'all.']\n",
      "[\"That's\", 'kinda', 'the', 'point.', 'He', 'throws', 'fuel', 'on', 'flames', 'to', 'bask', 'in', 'the', 'glow', 'of', 'drama.']\n",
      "['Chairman', 'Of', 'Minnesota’s', 'DFL', 'Party', 'Doesn’t', 'Believe', 'Monahan,', 'the', 'woman', 'who', 'accused', 'Congressman', 'Keith', 'Ellison', 'of', 'domestic', 'violence.', 'What', 'happened', 'to', '\"believe', 'all', 'women?\"', 'It', \"doesn't\", 'apply', 'in', 'this', 'case', 'because', 'the', 'accused', 'is', 'a', 'Democrat?', 'Nice.', 'UTTER', 'Hypocrites', 'Democrats', \"don't\", 'even', 'follow', 'the', 'RETARDED', 'standard', 'that', 'they', 'MANUFACTURED', 'https://kek.gg/u/tWJc']\n",
      "['I', 'have', 'killed', 'better', 'men', 'than', 'you', 'in', 'legitimate', 'warfare,', 'and', 'I', 'would', 'reduce', 'you', 'to', 'sobbing', 'with', 'a', 'harsh', 'look', 'IRL.', \"I've\", 'thrown', 'away', 'old', 'socks', 'that', 'were', 'manlier', 'than', 'you', 'by', 'virtue', 'of', 'the', 'fact', 'that', 'they', 'had', 'absorbed', 'my', 'sweat,', 'because', \"you're\", 'a', 'fat,', 'pathetic', 'virgin.']\n",
      "['What', 'the', 'fuck', 'did', 'you', 'just', 'fucking', 'say', 'about', 'me,', 'you', 'little', 'bitch?', 'I’ll', 'have', 'you', 'know', 'I', 'graduated', 'top', 'of', 'my', 'class', 'in', 'the', 'Navy', 'Seals,', 'and', 'I’ve', 'been', 'involved', 'in', 'numerous', 'secret', 'raids', 'on', 'Al-Quaeda,', 'and', 'I', 'have', 'over', '300', 'confirmed', 'kills.', 'I', 'am', 'trained', 'in', 'gorilla', 'warfare', 'and', 'I’m', 'the', 'top', 'sniper', 'in', 'the', 'entir-']\n",
      "['What', 'a', 'fat,', 'pathetic', 'virgin.', 'Oh,', 'and', 'you', 'mispelled', '\"guerrilla\",', 'faggot', 'dipshit.']\n",
      "[\"It's\", 'a', 'copypasta,', 'I', \"didn't\", 'write', 'it.', 'How', 'have', 'you', 'never', 'heard', 'of', 'the', 'Navy', 'Seal', 'copypasta,', 'are', 'you', 'trolling', 'rn?']\n",
      "[\"I'm\", 'not', '14,', 'and', 'I', \"don't\", 'live', 'on', 'the', 'internet,', 'so', \"I'm\", 'sure', 'that', \"there's\", 'lots', 'of', 'irrelevant', 'internet', 'bullshit', 'that', 'I', 'am', 'blissfully', 'oblivious', 'to.']\n",
      "['Ew,', 'a', 'boomer.']\n",
      "[\"There's\", 'another', 'term', 'you', 'might', 'want', 'to', 'look', 'up', 'before', 'you', 'use', 'it,', 'dummy.']\n",
      "['Remember', 'grandpa,', 'the', 'doctor', 'said', 'not', 'to', 'get', 'your', 'heart', 'rate', 'up', 'too', 'much.', 'Did', 'you', 'remember', 'to', 'take', 'your', 'medicine', 'this', 'morning?']\n",
      "['I', 'sure', 'did,', 'you', 'young', 'whippet-snorting,', 'faggot-snapper!']\n",
      "['Eww,', 'a', '14', 'year', 'old.']\n",
      "['Lost', 'a', 'couple', 'of', 'followers.', 'Was', 'it', 'something', 'I', 'said?', 'I', 'do', 'respond', 'to', 'criticism', 'you', 'know.']\n",
      "[\"I've\", 'wondered', 'how', 'many', \"I've\", 'lost', 'but', 'never', 'really', 'cared', 'that', 'much', 'to', 'keep', 'track.', 'I', 'get', 'followed', 'mostly', 'because', 'of', 'my', \"'humor'\", 'post,', 'but', 'when', \"it's\", 'time', 'for', 'an', 'opinion', \"I'm\", 'not', 'holding', 'back!', 'Good', 'for', 'you,', 'keep', 'telling', 'the', 'truth!']\n",
      "['I', 'do', 'my', 'retarded', 'best!', 'Tanks!']\n",
      "['She', 'also', 'incites', 'violence!', 'She’s', 'a', 'murderer']\n",
      "['I', 'see', 'your', 'post', 'is', 'of', 'course', 'devoid', 'of', 'any', 'facts.', 'Not', 'sure', 'why', 'you', 'useless', 'fucks', 'post', 'that', 'shit,', 'anyone', 'smarter', 'than', 'you', 'knows', 'it', 'isn’t', 'true,', 'and', 'when', 'I', 'say', 'anyone', 'smarter', 'than', 'you,', 'I', 'mean', 'basically', 'everyone', 'because', 'you', 'guys', 'are', 'fucking', 'retarded', 'cunts.']\n",
      "['Add', 'ONEWAYDOTCOM', 'to', 'the', 'Gab', 'censored', 'hall', 'of', 'martyrs,', 'alongside', 'the', 'great', 'Jsello', 'and', 'the', 'not', 'so', 'great', 'BLITZ', 'and', 'Pepe_Memes.']\n",
      "['😂', '#TOPKEK']\n",
      "['Cheering', 'on', 'censorship.', \"That's\", \"Gab's\", 'palace', 'guard.', 'A', 'bunch', 'of', 'scum', 'who', 'want', 'users', 'banned', 'for', 'their', 'opinions.', 'That', 'was', 'always', 'what', 'Side', 'stood', 'for.']\n",
      "['You', 'cheered', 'on', 'censorship', 'with', 'the', 'doxxing', 'of', 'side', 'What', 'goes', 'around', 'comes', 'around']\n",
      "['Sidephase', 'was', 'lobbying', 'to', 'ban', 'users.', \"'Two\", 'down,', 'two', 'to', \"go',\", 'he', 'said.', 'Then', 'he', 'was', 'gone.']\n",
      "['That', 'was', 'a', 'quick', '180°', 'dread']\n",
      "['I', 'would', 'never', 'have', 'doxxed', 'Side.', 'But', 'I', \"don't\", 'miss', 'him.']\n",
      "['Wow,', 'even', 'I', 'don’t', 'bitch', 'about', 'Side', 'for', 'days', 'on', 'end', 'the', 'way', 'you', 'do!', 'I', 'don’t', 'even', 'have', 'to', 'make', 'stuff', 'up', 'to', 'truthfully', 'be', 'angry', 'at', 'him.', 'Side', 'leaving', 'Gab', 'was', 'a', 'chickenshit', 'move', 'looking', 'back', 'at', 'it.', 'But', 'between', 'the', 'doxing', 'innocent', 'ppl', '&', 'yelling', 'at', 'good', 'friends', '&', 'major', 'fuck', 'up', 'with', 'his', 'girlfriend', '(me).', 'He', 'felt', 'it', 'was', 'the', 'right', 'choice.', 'At', 'the', 'time,', 'it', 'was', 'his', 'choice,', 'he', 'wasn’t', 'asked,', 'it', 'wasn’t', 'pleasant', 'but', 'he', 'took', 'the', 'out.', 'Side', 'felt', 'it', 'would', 'protect', 'everyone.', 'It', 'hasn’t', 'but', 'your', 'bullshit', 'comments', 'really', 'take', 'the', 'cake.', '#MoveTheFuckOn', '#YouAreCommieScum', 'cc:', '@Sockalexis', '@Gee', '@PepeFarmRemembers', '@militanthippy', '@DeplorableBuilder', '@Broken77', '@kgrace', '@Snugglebunny', '@Deplorable_Satoshi', '@LoafOfToast']\n",
      "[\"it's\", 'quite', 'clear', 'that', '#Robocop', '@Judgedread', 'has', 'a', 'crush', 'on', 'your', 'boyfriend...', \"He's\", 'just', 'to', 'much', 'of', 'a', 'sad', 'little', 'e-celeb', 'pussy', 'to', 'admit', 'it.', 'I', 'mean,', 'have', 'you', 'seen', 'how', 'much', 'that', 'faggot', 'talks', 'about', 'Side?', 'His', 'entire', 'page', 'is', 'filled', 'with', 'nothing', 'but', '\"Muh', 'Turbogate', 'and', 'Muh', 'Sidephayze', 'botnet', 'terrorizms\"']\n",
      "['Alyssa', 'Milano:', 'Trump', 'Uses', \"'Cult-Like\", \"Force'\", 'to', 'Communicate', 'With', 'Fans', 'https://www.thewrap.com/alyssa-milano-trump-uses-cult-like-force-to-communicate-with-followers-video/']\n",
      "['who', 'cares', 'what', 'that', 'skank', 'has', 'to', 'say', 'shes', 'a', 'nigger', 'lover!!!']\n",
      "['Cuckstianity', 'is', 'a', 'universalist', 'death', 'cult', 'whose', 'continued', 'profits', 'are', 'contingent', 'upon', 'a', 'steady', 'inflow', 'of', 'retards', 'to', 'whom', 'they', 'can', 'sell', 'everything', 'from', 'rosary', 'beads', 'to', 'salvation.', 'If', 'you', \"can't\", 'understand', 'this,', 'you', 'might', 'belong', 'in', 'the', 'above', 'mentioned', 'retard', 'category.']\n",
      "['https://twitter.com/somethingtexty']\n",
      "['JUST', 'ANOTHER', 'DYKE', 'BITCH']\n",
      "['Macron:', 'European', 'countries', 'will', 'be', 'punished', 'financially', 'if', 'they', 'do', 'not', 'accept', 'migrants', 'https://voiceofeurope.com/2018/10/macron-european-countries-will-be-punished-financially-if-they-do-not-accept-migrants/#.W9Mxvuw-v94.twitter']\n",
      "['Eat', 'Nigger', 'Cock', 'or', 'DIE', 'WHITEY!']\n",
      "['I', 'am', 'pretty', 'sure', \"he's\", 'done', 'that', 'plenty,', 'given', 'the', 'photos', 'he', 'had', 'taken.', 'Only', 'the', 'dieing', 'part', 'left', 'now!!']\n",
      "['you', 'didnt', 'list', 'gospel', 'in', 'this', 'bitch?', 'fuck', 'u']\n",
      "['Hey', 'dipshit,', 'option', '#5', '\"other\"']\n",
      "['gospel', 'is', 'Gospel.', 'not', '\"other\".', 'how', 'moronic', 'r', 'u?', '(very)']\n",
      "['Other', 'is', '\"Anything\"', 'other', 'than', 'listed', 'Douchenozzle.']\n",
      "['not', 'good', 'enough', 'as', 'Other', 'is', 'too', 'vague', 'and', 'not', 'Gospel,', 'it', 'deserved', 'its', 'own', 'dedicated', 'option', 'and', 'if', 'youre', 'to', 'retarded', 'to', 'realize', 'your', 'rabbi', 'prob', 'still', 'touches', 'u']\n",
      "['Hehehehe', 'Riemann', 'had', 'issues', 'he', 'died', 'and', 'left', 'his', 'shit', 'up', 'in', 'the', 'library', 'sanz,', 'like', 'he', 'was', 'trying', 'to', 'be', 'smart', 'like', 'a', 'retarded', 'dove', 'with', 'two', 'broken', 'wings', 'sanz']\n",
      "['I', 'present', 'into', 'evidence:', 'the', '‘brown', 'lipstick', 'is', 'racist’', 'chronicles', 'https://redd.it/9kjz24']\n",
      "['So', 'is', 'the', 'word', 'nigger', 'scary', 'to', 'blacks?']\n",
      "['RT', '@alexsalvinews:', '#BREAKING', 'on', '@OANN:', 'Chicago', 'police', 'Officer', 'Jason', 'Van', 'Dyke', 'found', 'guilty', 'of', 'second-degree', 'murder', 'in', 'the', 'killing', 'of', 'Laquan', 'McDonald.', '#OANN']\n",
      "['Invading', 'the', 'US,', 'Gimmegrants', '😡‼️']\n",
      "['They', 'have', 'been', 'invading', 'for', 'ages.', 'Unfortunately', 'nothing', 'new', 'there.']\n",
      "['Oh,', 'yes', 'it', 'is', 'when', 'your', '💩Illegal', 'President', 'is', 'a', 'Muzzie', 'and', 'brings', 'in', 'a', 'million😡']\n",
      "['Even', 'when', 'a', 'member', 'of', 'the', 'public', 'solves', 'a', 'case', '&', 'hands', 'it', 'to', 'the', 'Bill', 'on', 'a', 'plate', 'they', \"won't\", 'act.', 'https://www.dailymail.co.uk/news/article-6245563/Woman-44-turns-detective-steals-700-bicycle.html?login&param_code=4%2FcAC9_7WSmHtsng2AEPbH5GWpc1NVyRnP2WU81GKVFJnXGtOOGzHjYEwLyuD8fm5S2WylWJhi_nrOmdkqnbYIi4w&param_scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fplus.profile.language.read+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fplus.profile.agerange.read+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.profile+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fplus.me&param__host=www.dailymail.co.uk&param_hideMasthead=&param_hideFooter=&param_geolocation=gb&base_fe_url=https%3A%2F%2Fdailymail.co.uk%2F&validation_fe_uri=%2Fregistration%2Fp%2Fapi%2Ffield%2Fvalidation%2F&check_user_fe_uri=registration%2Fp%2Fapi%2Fuser%2Fuser_check%2F&isMobile=false']\n",
      "['Nothing', 'NEW,', 'I', 'handed', 'a', 'Burglar', 'with', 'evidence', 'of', '7', 'Burglaries', 'to', 'police', 'who', 'informed', 'me', 'they', 'were', 'unable', 'to', 'arrest', 'the', 'Migrant', 'piece', 'of', 'shit', 'because', 'he', 'was', 'an', 'Asylumn', 'seeker.', 'They', 'the', 'told', 'me', 'I', 'could', 'not', 'evict', 'the', 'cunt', 'from', 'my', 'property,', 'you', 'can', 'guess', 'the', 'answer', 'to', 'that,', 'the', 'Imams', 'Yellow', 'Army', 'put', 'the', 'shit', 'in', 'Police', 'TAXI', '&', 'had', 'him', 'rehoused', 'in', 'hours', 'UK', 'Cops', 'USELESS', 'CUNTS!']\n",
      "['Fat', 'frumpy', 'dyke', 'hate', 'crimes', 'herself.', 'https://www.dailymail.co.uk/news/article-6269483/Ohio-student-21-charged-sending-homophobic-threats-herself.html']\n",
      "['A', 'fat', 'dyke', 'cunt']\n",
      "['https://www.westernjournal.com/ct/police-union-lambastes-snl-grossly-inapt-portrayal-officers/']\n",
      "['Saturday', 'Night', 'Live', 'does', 'a', 'grossly', 'offensive', 'portrayal', 'of', 'police.', 'Police', 'Union', 'complains.', 'DEMS', 'really', 'are', 'against', 'law', 'and', 'order,', 'aren’t', 'they⁉️']\n",
      "['A', 'person', 'has', 'to', 'be', 'especially', 'retarded', 'to', 'laugh', 'at', 'anything', 'SNL', 'does', 'nowadays!', 'Works', 'well', 'for', 'a', 'NPC', 'Democrat', 'RETARD', 'though!']\n",
      "['This', 'is', 'still', 'one', 'of', 'the', 'funniest', 'things', \"I've\", 'seen.']\n",
      "['lolol', 'fucking', 'murderous', 'heinous', 'cunt']\n",
      "['It', 'will', 'be', 'a', '250lb', 'ghetto', 'nigger', 'bitch', 'doing', 'the', 'smothering,', 'though...']\n",
      "['Haha', 'the', 'boomers', 'are', 'going', 'to', 'spend', 'the', 'end', 'of', 'their', 'lives', 'being', 'taken', 'care', 'of', 'by', 'niggers', 'spics', 'and', 'philipinos.', 'I', 'have', 'rubbed', 'this', 'in', 'dads', 'face', 'before.']\n",
      "['Poetic', 'justice.', \"They've\", 'spent', 'their', 'entire', 'lives', 'either', 'ignoring,', 'or', 'endorsing', 'the', 'importation', 'of', 'the', 'hoards', 'of', 'savages', 'who', 'hate', 'them,', 'as', 'well', 'as', 'jumping', 'through', 'hoops', 'in', 'order', 'to', 'work', 'against', 'the', 'interests/survival', 'of', 'our', 'people,', 'so', \"it's\", 'only', 'right', 'that', 'they', 'get', '\"taken', 'care', 'of\"', 'by', 'those', 'same', 'barbarians', 'they', 'protected,', 'or', 'neglected.', 'The', 'future', 'will', 'be', 'filled', 'with', 'malnourished', 'BOOMERS', 'in', 'nursing', 'homes', 'covered', 'with', 'bed', 'sores', 'and', 'bruises', 'until', 'the', '250lb', 'transgendered', 'nigger', 'nursing', 'assistant', 'has', 'a', 'bad', 'day', 'and', 'smothers', 'them', 'with', 'a', 'mildew', 'stained', 'pillow.', 'The', 'sad', 'part', 'is,', 'they', 'will', 'probably', 'be', 'too', 'senile', 'to', 'realize', 'their', 'horrible', 'treatment', 'is', 'a', 'punishment', 'for', 'a', 'lifetime', 'of', 'enabling', 'nightmare', 'world', 'to', 'take', 'root', 'and', '\"blossom\".']\n",
      "['FUCKING', 'IDIOT', 'SJW', 'CUNT', 'WHORE', '!!']\n",
      "['Its', 'refreshing', 'to', 'see', 'people', 'say', 'what', 'they', 'think', 'lol.']\n",
      "['“Punished', 'Kavanaugh”', 'is', 'a', 'retarded', 'meme.', 'He’s', 'already', 'stated', 'he’s', 'hiring', 'all', 'female', 'clerks', 'and', 'isn’t', 'going', 'to', 'make', 'abortions', 'illegal.', 'He’s', 'going', 'to', 'come', 'out', 'of', 'this', 'with', 'an', 'even', 'hardened', 'position', 'on', 'the', 'need', 'for', '“fairness.”']\n",
      "[]\n",
      "['His', 'qualifications', 'were', '1.', 'He', 'was', 'Black,', 'half-ass', 'good', 'looking,', 'Harvard', 'degree', '(regardless', 'that', 'he', 'didn’t', 'do', 'much', 'with', 'it', 'and', 'it', 'was', 'paid', 'for', 'by', 'a', 'Saudi', 'Prince', 'he', 'would', 'be', 'beholden', 'to).', 'Typical', 'DemonRAT', 'crook.', 'Manchurian', 'Muzzie', 'Puppet', 'BathHouse', 'Barry.', 'The', 'MSM', 'refused', 'to', 'vet.']\n",
      "[]\n",
      "['Wish', 'POTUS45', 'would', 'unseal', 'Obama’s', 'records.', 'He', 'should', 'have', 'never', 'been', 'president', 'or', 'gotten', 'out', 'of', 'their', 'primaries.', 'By', 'then', 'it', 'should', 'have', 'been', 'public', 'knowledge', 'he', 'wasn’t', 'a', 'US', 'Citizen,', 'had', 'been', 'using', '3', 'SS', '#’s', '&', 'had', 'gone', 'to', 'Occidental', 'on', 'Foreign', 'Student', 'Loan’s.', 'Shows', 'you', 'what', 'con', 'man', 'can', 'be', 'sold', 'by', 'the', 'Fake', 'Media.']\n",
      "['The', 'POS', 'was', 'half', 'Saudi.', 'Obama', 'Sr.', 'was', 'Saudi', 'Arabian', '&', 'many', 'of', 'them', 'are', 'dark', 'skinned.', 'the', \"Saudi's\", 'were', 'in', 'Kenya', 'during', 'the', 'time', 'this', 'miserable', 'sub', 'human', 'POS', 'was', 'born.', 'So', 'even', 'saying', 'he', 'is', 'black', 'is', 'a', 'lie.', 'The', 'goons', 'used', 'the', 'race', 'card', 'to', 'get', 'the', 'POS', 'elected.']\n",
      "['Is', 'Megan', 'Markle', 'a', 'robot?', 'https://youtu.be/bpOY2GkYiR0']\n",
      "[\"No...she's\", 'a', 'fucking', 'nigger']\n",
      "['You', \"don't\", 'have', 'to', 'tell', 'me', \"you're\", 'addicted', 'to', 'fake', 'news.', 'Watch', 'out', 'for', 'that', 'muzzie', 'underneath', 'your', 'bed.', 'LOL']\n",
      "['RT', '@gregorytangelo:', '.@SenFeinstein', '&', '@SenKamalaHarris', 'voted', 'against', 'qualified', 'gay', 'nominee', '@RichardGrenell', 'for', 'Ambassador', 'to', 'Germany.', 'Now', 'they', 'are', 'already', 'on-record', 'opposing', 'qualified', 'gay', 'nominee', 'Patrick', 'Bumatay', 'for', 'the', '#9thCircuit.', 'Even', 'worse?', 'Both', 'are', 'THEIR', 'CONSTITUENTS.', 'https://kek.gg/u/RyP8']\n",
      "['Kamala', 'was', 'a', 'huge', 'nigger', 'wrestler', 'in', 'the', '80s.', 'I', 'see', 'the', 'resemblance.']\n",
      "['It', 'seems', 'refugees', 'are', 'just', 'note', 'grateful', 'for', 'being', 'saved', '!', 'Life', 'sentence', 'for', 'Afghan', 'refugee', 'who', 'raped', 'and', 'burned', 'Finnish', 'girl', 'alive', 'https://voiceofeurope.com/2017/12/life-sentence-for-afghan-refugee-who-raped-and-burned-finnish-girl-alive/']\n",
      "['Not', 'only', 'was', 'this', 'nigger', 'not', 'killed', 'immediately,', 'he', 'got', 'a', 'fucking', 'hearing', 'to', 'appeal', 'his', 'fucking', 'sentence??', 'And', 'he', 'was', 'in', 'a', 'relationship', 'with', 'this', '17', 'y.o.', 'in', 'the', 'first', 'place?', 'Where', 'does', 'it', 'fucking', 'end??', 'Stop', 'being', 'a', 'complacent', 'sack', 'of', 'shit,', 'White', 'man.', 'Ultimately', \"it's\", 'on', 'us', 'for', 'being', 'so', 'spiritually', 'debased.', 'Name', 'the', 'jew,', 'uplift', 'our', 'people,', 'smite', 'our', 'enemies.']\n",
      "['Smite', '-', 'I', 'like', 'that', 'word!']\n",
      "['Mental', 'illness', 'is', 'a', 'very', 'real', 'issue.', 'Seeing', 'attention', 'seeking', 'whores', 'pretending', 'to', 'be', 'something', 'entirely', 'imaginary,', 'and', 'knowingly', 'expecting', 'to', 'be', 'labelled', 'mentally', 'ill', 'for', 'that', 'attention', 'deserve', 'a', 'trip', 'to', 'Yemen,', 'or', 'Syria.', \"They'll\", 'get', 'a', 'lifetime', 'of', 'attention', 'and', 'a', 'very', 'stark', 'message', 'of', 'reality.', 'https://youtu.be/0SRqjSuh4uQ']\n",
      "['\"', 'Derek', 'and', 'Clive', '-', 'cunt', 'kicker', '\"..', 'on', 'U', '-', 'Tube', '=', 'always', 'worth', 'a', 'refresh..']\n",
      "['Ah', 'man,', 'those', 'two', 'are', 'just', 'brilliant,', 'even', 'Dudley', 'trying', 'not', 'to', 'laugh', 'is', 'comedy', 'gold.']\n",
      "['Peter', 'with', 'the', 'hand', 'brake', 'off', 'is', 'as', 'good', 'as', 'you', 'need..']\n",
      "['This', 'is', 'an', 'attempt', 'to', 'silence', 'wrongthink.', 'If', 'you', \"can't\", 'tell', 'that', 'by', 'now,', \"you're\", 'retarded', 'sorry.', 'First', 'whatever,', 'second', 'lolicon,', 'third', 'alluding', 'to', 'all', 'porn,', 'now', 'this.', \"It's\", 'not', 'hard', 'to', 'guess', 'what', 'this', 'means.']\n",
      "[\"What's\", 'going', 'on?', 'Is', 'Gab', 'going', 'to', 'add', 'a', 'block', 'button?']\n",
      "['Yeah', 'but', \"they're\", 'disguising', 'it', 'with', 'another', 'name.']\n",
      "['What', 'name?', 'What', 'is', 'it?', 'By', 'design,', 'Gab', 'must', 'not', 'have', 'a', 'block', 'button.', 'They', 'literally', 'advertise', 'that', 'as', 'a', 'feature.']\n",
      "['Disassociation.', '@gab']\n",
      "['I', 'just', 'saw', 'it.', 'Terrible.', 'Gab', 'is', 'losing', 'what', 'made', 'it', 'unique.', 'At', 'least', 'I', 'still', 'have', 'freedom', 'to', 'say', '#GasTheKikes.', 'But', 'for', 'how', 'long?']\n",
      "['Maybe', 'a', 'week,', 'maybe', 'a', 'month,', 'maybe', 'a', 'year.', 'Who', 'knows?']\n",
      "['But', 'muh', 'disassociation', 'button']\n",
      "['At', 'least', 'you', 'can', 'get', 'rid', 'of', 'Boomers', 'calling', 'you', 'a', 'pedophile', 'apologist.', 'Not', 'that', 'I', 'think', \"it's\", 'all', 'that', 'necessary.']\n",
      "['If', 'I', 'cared', 'that', 'much,', 'I', 'could', 'just', 'mute', 'them', 'and', 'they', 'can', 'have', 'the', 'freedom', 'to', 'talk', 'to', 'other', 'people', 'who', 'might', 'be', 'interested.']\n",
      "['On', 'one', 'hand,', 'there', 'are', 'some', 'really', 'desperate', 'people', 'who', 'like', 'to', 'downvote', 'random', 'posts', 'of', 'mine', 'and', 'spam', 'shit,', 'but', 'on', 'the', 'other', 'hand', 'I', 'trust', 'that', 'most', 'of', 'my', 'followers', 'who', 'I', 'interact', 'with', 'have', 'enough', 'sense', 'to', 'mute', 'them', 'anyways.', 'E-celebs', 'who', 'fear', 'substantial', 'criticism', 'need', 'these', 'kinds', 'of', 'things', 'far', 'more', 'than', 'people', 'who', 'attract', 'obviously', 'baseless', 'spammers.']\n",
      "['I', 'think', 'it', 'is', 'more', 'complicated', 'than', 'that.', 'There', 'are', 'some', 'people', 'here', 'who', 'are', 'just', 'as', 'intolerant', 'and', 'incapable', 'of', 'functional', 'thinking', 'as', 'those', 'they', 'hate', 'on', 'the', 'left.']\n",
      "['After', 'a', 'Black', 'man', 'murdered', 'a', 'Swedish', 'citizen,', 'the', 'Swedish', 'police', 'asked', 'the', 'public', 'for', 'help', 'identifying', 'him', '-', 'but', 'they', 'blurred', 'out', 'his', 'face', 'so', 'you', 'couldn’t', 'tell', 'he', 'was', 'Black.']\n",
      "[]\n",
      "['Exactly,', \"it's\", 'retarded', 'beyond', 'words...']\n",
      "['According', 'to', 'DemonRats', 'Russia', 'is', 'gonna', 'NUKE', 'USA', 'any', 'moment', 'now', 'When', 'in', 'Reality', 'Those', 'Nukes', 'will', 'most', 'likely', 'come', 'from', 'China', 'You', 'can', 'check', 'where', 'I', 'got', 'these', 'images', 'from', 'List', 'of', 'wars', 'involving', 'Russia', 'https://infogalactic.com/info/List_of_wars_involving_Russia', '(and', 'USA)', 'More', 'images', 'in', 'comments']\n",
      "['So', 'True.', 'RUSSIA', 'IS', 'NOT', 'THE', 'PROBLEM.', 'CHINA', 'IS', 'THE', 'PROBLEM', '&', 'HAS', 'BEEN', 'SINCE', 'THAT', 'DAMN', 'POS', 'SCUMDOG', 'TRASH', '&', 'RAPIST', 'BILL', 'CLINTON', 'GAVE', 'ALL', 'OUR', 'TECHNOLOGY', 'AWAY', 'TO', 'CHINA.']\n",
      "[\"I'm\", 'with', 'ya', 'on', 'that', \"Could'a\", 'knocked', 'me', 'over', 'with', 'a', 'feather', 'I', 'remember', 'watching', 'the', 'news', 'when', 'GH', 'called', 'for', 'a', 'NWO', 'But', 'had', 'NO', 'IDEA', 'what', 'he', 'was', 'talking', 'about', 'See,', 'I', 'never', 'really', 'paid', 'politics', 'any', 'attention', 'till', 'that', 'damn', 'Tranny', '&', 'Faggot', 'Kenyan', 'began', 'occupying', 'the', 'WH', \"That's\", 'when', 'I', 'started', 'learning']\n",
      "['news', 'flash', 'anti', 'jew', 'nazis', 'on', 'here....WHITE', 'PEOPLE', 'INVENTED', 'SOCIALISM', 'COMMUNISM!!!', 'so', 'we', 'gota', 'hate', 'all', 'the', 'whites', 'too!!!', 'if', 'u', 'blame', 'jews', 'for', 'every', 'evil', 'plot', 'u', 'see', 'in', 'everything', 'then', 'hate', 'ur', 'white', 'nazi', 'self', 'for', 'being', 'white', 'and', 'inventing', 'the', 'evil', 'socialism', 'communism']\n",
      "['Carl', 'Marx', 'and', 'Trotsky', \"we're\", 'Jews', 'the', 'Bolshevik', 'Revolution', 'was', 'lead', 'by', 'Jews.', 'All', 'the', 'communist', 'uprisings', 'and', 'revolutions', 'in', 'Europe', \"we're\", 'lead', 'by', 'Jews.', 'Hell', 'communism', 'in', 'Cuba', 'was', 'started', 'out', 'of', 'the', 'main', 'synagogue', 'there,', '(Wich', 'I', 'think', 'is', 'the', 'oldest', 'in', 'the', 'new', 'world).', 'So', 'no,', 'this', 'is', 'all', 'bullshit.']\n",
      "['This', 'is', 'a', 'retarded', 'argument']\n",
      "['Glad', 'you', 'can', 'admit', 'to', 'being', 'an', 'autistic', 'retard', 'that', 'wants', 'to', 'suck', 'cock.', 'Now', 'fuck', 'off', 'fag.']\n",
      "['The', 'only', 'way', 'to', 'remedy', 'the', 'jewish', 'problem', 'in', 'the', 'long', 'term', 'is', 'to', 'wake', 'up', 'as', 'many', 'people', 'as', 'possible.', 'A', 'guy', 'going', 'out', 'and', 'killing', 'jews', 'makes', 'it', 'harder', 'to', 'wake', 'normies', 'up.', 'Society', 'as', 'a', 'whole', 'must', 'deal', 'with', 'the', 'jews...', 'and', 'vigilantism', 'will', 'only', 'impede', 'achievement', 'of', 'the', 'societal', 'mass-awakening.', 'If', 'anyone', 'who', 'is', 'woke', 'to', 'the', 'jews', 'can', 'honestly', 'say', 'that', 'upon', 'their', 'initial', 'awakening,', 'that', 'unilateral', 'action', 'did', 'not', 'cross', 'their', 'mind,', 'comment', 'here,', 'and', 'I', 'will', 'call', 'you', 'a', 'liar.', 'We', 'are', 'dealing', 'with', 'the', 'most', 'genocidal,', 'evil,', 'deceptive', 'group', 'of', 'people', 'to', 'ever', 'live,', 'and', 'some', 'people', 'who', 'wake', 'up', 'to', 'their', 'evil', 'just', 'cannot', 'bear', 'the', 'pain', 'that', 'comes', 'with', 'being', 'awake', 'before', 'a', 'critical', 'mass', 'of', 'the', 'population', 'is', 'awake.', 'If', 'you', 'feel', 'like', 'hurting', 'jews,', 'JUST', 'GO', 'OUT', 'AND', 'NAME', 'THE', 'JEW', 'instead.']\n",
      "['\"Bitch,', 'your', 'submissive', 'whining', 'is', 'what', 'makes', 'us', 'look', 'bad.', 'I’m', 'sure', 'there’s', 'plenty', 'of', 'nice', 'old', 'nigger', 'church', 'ladies', 'in', 'South', 'Africa', 'helping', 'finance', 'the', 'ongoing', 'slaughter', 'of', 'Whites', 'over', 'there,', 'too.\"', 'https://archive.is/w61o4']\n",
      "['LYING', 'CUNT', 'BITCH', '!!']\n",
      "['Watch', \"Henrik's\", 'interview', 'with', 'Millennial', 'Woes', 'about', 'the', 'suspension', 'of', 'his', 'Twitter', 'account.', 'https://redice.tv/red-ice-tv/the-censorship-question-millennial-woes-suspended-from-twitter-freewoes', 'A', 'totally', 'uncontroversial', 'reply', 'got', 'Woes', 'account', '-', 'with', '22K', 'followers', '-', 'suspended.']\n",
      "['Oh', 'no!', 'MW', 'the', 'faggot', 'who', 'says', 'he', 'likes', '\"pretty', 'boys\"', 'was', 'censored!', 'Better', 'get', 'Fed', 'Ice', 'on', 'the', 'case.']\n",
      "['Hims', 'dindu', 'nufin!']\n",
      "[]\n",
      "['Get', 'fucked', 'you', 'low', 'life', 'unwashed', 'drug', 'fucked', 'unemployed', 'Nazi', 'racist', 'racist', 'Antifa', 'cunt!']\n",
      "['Once', 'again', 'you', 'show', 'how', 'fucking', 'retarded', 'you', 'are', 'you', 'r@cist', 'Nazi', 'cunt.', 'I', 'am', 'Aboriginal', 'therefore', 'unlike', 'yourself', 'I', 'am', 'most', 'definitely', 'not', 'a', 'racist', 'Nazi', 'cunt.', 'Furthermore', 'I', 'will', 'continue', 'to', 'respond', 'to', 'your', 'fucking', 'racist', 'Nazi', 'cunt', 'comments.', 'You', 'have', 'no', 'authority', 'to', 'tell', 'me', 'what', 'to', 'do', 'you', 'fuckwit.']\n",
      "['WATCH:', 'Pennsylvania', 'governor', 'candidate', 'Scott', 'Wagner', 'tells', 'Gov.', 'Tom', 'Wolf', \"he's\", 'going', 'to', 'stomp', 'on', 'his', 'face', 'with', 'golf', 'spikes', 'in', 'an', 'aggressive', 'campaign', 'video', 'released', 'on', 'Facebook.', 'https://kek.gg/u/brqN']\n",
      "['A', 'bit', 'too', 'aggressive', 'there.']\n",
      "[\"He's\", 'a', 'nobody', \"that's\", 'about', 'to', 'get', 'stomped', 'in', 'the', 'upcoming', 'election.', 'But', 'Dems', 'are', 'going', 'to', 'try', 'to', 'paint', 'this', 'retard', 'as', 'the', 'spokesperson', 'for', 'the', 'entire', 'GOP.']\n",
      "['fuckin', 'skål', 'man.', 'skål', 'to', 'the', 'fuck', 'heil', 'dudes', 'fuckin', 'odin', 'smash', 'your', 'fuckin', 'brains', 'out', 'and', 'give', 'me', 'beer', 'and', 'women', 'til', 'valhalla']\n",
      "[]\n",
      "['actually', 'im', 'retarded', 'and', 'blind', 'and', \"didn't\", 'count', 'the', 'fingers']\n",
      "['Super', 'cringe.']\n",
      "['Fuck', 'this', 'gay', 'earth.', 'If', 'this', \"doesn't\", 'trigger', 'that', 'nigger', 'jesus', 'to', 'come', 'back', 'nothing', 'will.']\n",
      "['@CrafyFox', 'FUCK', 'OFF', 'YOU', 'STUPID', 'FUCKING', 'NIGGER', 'FUCKER!!!', 'GO', 'SUCK', 'A', 'COCK,', 'FUCKTARD!!!!']\n",
      "['LOL', 'your', 'use', 'of', 'capital', 'letters', 'is', 'inspiring,', 'sadly', 'your', 'poor', 'use', 'of', 'the', 'English', 'Language', 'is', 'not.', 'Would', 'expect', 'nothing', 'more', 'from', 'a', 'low', 'intelligence', '#biffer.']\n",
      "['No', 'one', 'hates', 'a', 'nigger', 'like', 'a', 'nigger.']\n",
      "['Lowes', 'TV', 'commercial', 'just', 'showed', '&', 'Negro', '&', 'a', 'White', 'woman', 'appearing', 'as', 'married.', 'Hardly', 'anything', 'can', 'be', 'more', 'offensive,', 'as', 'it', 'has', 'been', 'since', 'the', 'beginning', 'of', 'time,', 'than', 'masegination.']\n",
      "['Nothing', 'new', 'here.', \"They've\", 'been', 'bombarding', 'us', 'with', 'that', 'kind', 'of', 'PC', 'garbage', 'for', 'a', 'decade.', \"It's\", 'not', 'happening.', 'I', 'think', \"it's\", 'to', 'overload', 'a', \"person's\", 'mind.']\n",
      "['It', 'started', 'w/Obama.', '2', 'mos', 'after', 'he', 'was', 'in', 'the', 'cunt', 'running', 'History', 'CH', 'Wiped', 'OUT', 'History', '&', 'put', 'in', 'BS/Pawn', 'Stars.', 'I', 'spoke', 'to', 'her', 'on', 'the', 'ph.', 'She', 'said', 'no1', 'wanted', 'to', 'see', 'History', 'any', 'more.', 'I', 'was', 'Flabbergasted', 'by', 'her', 'stupidity.', 'Then', \"McD's\", 'put', 'on', 'a', 'Commercial', 'w/', 'the', 'Blackest', 'Negro', 'guy', 'sitting', 'w/the', 'whitest', 'platinum', 'blonde', 'ever.', 'I', 'called', '&', 'Railed', 'at', \"McD's.\", 'I', 'never', 'saw', 'it', 'again.']\n",
      "['That', 'was', 'rough', 'times.', 'I', \"didn't\", 'really', \"didn't\", 'even', 'know', 'who', 'I', 'was', 'anymore.', 'As', 'if', 'I', 'was', 'hit', 'by', 'a', 'bolt', 'of', 'lightning.', 'Sure', 'wish', 'that', \"hadn't\", 'had', 'to', 'happen', 'to', 'our', 'country.', 'There', \"isn't\", 'any', 'rational', 'for', 'it.']\n",
      "['Its', 'Brainwashing', 'pure', '&', 'simple.']\n",
      "['That', '08', 'Crash', 'was', 'bc', 'of', 'Clinton', 'repealing', 'the', 'Glass', 'Steagall', 'Act.', 'That', 'was', '&', 'is', 'prt', 'of', 'Bad', 'Times', 'in', 'US', '4', 'Whites', 'Drained', 'of', 'our', 'life', 'savings.', 'Bolt', 'of', 'Lightning!']\n",
      "['That', 'mixed', 'with', 'a', 'black', 'muslim', 'dumbass', 'President', 'while', 'we', 'were', 'in', 'a', 'war', 'with', 'them.', 'It', 'was', 'rape', 'by', 'people', 'dumber', 'than', 'dirt.', \"It's\", 'no', 'wonder', 'people', 'have', 'tattoos', 'all', 'over', 'themselves.', 'Acting', 'like', 'crazy', 'people.']\n",
      "['(My', 'keys', 'r', 'broken)', 'In', 'the', \"90's\", 'A&E', 'started', 'running', 'TATTOO', 'contests', '&', 'shows.', 'This', 'was', 'another', 'BS', 'thing', 'pulled', 'on', 'Whites.', 'It', 'was', 'brainwashing', 'to', 'start', 'a', 'new', 'industry,', 'Tattoos,', 'a', 'New', 'Small', 'BS', 'Biz', 'in', 'America', 'to', 'replace', 'Jobs', 'to', 'China.', 'Another', 'Double', \"Fuck'n\", 'by', 'CLINTON!']\n",
      "['I', 'know', 'my', 'life', 'would', 'be', 'much', 'better', 'if', 'George', 'HW', 'Bush', 'would', 'have', 'won', 'a', 'second', 'term.', 'We', \"wouldn't\", 'had', 'to', 'worry', 'about', 'Jr', 'there', 'or', '9/11.', 'Sure', \"wouldn't\", 'have', 'had', '8', 'years', 'of', 'Obozo.']\n",
      "['FREE', 'Them', 'ALL!!!', ':::The', 'TRUTH', 'Fears', 'NO', 'Investigation:::', 'Please', 'POST-EVERYWHERE', ':-)']\n",
      "['FREE', 'Them', 'ALL!!!', ':::The', 'TRUTH', 'Fears', 'NO', 'Investigation:::', 'Please', 'POST-EVERYWHERE', ':-)']\n",
      "['The', 'Poisonous', 'Allure', 'of', 'Right-Wing', 'Violence', 'https://www.nationalreview.com/2018/10/gavin-mcinnes-proud-boys-poisonous-violence/']\n",
      "['Pretty', 'much', 'sums', 'up', 'why', 'I', 'am', 'not', 'voting', 'for', 'these', 'losers', 'in', 'November']\n",
      "['The', 'only', 'reason', 'I', 'have', 'decided', 'to', 'delay', 'my', 'own', 'total', 'disconnect', 'from', 'the', 'voting', 'machine', 'is', 'because', 'the', 'democrats', 'went', 'ultimate', 'full', 'retard', 'and', 'REALLY', 'pushed', 'this', 'disgruntled', 'patriot', 'back', 'into', 'the', 'voting', 'fold.', 'Otherwise,', \"I'd\", 'be', 'standing', 'outside', 'the', 'polls', 'laughing', 'at', 'every', 'Republican', 'almost', 'as', 'hard', 'as', 'I', 'do', 'at', 'the', 'Democrats.']\n",
      "['Vote', 'Democrat!', 'Mobs,', 'not', 'Jobs!', 'Safe', 'spaces,', 'not', 'Safety!', 'Free', 'stuff,', 'not', 'Freedom!']\n",
      "['The', 'democrats', 'are', 'the', 'enemy.', 'The', 'republicans', 'are', '(usually)', 'their', 'Vichy', 'allies.']\n",
      "['Bette', 'Midler', 'Tweets', 'Women', '‘Are', 'the', 'N-Word', 'of', 'the', 'World’', \"'Raped,\", 'Beaten,', \"Enslaved'\", 'https://kek.gg/u/dWhg']\n",
      "['what', 'a', 'crock', 'of', 'shit....', 'Men', 'are', 'the', 'shit', 'carriers', 'for', 'every', 'moaning', 'faced', 'twat', 'like', 'her.', 'We', 'fight', 'the', 'wars,', 'we', 'protect', 'her', 'and', 'the', 'children.', 'we', 'work', 'ourselves', 'into', 'an', 'early', 'grave', 'to', 'let', 'them', 'stay', 'home', 'and', 'drink', 'gin.', 'What', 'a', 'cunt!']\n",
      "['CNN:', 'President', 'Trump', 'Insults', 'Female', 'Journalists', 'During', 'Rose', 'Garden', 'Press', 'Conference', 'https://youtu.be/jB1TvK41Z14']\n",
      "['Then', 'they', 'bring', 'in', 'the', 'house', 'nigger', 'April', 'Ryan,', 'and', 'the', 'white', 'stooge!']\n",
      "[]\n",
      "['I', 'call', 'everybody', 'a', 'faggot', 'so', 'I', 'guess', 'im', 'cool']\n",
      "['Yet...you', 'like', 'HARD', 'FAGS...sort', 'of', 'CONTRADICTORY', \"don't\", 'you', 'suck?', 'I', 'mean', 'think...you', 'grew', 'up', 'with', 'your', 'Hillbilly', 'Daddy', 'fucking', 'you...all', 'people', 'named', 'SIMS', 'have', 'turned', 'out', 'to', 'be', 'GAY!', 'You', 'SIM-ULATE', 'being', 'human...as', 'most', 'Country', 'Fuck', 'Hillbillies', 'do.', 'Real', 'Men', 'frighten', 'you.']\n",
      "['Dumb', 'ass', 'Democrat', 'Plantation', 'Slave,', 'and', 'CNN', 'fake', 'news', 'pimp,', 'Don', 'Lemon', 'said,', 'that', 'every', 'black', 'American', '\"cringed\"', 'when', 'they', 'watched', 'Kanye', 'West', 'speaking', 'at', 'the', 'White', 'House.', 'Golly', 'Don,', 'I', \"didn't\", 'realize', 'EVERY', 'black', 'person', 'thinks', 'like', 'you.', 'Quite', 'the', 'arrogant,', 'elitist', 'attitude!', 'Pigeonhole', 'the', 'ENTIRE', 'black', 'community.', \"That's\", 'called', 'racism,', 'ya', 'stupid', 'DOLT.']\n",
      "['Maybe', 'he', 'means', 'every', 'black', 'faggot', 'like', 'him?!', ':)']\n",
      "['@a', '@e', '@Mr_Bond', '@Amy', 'https://www.youtube.com/watch?v=IU3nyBtl1vU']\n",
      "['This', 'video', 'is', 'shit.']\n",
      "['I', 'like', 'it', 'though...', 'wuz', 'always', 'wondering', 'who', 'was', 'that', 'faggot', 'that', 'made', 'it?!', 'seems', 'filmed', 'in', 'Bruxhells.']\n",
      "['UPVOTE/DOWNVOTE', 'RATIO', 'DOES', 'NOT', 'LIE']\n",
      "['What', 'significance', 'do', 'you', 'attach', 'to', 'my', 'ratio?', 'I', 'take', 'on', 'the', 'human', 'debris', 'who', 'come', 'here;', 'the', 'nazis,', 'fascists,', 'antisemites,', 'and', 'bigots.', 'I', 'do', 'it', 'as', 'a', 'public', 'service.', 'My', 'ratio', 'holds', 'no', 'importance', 'to', 'me.', 'Think', 'of', 'it', 'as', 'battle', 'scars.']\n",
      "['Stop', 'being', 'a', 'faggot', 'and', 'stand', 'up', 'for', 'your', 'race,', 'white', 'man.']\n",
      "['What', 'a', 'goofy', 'statement.', 'We', 'call', 'it', 'the', 'human', 'race.', 'Perhaps', 'you', 'have', 'heard', 'of', 'it.']\n"
     ]
    }
   ],
   "source": [
    "for texts in content_gab['text']:\n",
    "    for sentence in texts:\n",
    "        words = sentence.split()\n",
    "        words.pop(0)\n",
    "        print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[22, 1], edge_index=[2, 21], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[67, 1], edge_index=[2, 66], y=[1])\n",
      "Data(x=[39, 1], edge_index=[2, 38], y=[1])\n",
      "Data(x=[29, 1], edge_index=[2, 28], y=[1])\n",
      "Data(x=[26, 1], edge_index=[2, 25], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[44, 1], edge_index=[2, 43], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[32, 1], edge_index=[2, 31], y=[1])\n",
      "Data(x=[37, 1], edge_index=[2, 36], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[68, 1], edge_index=[2, 67], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[35, 1], edge_index=[2, 34], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[25, 1], edge_index=[2, 24], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[45, 1], edge_index=[2, 44], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[41, 1], edge_index=[2, 40], y=[1])\n",
      "Data(x=[43, 1], edge_index=[2, 42], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[45, 1], edge_index=[2, 44], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[43, 1], edge_index=[2, 42], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[29, 1], edge_index=[2, 28], y=[1])\n",
      "Data(x=[1, 1], edge_index=[0], y=[1])\n",
      "Data(x=[24, 1], edge_index=[2, 23], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[65, 1], edge_index=[2, 64], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[59, 1], edge_index=[2, 58], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[31, 1], edge_index=[2, 30], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[31, 1], edge_index=[2, 30], y=[1])\n",
      "Data(x=[19, 1], edge_index=[2, 18], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[23, 1], edge_index=[2, 22], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[25, 1], edge_index=[2, 24], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[113, 1], edge_index=[2, 112], y=[1])\n",
      "Data(x=[30, 1], edge_index=[2, 29], y=[1])\n",
      "Data(x=[28, 1], edge_index=[2, 27], y=[1])\n",
      "Data(x=[66, 1], edge_index=[2, 65], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[28, 1], edge_index=[2, 27], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[67, 1], edge_index=[2, 66], y=[1])\n",
      "Data(x=[27, 1], edge_index=[2, 26], y=[1])\n",
      "Data(x=[19, 1], edge_index=[2, 18], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[55, 1], edge_index=[2, 54], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[32, 1], edge_index=[2, 31], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[35, 1], edge_index=[2, 34], y=[1])\n",
      "Data(x=[45, 1], edge_index=[2, 44], y=[1])\n",
      "Data(x=[35, 1], edge_index=[2, 34], y=[1])\n",
      "Data(x=[29, 1], edge_index=[2, 28], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[194, 1], edge_index=[2, 193], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[31, 1], edge_index=[2, 30], y=[1])\n",
      "Data(x=[63, 1], edge_index=[2, 62], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[54, 1], edge_index=[2, 53], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[49, 1], edge_index=[2, 48], y=[1])\n",
      "Data(x=[19, 1], edge_index=[2, 18], y=[1])\n",
      "Data(x=[44, 1], edge_index=[2, 43], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[31, 1], edge_index=[2, 30], y=[1])\n",
      "Data(x=[39, 1], edge_index=[2, 38], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[29, 1], edge_index=[2, 28], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[24, 1], edge_index=[2, 23], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[24, 1], edge_index=[2, 23], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[26, 1], edge_index=[2, 25], y=[1])\n",
      "Data(x=[37, 1], edge_index=[2, 36], y=[1])\n",
      "Data(x=[73, 1], edge_index=[2, 72], y=[1])\n",
      "Data(x=[241, 1], edge_index=[2, 240], y=[1])\n",
      "Data(x=[65, 1], edge_index=[2, 64], y=[1])\n",
      "Data(x=[52, 1], edge_index=[2, 51], y=[1])\n",
      "Data(x=[45, 1], edge_index=[2, 44], y=[1])\n",
      "Data(x=[38, 1], edge_index=[2, 37], y=[1])\n",
      "Data(x=[53, 1], edge_index=[2, 52], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[32, 1], edge_index=[2, 31], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[30, 1], edge_index=[2, 29], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[156, 1], edge_index=[2, 155], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[1, 1], edge_index=[0], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[26, 1], edge_index=[2, 25], y=[1])\n",
      "Data(x=[24, 1], edge_index=[2, 23], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[54, 1], edge_index=[2, 53], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[26, 1], edge_index=[2, 25], y=[1])\n",
      "Data(x=[42, 1], edge_index=[2, 41], y=[1])\n",
      "Data(x=[29, 1], edge_index=[2, 28], y=[1])\n",
      "Data(x=[26, 1], edge_index=[2, 25], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[37, 1], edge_index=[2, 36], y=[1])\n",
      "Data(x=[24, 1], edge_index=[2, 23], y=[1])\n",
      "Data(x=[24, 1], edge_index=[2, 23], y=[1])\n",
      "Data(x=[38, 1], edge_index=[2, 37], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[19, 1], edge_index=[2, 18], y=[1])\n",
      "Data(x=[40, 1], edge_index=[2, 39], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[43, 1], edge_index=[2, 42], y=[1])\n",
      "Data(x=[40, 1], edge_index=[2, 39], y=[1])\n",
      "Data(x=[23, 1], edge_index=[2, 22], y=[1])\n",
      "Data(x=[42, 1], edge_index=[2, 41], y=[1])\n",
      "Data(x=[44, 1], edge_index=[2, 43], y=[1])\n",
      "Data(x=[1, 1], edge_index=[0], y=[1])\n",
      "Data(x=[38, 1], edge_index=[2, 37], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[38, 1], edge_index=[2, 37], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[57, 1], edge_index=[2, 56], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[48, 1], edge_index=[2, 47], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[53, 1], edge_index=[2, 52], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[59, 1], edge_index=[2, 58], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[82, 1], edge_index=[2, 81], y=[1])\n",
      "Data(x=[24, 1], edge_index=[2, 23], y=[1])\n",
      "Data(x=[33, 1], edge_index=[2, 32], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[58, 1], edge_index=[2, 57], y=[1])\n",
      "Data(x=[59, 1], edge_index=[2, 58], y=[1])\n",
      "Data(x=[50, 1], edge_index=[2, 49], y=[1])\n",
      "Data(x=[30, 1], edge_index=[2, 29], y=[1])\n",
      "Data(x=[42, 1], edge_index=[2, 41], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[23, 1], edge_index=[2, 22], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[1, 1], edge_index=[0], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[31, 1], edge_index=[2, 30], y=[1])\n",
      "Data(x=[68, 1], edge_index=[2, 67], y=[1])\n",
      "Data(x=[20, 1], edge_index=[2, 19], y=[1])\n",
      "Data(x=[63, 1], edge_index=[2, 62], y=[1])\n",
      "Data(x=[82, 1], edge_index=[2, 81], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[63, 1], edge_index=[2, 62], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[26, 1], edge_index=[2, 25], y=[1])\n",
      "Data(x=[53, 1], edge_index=[2, 52], y=[1])\n",
      "Data(x=[38, 1], edge_index=[2, 37], y=[1])\n",
      "Data(x=[61, 1], edge_index=[2, 60], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[41, 1], edge_index=[2, 40], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[31, 1], edge_index=[2, 30], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[27, 1], edge_index=[2, 26], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[29, 1], edge_index=[2, 28], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[28, 1], edge_index=[2, 27], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[25, 1], edge_index=[2, 24], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[22, 1], edge_index=[2, 21], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[68, 1], edge_index=[2, 67], y=[1])\n",
      "Data(x=[64, 1], edge_index=[2, 63], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[42, 1], edge_index=[2, 41], y=[1])\n",
      "Data(x=[47, 1], edge_index=[2, 46], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[36, 1], edge_index=[2, 35], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[34, 1], edge_index=[2, 33], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[19, 1], edge_index=[2, 18], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[1, 1], edge_index=[0], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[22, 1], edge_index=[2, 21], y=[1])\n",
      "Data(x=[273, 1], edge_index=[2, 272], y=[1])\n",
      "Data(x=[51, 1], edge_index=[2, 50], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[55, 1], edge_index=[2, 54], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[32, 1], edge_index=[2, 31], y=[1])\n",
      "Data(x=[61, 1], edge_index=[2, 60], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[1, 1], edge_index=[0], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[48, 1], edge_index=[2, 47], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[25, 1], edge_index=[2, 24], y=[1])\n",
      "Data(x=[26, 1], edge_index=[2, 25], y=[1])\n",
      "Data(x=[64, 1], edge_index=[2, 63], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[40, 1], edge_index=[2, 39], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[33, 1], edge_index=[2, 32], y=[1])\n",
      "Data(x=[29, 1], edge_index=[2, 28], y=[1])\n",
      "Data(x=[19, 1], edge_index=[2, 18], y=[1])\n",
      "Data(x=[57, 1], edge_index=[2, 56], y=[1])\n",
      "Data(x=[33, 1], edge_index=[2, 32], y=[1])\n",
      "Data(x=[158, 1], edge_index=[2, 157], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[25, 1], edge_index=[2, 24], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[67, 1], edge_index=[2, 66], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[24, 1], edge_index=[2, 23], y=[1])\n",
      "Data(x=[54, 1], edge_index=[2, 53], y=[1])\n",
      "Data(x=[34, 1], edge_index=[2, 33], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[55, 1], edge_index=[2, 54], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[48, 1], edge_index=[2, 47], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[51, 1], edge_index=[2, 50], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[33, 1], edge_index=[2, 32], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[35, 1], edge_index=[2, 34], y=[1])\n",
      "Data(x=[62, 1], edge_index=[2, 61], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[23, 1], edge_index=[2, 22], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[34, 1], edge_index=[2, 33], y=[1])\n",
      "Data(x=[56, 1], edge_index=[2, 55], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[33, 1], edge_index=[2, 32], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[26, 1], edge_index=[2, 25], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[83, 1], edge_index=[2, 82], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[46, 1], edge_index=[2, 45], y=[1])\n",
      "Data(x=[59, 1], edge_index=[2, 58], y=[1])\n",
      "Data(x=[62, 1], edge_index=[2, 61], y=[1])\n",
      "Data(x=[28, 1], edge_index=[2, 27], y=[1])\n",
      "Data(x=[50, 1], edge_index=[2, 49], y=[1])\n",
      "Data(x=[38, 1], edge_index=[2, 37], y=[1])\n",
      "Data(x=[42, 1], edge_index=[2, 41], y=[1])\n",
      "Data(x=[1, 1], edge_index=[0], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[35, 1], edge_index=[2, 34], y=[1])\n",
      "Data(x=[38, 1], edge_index=[2, 37], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[27, 1], edge_index=[2, 26], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[31, 1], edge_index=[2, 30], y=[1])\n",
      "Data(x=[67, 1], edge_index=[2, 66], y=[1])\n",
      "Data(x=[67, 1], edge_index=[2, 66], y=[1])\n",
      "Data(x=[89, 1], edge_index=[2, 88], y=[1])\n",
      "Data(x=[71, 1], edge_index=[2, 70], y=[1])\n",
      "Data(x=[22, 1], edge_index=[2, 21], y=[1])\n",
      "Data(x=[1, 1], edge_index=[0], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[35, 1], edge_index=[2, 34], y=[1])\n",
      "Data(x=[71, 1], edge_index=[2, 70], y=[1])\n",
      "Data(x=[15, 1], edge_index=[2, 14], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[22, 1], edge_index=[2, 21], y=[1])\n",
      "Data(x=[62, 1], edge_index=[2, 61], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[48, 1], edge_index=[2, 47], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[50, 1], edge_index=[2, 49], y=[1])\n",
      "Data(x=[49, 1], edge_index=[2, 48], y=[1])\n",
      "Data(x=[58, 1], edge_index=[2, 57], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[26, 1], edge_index=[2, 25], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[23, 1], edge_index=[2, 22], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[42, 1], edge_index=[2, 41], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[47, 1], edge_index=[2, 46], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[25, 1], edge_index=[2, 24], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[113, 1], edge_index=[2, 112], y=[1])\n",
      "Data(x=[52, 1], edge_index=[2, 51], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[42, 1], edge_index=[2, 41], y=[1])\n",
      "Data(x=[1, 1], edge_index=[0], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[20, 1], edge_index=[2, 19], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[30, 1], edge_index=[2, 29], y=[1])\n",
      "Data(x=[31, 1], edge_index=[2, 30], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[23, 1], edge_index=[2, 22], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[23, 1], edge_index=[2, 22], y=[1])\n",
      "Data(x=[72, 1], edge_index=[2, 71], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[1, 1], edge_index=[0], y=[1])\n",
      "Data(x=[22, 1], edge_index=[2, 21], y=[1])\n",
      "Data(x=[22, 1], edge_index=[2, 21], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[29, 1], edge_index=[2, 28], y=[1])\n",
      "Data(x=[121, 1], edge_index=[2, 120], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[38, 1], edge_index=[2, 37], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[47, 1], edge_index=[2, 46], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[58, 1], edge_index=[2, 57], y=[1])\n",
      "Data(x=[52, 1], edge_index=[2, 51], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[20, 1], edge_index=[2, 19], y=[1])\n",
      "Data(x=[36, 1], edge_index=[2, 35], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[24, 1], edge_index=[2, 23], y=[1])\n",
      "Data(x=[64, 1], edge_index=[2, 63], y=[1])\n",
      "Data(x=[6, 1], edge_index=[2, 5], y=[1])\n",
      "Data(x=[49, 1], edge_index=[2, 48], y=[1])\n",
      "Data(x=[17, 1], edge_index=[2, 16], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[36, 1], edge_index=[2, 35], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[25, 1], edge_index=[2, 24], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[21, 1], edge_index=[2, 20], y=[1])\n",
      "Data(x=[25, 1], edge_index=[2, 24], y=[1])\n",
      "Data(x=[62, 1], edge_index=[2, 61], y=[1])\n",
      "Data(x=[30, 1], edge_index=[2, 29], y=[1])\n",
      "Data(x=[32, 1], edge_index=[2, 31], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[43, 1], edge_index=[2, 42], y=[1])\n",
      "Data(x=[31, 1], edge_index=[2, 30], y=[1])\n",
      "Data(x=[56, 1], edge_index=[2, 55], y=[1])\n",
      "Data(x=[46, 1], edge_index=[2, 45], y=[1])\n",
      "Data(x=[53, 1], edge_index=[2, 52], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[144, 1], edge_index=[2, 143], y=[1])\n",
      "Data(x=[34, 1], edge_index=[2, 33], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[27, 1], edge_index=[2, 26], y=[1])\n",
      "Data(x=[20, 1], edge_index=[2, 19], y=[1])\n",
      "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[53, 1], edge_index=[2, 52], y=[1])\n",
      "Data(x=[29, 1], edge_index=[2, 28], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[29, 1], edge_index=[2, 28], y=[1])\n",
      "Data(x=[24, 1], edge_index=[2, 23], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[2, 1], edge_index=[2, 1], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[27, 1], edge_index=[2, 26], y=[1])\n",
      "Data(x=[8, 1], edge_index=[2, 7], y=[1])\n",
      "Data(x=[31, 1], edge_index=[2, 30], y=[1])\n",
      "Data(x=[27, 1], edge_index=[2, 26], y=[1])\n",
      "Data(x=[72, 1], edge_index=[2, 71], y=[1])\n",
      "Data(x=[40, 1], edge_index=[2, 39], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[32, 1], edge_index=[2, 31], y=[1])\n",
      "Data(x=[37, 1], edge_index=[2, 36], y=[1])\n",
      "Data(x=[48, 1], edge_index=[2, 47], y=[1])\n",
      "Data(x=[36, 1], edge_index=[2, 35], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[11, 1], edge_index=[2, 10], y=[1])\n",
      "Data(x=[7, 1], edge_index=[2, 6], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[55, 1], edge_index=[2, 54], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[14, 1], edge_index=[2, 13], y=[1])\n",
      "Data(x=[45, 1], edge_index=[2, 44], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[13, 1], edge_index=[2, 12], y=[1])\n",
      "Data(x=[0, 1], edge_index=[0], y=[1])\n",
      "Data(x=[10, 1], edge_index=[2, 9], y=[1])\n",
      "Data(x=[42, 1], edge_index=[2, 41], y=[1])\n",
      "Data(x=[55, 1], edge_index=[2, 54], y=[1])\n",
      "Data(x=[9, 1], edge_index=[2, 8], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[4, 1], edge_index=[2, 3], y=[1])\n",
      "Data(x=[18, 1], edge_index=[2, 17], y=[1])\n",
      "Data(x=[5, 1], edge_index=[2, 4], y=[1])\n",
      "Data(x=[43, 1], edge_index=[2, 42], y=[1])\n",
      "Data(x=[12, 1], edge_index=[2, 11], y=[1])\n",
      "Data(x=[16, 1], edge_index=[2, 15], y=[1])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "# Function to construct a graph for a single sentence\n",
    "def construct_graph_words(sentence, label):\n",
    "    # Split sentence into words and remove the first word\n",
    "    words = sentence.split()[1:]\n",
    "\n",
    "    # Create nodes (word embeddings, or simple indices for now)\n",
    "    nodes = list(range(len(words)))\n",
    "\n",
    "    # Create edges (sequential connections: i -> i+1)\n",
    "    edges = [(i, i+1) for i in range(len(words)-1)]  # Directed edges\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Convert nodes to tensor\n",
    "    x = torch.tensor(nodes, dtype=torch.float).view(-1, 1)  # Example: 1D feature per node\n",
    "\n",
    "    # Create the graph\n",
    "    graph = Data(x=x, edge_index=edge_index, y=torch.tensor([label], dtype=torch.long))\n",
    "    print(graph)\n",
    "    return graph\n",
    "\n",
    "# Process each sentence in the DataFrame\n",
    "graphs_words = []\n",
    "for index, row in content_gab.iterrows():\n",
    "    for sentence, label in zip(row['text'], row['text_labels']):\n",
    "        graph = construct_graph_words(sentence, label)\n",
    "        graphs_words.append(graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge to one graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1198, 384], edge_index=[2, 998], y=[1198])\n",
      "Merged Node Features:\n",
      "tensor([[ 0.0813, -0.0214, -0.0582,  ...,  0.0492,  0.0206,  0.0012],\n",
      "        [-0.0027,  0.0063, -0.0170,  ..., -0.0939, -0.0490,  0.0221],\n",
      "        [ 0.0185, -0.0804,  0.0782,  ..., -0.0679, -0.0118,  0.0497],\n",
      "        ...,\n",
      "        [ 0.0485,  0.0435, -0.0563,  ..., -0.0356,  0.0521, -0.0419],\n",
      "        [ 0.0144,  0.0081, -0.0431,  ..., -0.0029,  0.0659, -0.0579],\n",
      "        [ 0.1278,  0.0149, -0.0109,  ...,  0.0264,  0.0013, -0.0679]])\n",
      "Merged Edge Index:\n",
      "tensor([[   0,    0,    0,  ..., 1193, 1193, 1193],\n",
      "        [   1,    2,    3,  ..., 1195, 1196, 1197]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize empty lists to store the merged node features, edge indices, and labels (y)\n",
    "merged_x = []\n",
    "merged_edge_index = []\n",
    "merged_y = []\n",
    "\n",
    "# Keep track of the offset for node indices in subsequent graphs\n",
    "node_offset = 0\n",
    "\n",
    "# Iterate over each graph in the list\n",
    "for graph in graphs:\n",
    "    # Concatenate node features\n",
    "    merged_x.append(graph.x)\n",
    "    \n",
    "    # Adjust edge indices: add the current node_offset to the second row of edge_index\n",
    "    merged_edge_index.append(graph.edge_index + node_offset)\n",
    "    \n",
    "    # Concatenate labels (y), the target labels from each graph\n",
    "    merged_y.append(graph.y)\n",
    "    \n",
    "    # Update node_offset for the next graph\n",
    "    node_offset += graph.x.size(0)\n",
    "\n",
    "# Concatenate all node features, edge indices, and labels\n",
    "merged_x = torch.cat(merged_x, dim=0)\n",
    "merged_edge_index = torch.cat(merged_edge_index, dim=1)\n",
    "merged_y = torch.cat(merged_y, dim=0)\n",
    "\n",
    "# Create a new graph with merged node features, edge indices, and labels (y)\n",
    "merged_graph = Data(x=merged_x, edge_index=merged_edge_index, y=merged_y)\n",
    "\n",
    "print(merged_graph)\n",
    "# Print the merged graph details\n",
    "print(\"Merged Node Features:\")\n",
    "print(merged_graph.x)\n",
    "print(\"Merged Edge Index:\")\n",
    "print(merged_graph.edge_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node level to graph level labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Aggregating node-level labels into graph-level labels\n",
    "#def convert_to_graph_level(dataset):\n",
    " #   new_dataset = []\n",
    " #   for data in dataset:\n",
    " #       # Example: Majority vote for classification\n",
    "  #      #graph_label = data.y.mode()[0]  # Use the most frequent label\n",
    "   #     graph_label = 1 if (data.y == 1).sum().item() > 0 else 0\n",
    "    #    #data.y = graph_label.unsqueeze(0)  # Ensure shape [1]\n",
    "     #   data.y = graph_label\n",
    "      #  new_dataset.append(data)\n",
    "    #return new_dataset\n",
    "\n",
    "# Convert dataset\n",
    "#new_dataset = convert_to_graph_level(graphs)\n",
    "#for i in new_dataset:\n",
    " #   print(i.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given percentage of shuffled dataset is test fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(graphs_words)\n",
    "\n",
    "size_train = len(graphs_words) - len(graphs_words) // 10 # 10% test dataset\n",
    "\n",
    "train_dataset = graphs_words[:size_train]\n",
    "test_dataset = graphs_words[size_train:]\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = []\n",
    "#for index, row in content_gab.iterrows():\n",
    "#    y.append(np.concatenate((row['text_labels'], row['response_labels'])).astype(int))\n",
    "\n",
    "#for i, q in enumerate(y):\n",
    "#    print(q)\n",
    "#    if i >= 5:\n",
    "#       print('\\n- - - -')\n",
    "#       break\n",
    "#for i, q in enumerate(graphs):\n",
    "#    print(q)\n",
    "#    if i >= 5:\n",
    "#       break\n",
    "\n",
    "#rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=36851234)\n",
    "#folds = list(rskf.split(graphs, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-batching of graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1547, 1], edge_index=[2, 1483], y=[64], batch=[1547], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1730, 1], edge_index=[2, 1666], y=[64], batch=[1730], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1509, 1], edge_index=[2, 1449], y=[64], batch=[1509], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1510, 1], edge_index=[2, 1450], y=[64], batch=[1510], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1256, 1], edge_index=[2, 1195], y=[64], batch=[1256], ptr=[65])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1662, 1], edge_index=[2, 1599], y=[64], batch=[1662], ptr=[65])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1533, 1], edge_index=[2, 1470], y=[64], batch=[1533], ptr=[65])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1691, 1], edge_index=[2, 1628], y=[64], batch=[1691], ptr=[65])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 5\n",
      "DataBatch(x=[98, 1], edge_index=[2, 94], y=[5], batch=[98], ptr=[6])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs from words classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "num_classes = 2\n",
    "input_dim = graphs_words[0].x.shape[1]\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(input_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([5, 2])\n",
      "Epoch: 001, Train Acc: 0.5803, Test Acc: 0.5263\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([5, 2])\n",
      "Epoch: 002, Train Acc: 0.6093, Test Acc: 0.5965\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([5, 2])\n",
      "Epoch: 003, Train Acc: 0.6093, Test Acc: 0.5965\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([5, 2])\n",
      "Epoch: 004, Train Acc: 0.6093, Test Acc: 0.5965\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([5, 2])\n",
      "Epoch: 005, Train Acc: 0.6093, Test Acc: 0.5965\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([5, 2])\n",
      "Epoch: 006, Train Acc: 0.6093, Test Acc: 0.5965\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([5, 2])\n",
      "Epoch: 007, Train Acc: 0.6093, Test Acc: 0.5965\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([64, 2])\n",
      "Model output shape: torch.Size([63, 2])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (63) to match target batch_size (64).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m      \u001b[38;5;28;01mreturn\u001b[39;00m correct \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader\u001b[38;5;241m.\u001b[39mdataset)  \u001b[38;5;66;03m# Derive ratio of correct predictions.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m171\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m test(train_loader)\n\u001b[0;32m     37\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
      "Cell \u001b[1;32mIn[88], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m64\u001b[39m:\n\u001b[0;32m     16\u001b[0m    \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel output shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compute the loss.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Derive gradients.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update parameters based on gradients.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (63) to match target batch_size (64)."
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "            \n",
    "            # Check the output shape and target shape:\n",
    "        \n",
    "         print(f\"Model output shape: {out.shape}\")\n",
    "         \n",
    "         loss = criterion(out, data.y)  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 171):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(384, 16)\n",
      "  (conv2): GCNConv(16, 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "input_dim = merged_graph.x.shape[1]    # embedding dimensionality\n",
    "data = merged_graph\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(input_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "model.eval()\n",
    "\n",
    "out = model(data.x, data.edge_index)\n",
    "#visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6894, Test Accuracy: 0.7922\n",
      "Epoch: 002, Loss: 0.6319, Test Accuracy: 0.7922\n",
      "Epoch: 003, Loss: 0.5803, Test Accuracy: 0.7922\n",
      "Epoch: 004, Loss: 0.5405, Test Accuracy: 0.7922\n",
      "Epoch: 005, Loss: 0.5318, Test Accuracy: 0.7922\n",
      "Epoch: 006, Loss: 0.5238, Test Accuracy: 0.7922\n",
      "Epoch: 007, Loss: 0.5417, Test Accuracy: 0.7922\n",
      "Epoch: 008, Loss: 0.5459, Test Accuracy: 0.7922\n",
      "Epoch: 009, Loss: 0.5421, Test Accuracy: 0.7922\n",
      "Epoch: 010, Loss: 0.5371, Test Accuracy: 0.7922\n",
      "Epoch: 011, Loss: 0.5251, Test Accuracy: 0.7922\n",
      "Epoch: 012, Loss: 0.5132, Test Accuracy: 0.7922\n",
      "Epoch: 013, Loss: 0.5104, Test Accuracy: 0.7922\n",
      "Epoch: 014, Loss: 0.5037, Test Accuracy: 0.7922\n",
      "Epoch: 015, Loss: 0.4979, Test Accuracy: 0.7922\n",
      "Epoch: 016, Loss: 0.5026, Test Accuracy: 0.7922\n",
      "Epoch: 017, Loss: 0.4963, Test Accuracy: 0.7922\n",
      "Epoch: 018, Loss: 0.5015, Test Accuracy: 0.7922\n",
      "Epoch: 019, Loss: 0.4988, Test Accuracy: 0.7922\n",
      "Epoch: 020, Loss: 0.4973, Test Accuracy: 0.7922\n",
      "Epoch: 021, Loss: 0.5009, Test Accuracy: 0.7922\n",
      "Epoch: 022, Loss: 0.4950, Test Accuracy: 0.7922\n",
      "Epoch: 023, Loss: 0.4913, Test Accuracy: 0.7922\n",
      "Epoch: 024, Loss: 0.4878, Test Accuracy: 0.7922\n",
      "Epoch: 025, Loss: 0.4851, Test Accuracy: 0.7922\n",
      "Epoch: 026, Loss: 0.4838, Test Accuracy: 0.7922\n",
      "Epoch: 027, Loss: 0.4807, Test Accuracy: 0.7922\n",
      "Epoch: 028, Loss: 0.4838, Test Accuracy: 0.7922\n",
      "Epoch: 029, Loss: 0.4807, Test Accuracy: 0.7922\n",
      "Epoch: 030, Loss: 0.4834, Test Accuracy: 0.7922\n",
      "Epoch: 031, Loss: 0.4754, Test Accuracy: 0.7922\n",
      "Epoch: 032, Loss: 0.4736, Test Accuracy: 0.7922\n",
      "Epoch: 033, Loss: 0.4727, Test Accuracy: 0.7922\n",
      "Epoch: 034, Loss: 0.4714, Test Accuracy: 0.7922\n",
      "Epoch: 035, Loss: 0.4709, Test Accuracy: 0.7922\n",
      "Epoch: 036, Loss: 0.4680, Test Accuracy: 0.7922\n",
      "Epoch: 037, Loss: 0.4648, Test Accuracy: 0.7922\n",
      "Epoch: 038, Loss: 0.4693, Test Accuracy: 0.7922\n",
      "Epoch: 039, Loss: 0.4672, Test Accuracy: 0.7922\n",
      "Epoch: 040, Loss: 0.4652, Test Accuracy: 0.7922\n",
      "Epoch: 041, Loss: 0.4633, Test Accuracy: 0.7922\n",
      "Epoch: 042, Loss: 0.4546, Test Accuracy: 0.7922\n",
      "Epoch: 043, Loss: 0.4537, Test Accuracy: 0.7922\n",
      "Epoch: 044, Loss: 0.4588, Test Accuracy: 0.7922\n",
      "Epoch: 045, Loss: 0.4522, Test Accuracy: 0.7922\n",
      "Epoch: 046, Loss: 0.4519, Test Accuracy: 0.7922\n",
      "Epoch: 047, Loss: 0.4491, Test Accuracy: 0.7922\n",
      "Epoch: 048, Loss: 0.4471, Test Accuracy: 0.7922\n",
      "Epoch: 049, Loss: 0.4477, Test Accuracy: 0.7922\n",
      "Epoch: 050, Loss: 0.4470, Test Accuracy: 0.7922\n",
      "Epoch: 051, Loss: 0.4444, Test Accuracy: 0.7922\n",
      "Epoch: 052, Loss: 0.4458, Test Accuracy: 0.7922\n",
      "Epoch: 053, Loss: 0.4397, Test Accuracy: 0.7922\n",
      "Epoch: 054, Loss: 0.4384, Test Accuracy: 0.7922\n",
      "Epoch: 055, Loss: 0.4339, Test Accuracy: 0.7922\n",
      "Epoch: 056, Loss: 0.4350, Test Accuracy: 0.7922\n",
      "Epoch: 057, Loss: 0.4301, Test Accuracy: 0.7922\n",
      "Epoch: 058, Loss: 0.4339, Test Accuracy: 0.7922\n",
      "Epoch: 059, Loss: 0.4311, Test Accuracy: 0.7922\n",
      "Epoch: 060, Loss: 0.4248, Test Accuracy: 0.7922\n",
      "Epoch: 061, Loss: 0.4240, Test Accuracy: 0.7922\n",
      "Epoch: 062, Loss: 0.4260, Test Accuracy: 0.7922\n",
      "Epoch: 063, Loss: 0.4197, Test Accuracy: 0.7922\n",
      "Epoch: 064, Loss: 0.4194, Test Accuracy: 0.7922\n",
      "Epoch: 065, Loss: 0.4156, Test Accuracy: 0.7922\n",
      "Epoch: 066, Loss: 0.4193, Test Accuracy: 0.7922\n",
      "Epoch: 067, Loss: 0.4191, Test Accuracy: 0.7922\n",
      "Epoch: 068, Loss: 0.4132, Test Accuracy: 0.7922\n",
      "Epoch: 069, Loss: 0.4152, Test Accuracy: 0.7922\n",
      "Epoch: 070, Loss: 0.4135, Test Accuracy: 0.7922\n",
      "Epoch: 071, Loss: 0.4151, Test Accuracy: 0.7922\n",
      "Epoch: 072, Loss: 0.4104, Test Accuracy: 0.7922\n",
      "Epoch: 073, Loss: 0.4089, Test Accuracy: 0.7922\n",
      "Epoch: 074, Loss: 0.4109, Test Accuracy: 0.7922\n",
      "Epoch: 075, Loss: 0.4063, Test Accuracy: 0.7922\n",
      "Epoch: 076, Loss: 0.4031, Test Accuracy: 0.7922\n",
      "Epoch: 077, Loss: 0.4042, Test Accuracy: 0.7922\n",
      "Epoch: 078, Loss: 0.4018, Test Accuracy: 0.7922\n",
      "Epoch: 079, Loss: 0.4030, Test Accuracy: 0.7922\n",
      "Epoch: 080, Loss: 0.3962, Test Accuracy: 0.7922\n",
      "Epoch: 081, Loss: 0.3971, Test Accuracy: 0.7922\n",
      "Epoch: 082, Loss: 0.3985, Test Accuracy: 0.7922\n",
      "Epoch: 083, Loss: 0.3948, Test Accuracy: 0.7922\n",
      "Epoch: 084, Loss: 0.3915, Test Accuracy: 0.7922\n",
      "Epoch: 085, Loss: 0.3937, Test Accuracy: 0.7922\n",
      "Epoch: 086, Loss: 0.3944, Test Accuracy: 0.7922\n",
      "Epoch: 087, Loss: 0.3893, Test Accuracy: 0.7922\n",
      "Epoch: 088, Loss: 0.3886, Test Accuracy: 0.7922\n",
      "Epoch: 089, Loss: 0.3874, Test Accuracy: 0.7922\n",
      "Epoch: 090, Loss: 0.3867, Test Accuracy: 0.7922\n",
      "Epoch: 091, Loss: 0.3853, Test Accuracy: 0.7922\n",
      "Epoch: 092, Loss: 0.3857, Test Accuracy: 0.7922\n",
      "Epoch: 093, Loss: 0.3890, Test Accuracy: 0.7922\n",
      "Epoch: 094, Loss: 0.3831, Test Accuracy: 0.7922\n",
      "Epoch: 095, Loss: 0.3838, Test Accuracy: 0.7922\n",
      "Epoch: 096, Loss: 0.3797, Test Accuracy: 0.7922\n",
      "Epoch: 097, Loss: 0.3751, Test Accuracy: 0.7922\n",
      "Epoch: 098, Loss: 0.3755, Test Accuracy: 0.7922\n",
      "Epoch: 099, Loss: 0.3764, Test Accuracy: 0.7922\n",
      "Epoch: 100, Loss: 0.3776, Test Accuracy: 0.7922\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "data = merged_graph\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out, data.y.long())  # Compute the loss for the training dataset.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    test_correct = pred == data.y.long()  # Check against ground-truth labels.\n",
    "    test_acc = int(test_correct.sum()) / len(data.y)  # Derive ratio of correct predictions.\n",
    "    return test_acc\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()  # Pass the training dataset to train function.\n",
    "    test_acc = test()  # Pass the test dataset to test function.\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7922\n"
     ]
    }
   ],
   "source": [
    "test_acc = test()\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
