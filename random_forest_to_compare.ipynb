{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we're creating a CNN to compare it with GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary stuff for\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', 10)  # Limit number of rows displayed\n",
    "pd.set_option('display.width', 1000)  # Set max width for table\n",
    "pd.set_option('display.colheader_justify', 'center')  # Center-align column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_special_chars(value):\n",
    "    if isinstance(value, str):  \n",
    "        return value.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ').replace('  ', ' ').strip()\n",
    "    return value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading gab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_gab = pd.read_csv('gab_reddit_benchmark/gab.csv')\n",
    "\n",
    "content_gab[\"text\"] = content_gab[\"text\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\") \n",
    "content_gab[\"response\"] = content_gab[\"response\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\")\n",
    "content_gab[\"hate_speech_idx\"] = content_gab[\"hate_speech_idx\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\") \n",
    "\n",
    "# content_gab[\"text\"] = content_gab[\"text\"].apply(clean_special_chars)\n",
    "# content_gab[\"response\"] = content_gab[\"response\"].apply(clean_special_chars)\n",
    "\n",
    "for index, row in content_gab.iterrows():\n",
    "    row['text'] = row['text'].replace(\"'\", '\"')\n",
    "    row['response'] = row['response'].replace(\"'\", '\"')\n",
    "\n",
    "# content_gab = content_gab.applymap(clean_special_chars)\n",
    "print(content_gab.head(n=10))\n",
    "print('\\n- - - - - -\\n')\n",
    "print(content_gab.columns)\n",
    "print('\\n- - - - - -\\n')\n",
    "print(content_gab.iloc[1]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_first_number(input_string):\n",
    "    match = re.search(r'\\d{2,}', input_string)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None\n",
    "\n",
    "content_gab['extracted_id'] = content_gab['id'].apply(get_first_number)\n",
    "\n",
    "# Find duplicate rows based on 'extracted_id'\n",
    "duplicates = content_gab[content_gab.duplicated(subset=['extracted_id'], keep=False)]\n",
    "filtered_groups = []\n",
    "grouped = content_gab.groupby('extracted_id')\n",
    "for key, group in grouped:\n",
    "    if len(group) > 1:\n",
    "        filtered_groups.append(group)\n",
    "\n",
    "merged_df = pd.concat(filtered_groups, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv('gab_reddit_benchmark/gab_groups.csv', index=False)\n",
    "\n",
    "merged_df = grouped.agg({\n",
    "    'id': ' '.join,\n",
    "    'text': ' '.join,\n",
    "    'hate_speech_idx': ' '.join,\n",
    "    'response': ' '.join\n",
    "}).reset_index()\n",
    "merged_df.to_csv('gab_reddit_benchmark/gab_merged.csv')\n",
    "\n",
    "df = pd.read_csv('gab_reddit_benchmark/gab_merged.csv')\n",
    "df = df.applymap(lambda x: x.replace('] [', ', ') if isinstance(x, str) else x)\n",
    "df = df.applymap(lambda x: x.replace(']  [', ', ') if isinstance(x, str) else x)\n",
    "df = df.applymap(lambda x: 'n/a' if isinstance(x, str) and x.strip() == '' else x)\n",
    "df.to_csv('gab_reddit_benchmark/gab_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_gab_m = pd.read_csv('gab_reddit_benchmark/gab_merged.csv')\n",
    "content_gab_m = content_gab_m.drop('Unnamed: 0', axis=1)\n",
    "content_gab_m = content_gab_m.drop('extracted_id', axis=1)\n",
    "\n",
    "\n",
    "content_gab_m[\"text\"] = content_gab_m[\"text\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\") \n",
    "content_gab_m[\"response\"] = content_gab_m[\"response\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\")\n",
    "content_gab_m[\"hate_speech_idx\"] = content_gab_m[\"hate_speech_idx\"].replace(to_replace=[None, np.nan, \"\", \"nan\", \"n/a\"], value=\"\") \n",
    "\n",
    "for index, row in content_gab_m.iterrows():\n",
    "    row['text'] = row['text'].replace(\"'\", '\"')\n",
    "    row['response'] = row['response'].replace(\"'\", '\"')\n",
    "\n",
    "print(content_gab_m.head(n=10))\n",
    "print('\\n- - - - - -\\n')\n",
    "print(content_gab_m.columns)\n",
    "print('\\n- - - - - -\\n')\n",
    "print(content_gab_m.iloc[0]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_text_labels(text_utterances_length, labels):\n",
    "    if not labels:\n",
    "        # return ['other'] * text_utterances_length\n",
    "        return [0] * text_utterances_length\n",
    "    new_labels = []\n",
    "    int_list = ast.literal_eval(labels)\n",
    "    for i in range(text_utterances_length):\n",
    "        if i+1 in int_list:\n",
    "            # new_labels.append('hate_speech')\n",
    "            new_labels.append(1)\n",
    "        else:\n",
    "            # new_labels.append('other')\n",
    "            new_labels.append(0)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting 'text' and 'response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column = []\n",
    "text_labels_column = []\n",
    "response_column = []\n",
    "response_labels_column = []\n",
    "\n",
    "for index, row in content_gab.iterrows():\n",
    "    text_utterances = row['text'].split('\\n')\n",
    "    text_utterances = list(filter(None, text_utterances))\n",
    "\n",
    "    for i, t in enumerate(text_utterances):\n",
    "        text_utterances[i] = clean_special_chars(t)\n",
    "    text_labels = mark_text_labels(len(text_utterances), row['hate_speech_idx'])\n",
    "\n",
    "    response_utterances = ast.literal_eval(row['response']) if row['response'] else []\n",
    "    for i, r in enumerate(response_utterances):\n",
    "        response_utterances[i] = clean_special_chars(r)\n",
    "    # response_labels = ['other'] * len(response_utterances)  \n",
    "    response_labels = [0] * len(response_utterances)  \n",
    "\n",
    "    \n",
    "    text_column.append(text_utterances)\n",
    "    text_labels_column.append(text_labels)\n",
    "    response_column.append(response_utterances)\n",
    "    response_labels_column.append(response_labels)\n",
    "\n",
    "content_gab['text'] = text_column\n",
    "content_gab['hate_speech_idx'] = text_labels_column\n",
    "content_gab['response'] = response_column\n",
    "content_gab['response_labels'] = response_labels_column\n",
    "\n",
    "content_gab = content_gab.rename(columns={'hate_speech_idx': 'text_labels'})\n",
    "print(content_gab.head())\n",
    "print('- - - - ')\n",
    "print(content_gab.columns)\n",
    "\n",
    "for index, row in content_gab.iterrows():\n",
    "    if index == 1:\n",
    "        continue\n",
    "    print(row['id'], row['text'], row['text_labels'], row['response'], row['response_labels'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text, first label, response, first response label for each row\n",
    "texts = []\n",
    "text_labels = []\n",
    "for index, row in content_gab.iterrows():\n",
    "    for i, t in enumerate(row['text']):\n",
    "        texts.append(t)\n",
    "        text_labels.append(row['text_labels'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def generate_embeddings(sentences):\n",
    "    if isinstance(sentences, list):\n",
    "        return bert.encode(sentences, show_progress_bar=True).tolist()\n",
    "    elif isinstance(sentences, str):\n",
    "        return bert.encode([sentences], show_progress_bar=True).tolist()\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_gab = content_gab[:200]\n",
    "# before = time.time()\n",
    "# content_gab['text_embeddings'] = content_gab['text'].apply(generate_embeddings)\n",
    "# after_text = time.time()\n",
    "# print(content_gab.iloc[1]['text_embeddings'])\n",
    "# print('\\nTIME FOR TEXT EMBEDDINGS: ', after_text - before)\n",
    "# print('\\n- - - - - -\\n')\n",
    "# content_gab['response_embeddings'] = content_gab['response'].apply(generate_embeddings)\n",
    "# after_response = time.time()\n",
    "# print(content_gab.iloc[2]['response_embeddings'])\n",
    "# print('\\nTIME FOR RESPONSE EMBEDDINGS: ', after_response - after_text)\n",
    "# print('\\n- - - - - -\\n')\n",
    "# embed texts\n",
    "before = time.time()\n",
    "text_embeddings = generate_embeddings(texts)\n",
    "after_text = time.time()\n",
    "print('\\nTIME FOR TEXT EMBEDDINGS: ', after_text - before)\n",
    "print('\\n- - - - - -\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "text_embeddings = np.array(text_embeddings)\n",
    "print(f\"embeddings shape: {text_embeddings.shape}\")\n",
    "text_labels = np.array(text_labels)\n",
    "print(f\"labels shape: {text_labels.shape}\")\n",
    "\n",
    "text_embeddings = np.stack(text_embeddings, axis=0)\n",
    "text_labels = np.stack(text_labels, axis=0)\n",
    "print(f\"embeddings shape: {text_embeddings.shape}\")\n",
    "print(f\"labels shape: {text_labels.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_embeddings, text_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=50, \n",
    "    max_depth=10\n",
    ")\n",
    "cv_scores = []\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(rskf.split(X_train, y_train)):\n",
    "    X_train_fold, X_test_fold = X_train[train_idx], X_train[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
    "\n",
    "    model = clone(rf)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = model.predict(X_test_fold)\n",
    "    accuracy = balanced_accuracy_score(y_test_fold, y_pred)\n",
    "    cv_scores.append(accuracy)\n",
    "    print(f\"Fold {i+1} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "final_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy (Mean ± Std): {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')\n",
    "print(f'Final Test Accuracy: {final_accuracy:.4f}')\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    rf, X_train, y_train, cv=rskf, scoring=\"balanced_accuracy\", train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, \"o-\", color=\"blue\", label=\"Training Balanced Accuracy\")\n",
    "\n",
    "plt.plot(train_sizes, test_mean, \"o-\", color=\"red\", label=\"Cross-Validation Balanced Accuracy\")\n",
    "\n",
    "plt.ylabel(\"Balanced Accuracy\")\n",
    "plt.title(\"Learning Curve with Repeated Stratified K-Fold\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
